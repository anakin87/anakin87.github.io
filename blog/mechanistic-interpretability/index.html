<!doctype html><html lang=en><head><meta charset=UTF-8><meta content="default-src 'self';font-src 'self' data:;img-src 'self' https://* data:;media-src 'self';style-src 'self';frame-src 'self' player.vimeo.com https://www.youtube-nocookie.com;connect-src 'self';script-src 'self' 'self'" http-equiv=Content-Security-Policy><meta content="width=device-width,initial-scale=1.0" name=viewport><meta content=https://anakin87.github.io/ name=base><title>
~/anakin87 â€¢ ğŸ¤” What does a LLM think when it thinks?</title><link href='data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100"><text y="50%" x="50%" dominant-baseline="central" text-anchor="middle" font-size="88">ğŸ§‘â€ğŸš€</text></svg>' rel=icon><link title="~/anakin87 - Atom Feed" href=https://anakin87.github.io/atom.xml rel=alternate type=application/atom+xml><link href="https://anakin87.github.io/custom_subset.css?h=0b9535a28bc3d5bf2321" rel=stylesheet><link href="https://anakin87.github.io/main.css?h=045c365e19a4d50a64bb" rel=stylesheet><link href="https://anakin87.github.io/skins/indigo_ingot.css?h=d429472afbb246441b1a" rel=stylesheet><meta content="light dark" name=color-scheme><meta content="Introduction to mechanistic interpretability of LLMs." name=description><meta content="Introduction to mechanistic interpretability of LLMs." property=og:description><meta content="ğŸ¤” What does a LLM think when it thinks?" property=og:title><meta content=article property=og:type><meta content=en_GB property=og:locale><meta content=https://anakin87.github.io/blog/mechanistic-interpretability/ property=og:url><meta content=~/anakin87 property=og:site_name><noscript><link href=https://anakin87.github.io/no_js.css rel=stylesheet></noscript><script src=https://anakin87.github.io/js/initializeTheme.min.js></script><script defer src=https://anakin87.github.io/js/themeSwitcher.min.js></script><script src="https://anakin87.github.io/js/searchElasticlunr.min.js?h=3626c0ef99daa745b31e" defer></script><body><a href=#main-content id=skip-link>Skip to content</a><header><nav class=navbar><div class=nav-title><a class=home-title href=https://anakin87.github.io/>~/anakin87</a></div><div class=nav-navs><ul><li><a class="nav-links no-hover-padding" href=https://anakin87.github.io/about/>about </a><li><a class="nav-links no-hover-padding" href=https://anakin87.github.io/blog/>blog </a><li><a class="nav-links no-hover-padding" href=https://anakin87.github.io/tags/tutorials/>tutorials </a><li><a class="nav-links no-hover-padding" href=https://anakin87.github.io/archive/>archive </a><li><a class="nav-links no-hover-padding" href=https://anakin87.github.io/tags/>tags </a><li class=menu-icons-container><ul class=menu-icons-group><li class="js menu-icon"><div aria-label="Click or press $SHORTCUT to open search" class="search-icon interactive-icon" title="Click or press $SHORTCUT to open search" id=search-button role=button tabindex=0><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="M784-120 532-372q-30 24-69 38t-83 14q-109 0-184.5-75.5T120-580q0-109 75.5-184.5T380-840q109 0 184.5 75.5T640-580q0 44-14 83t-38 69l252 252-56 56ZM380-400q75 0 127.5-52.5T560-580q0-75-52.5-127.5T380-760q-75 0-127.5 52.5T200-580q0 75 52.5 127.5T380-400Z"/></svg></div><li class="theme-switcher-wrapper js"><div aria-label="Toggle dark mode" title="Toggle dark/light mode" aria-pressed=false class=theme-switcher role=button tabindex=0></div><div aria-label="Reset mode to default" class="theme-resetter arrow" title="Reset mode to default" aria-hidden=true role=button tabindex=0></div></ul></ul></div></nav></header><div class=content id=main-content><main><article class=h-entry><h1 class="p-name article-title">ğŸ¤” What does a LLM think when it thinks?</h1><a class="u-url u-uid" href=https://anakin87.github.io/blog/mechanistic-interpretability/></a><ul class=meta><span class="hidden p-author h-card"> <a title="Stefano Fiorucci" class=u-url href=https://anakin87.github.io/ rel=author>Stefano Fiorucci</a> </span><li><time class=dt-published datetime=2024-08-01>1st Aug 2024</time><li title="266 words"><span aria-hidden=true class=separator>â€¢</span>2 min read<li class=tag><span aria-hidden=true class=separator>â€¢</span>Tags:Â <li class=tag><a class=p-category href=https://anakin87.github.io/tags/llm/>LLM</a>,Â <li class=tag><a class=p-category href=https://anakin87.github.io/tags/interpretability/>interpretability</a>,Â <li class=tag><a class=p-category href=https://anakin87.github.io/tags/gemma/>Gemma</a>,Â <li class=tag><a class=p-category href=https://anakin87.github.io/tags/notes/>notes</a></ul><p class=p-summary hidden>Introduction to mechanistic interpretability of LLMs.<section class="e-content body"><div class=toc-container><ul><li><a href=https://anakin87.github.io/blog/mechanistic-interpretability/#memo-mechanistic-interpretability-recap>ğŸ“ Mechanistic interpretability recap</a><li><a href=https://anakin87.github.io/blog/mechanistic-interpretability/#gem-gemma-scope>ğŸ’ Gemma Scope</a><li><a href=https://anakin87.github.io/blog/mechanistic-interpretability/#books-resources>ğŸ“š Resources</a> <ul><li><a href=https://anakin87.github.io/blog/mechanistic-interpretability/#theory>Theory</a><li><a href=https://anakin87.github.io/blog/mechanistic-interpretability/#gem-gemma-scope-1>ğŸ’ Gemma Scope</a></ul></ul></div><p>Yesterdayâ€™s Gemma release was big!<p>Not only because the 2B model surpasses GPT-3.5-Turbo in the Chatbot Arenaâ€¦<p>Deepmind folks also released Gemma Scope, which opens new doors in LLM interpretability.<h2 id=memo-mechanistic-interpretability-recap>ğŸ“ Mechanistic interpretability recap</h2><p>ğŸ”¹ When you ask an LLM a question, your text is turned into a series of activations that map the relations between words.<p>ğŸ”¹ These activations, at different layers in the modelâ€™s neural network, represent increasingly complex concepts, called features.<p>â›” Researchers face a key challenge: the modelâ€™s activations mix many different features together.<p>â›” Features do not match individual neurons.<p>ğŸ’¡ This is where <strong>sparse autoencoders</strong> come in. They can be trained for each layer/sublayer to identify a small number of significant features for each activation. (Remember Golden Gate Claude? ğŸŒ‰)<h2 id=gem-gemma-scope>ğŸ’ Gemma Scope</h2><p>Google DeepMind trained sparse autoencoders for every layer and sublayer output of Gemma 2 2B and 9B.<p>Gemma Scope is a collection of over 400 sparse autoencoders with more than 30 million learned features.<p>You can easily use these to investigate and inspect the inner behavior of the LLM.<p>Comes with an interactive demo and a Colab notebook! ğŸ““<p><img alt="Gemma Scope" src=https://anakin87.github.io/blog/mechanistic-interpretability/gemma_scope.jpeg><h2 id=books-resources>ğŸ“š Resources</h2><h3 id=theory>Theory</h3><ul><li><a class=external href=https://adamkarvonen.github.io/machine_learning/2024/06/11/sae-intuitions.html rel=external>Introduction to Sparse Autoencoders for LLM interpretability (by Adam Karvonen)</a><li><a class=external href=https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html rel=external>Scaling monosemanticity - with Golden Gate experiment (by Anthropic)</a></ul><h3 id=gem-gemma-scope-1>ğŸ’ Gemma Scope</h3><ul><li><a class=external href=https://deepmind.google/discover/blog/gemma-scope-helping-the-safety-community-shed-light-on-the-inner-workings-of-language-models/ rel=external>Blog post</a><li><a class=external href=https://storage.googleapis.com/gemma-scope/gemma-scope-report.pdf rel=external>Technical report</a><li><a class=external href=https://www.neuronpedia.org/gemma-scope rel=external>Interactive demo</a><li><a class=external href=https://colab.research.google.com/drive/17dQFYUYnuKnP6OwQPH9v_GSYUW5aj-Rp rel=external>Colab notebook</a></ul></section></article></main><div id=button-container><div id=toc-floating-container><input class=toggle id=toc-toggle type=checkbox><label title="Toggle Table of Contents" class=button for=toc-toggle id=toc-button><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="M414.82-193.094q-18.044 0-30.497-12.32-12.453-12.319-12.453-30.036t12.453-30.086q12.453-12.37 30.497-12.37h392.767q17.237 0 29.927 12.487 12.69 12.486 12.69 30.203 0 17.716-12.69 29.919t-29.927 12.203H414.82Zm0-244.833q-18.044 0-30.497-12.487Q371.87-462.9 371.87-480.45t12.453-29.92q12.453-12.369 30.497-12.369h392.767q17.237 0 29.927 12.511 12.69 12.512 12.69 29.845 0 17.716-12.69 30.086-12.69 12.37-29.927 12.37H414.82Zm0-245.167q-18.044 0-30.497-12.32t-12.453-30.037q0-17.716 12.453-30.086 12.453-12.369 30.497-12.369h392.767q17.237 0 29.927 12.486 12.69 12.487 12.69 30.203 0 17.717-12.69 29.92-12.69 12.203-29.927 12.203H414.82ZM189.379-156.681q-32.652 0-55.878-22.829t-23.226-55.731q0-32.549 23.15-55.647 23.151-23.097 55.95-23.097 32.799 0 55.313 23.484 22.515 23.484 22.515 56.246 0 32.212-22.861 54.893-22.861 22.681-54.963 22.681Zm0-245.167q-32.652 0-55.878-23.134-23.226-23.135-23.226-55.623 0-32.487 23.467-55.517t56.12-23.03q32.102 0 54.721 23.288 22.62 23.288 22.62 55.775 0 32.488-22.861 55.364-22.861 22.877-54.963 22.877Zm-.82-244.833q-32.224 0-55.254-23.288-23.03-23.289-23.03-55.623 0-32.333 23.271-55.364 23.272-23.03 55.495-23.03 32.224 0 55.193 23.288 22.969 23.289 22.969 55.622 0 32.334-23.21 55.364-23.21 23.031-55.434 23.031Z"/></svg></label><div class=toc-content><div class=toc-container><ul><li><a href=https://anakin87.github.io/blog/mechanistic-interpretability/#memo-mechanistic-interpretability-recap>ğŸ“ Mechanistic interpretability recap</a><li><a href=https://anakin87.github.io/blog/mechanistic-interpretability/#gem-gemma-scope>ğŸ’ Gemma Scope</a><li><a href=https://anakin87.github.io/blog/mechanistic-interpretability/#books-resources>ğŸ“š Resources</a> <ul><li><a href=https://anakin87.github.io/blog/mechanistic-interpretability/#theory>Theory</a><li><a href=https://anakin87.github.io/blog/mechanistic-interpretability/#gem-gemma-scope-1>ğŸ’ Gemma Scope</a></ul></ul></div></div></div><a title="Go to the top of the page" class=no-hover-padding href=# id=top-button> <svg viewbox="0 0 20 20" fill=currentColor><path d="M3.293 9.707a1 1 0 010-1.414l6-6a1 1 0 011.414 0l6 6a1 1 0 01-1.414 1.414L11 5.414V17a1 1 0 11-2 0V5.414L4.707 9.707a1 1 0 01-1.414 0z"/></svg> </a></div><span class=hidden id=copy-success> Copied! </span><span class=hidden id=copy-init> Copy code to clipboard </span><script defer src=https://anakin87.github.io/js/copyCodeToClipboard.min.js></script></div><footer><section><nav class="socials nav-navs"><ul><li><a class="nav-links no-hover-padding social" rel=" me" href=https://github.com/anakin87> <img alt=github loading=lazy src=https://anakin87.github.io/social_icons/github.svg title=github> </a><li><a class="nav-links no-hover-padding social" rel=" me" href=https://huggingface.co/anakin87> <img alt=huggingface loading=lazy src=https://anakin87.github.io/social_icons/huggingface.svg title=huggingface> </a><li><a class="nav-links no-hover-padding social" rel=" me" href=https://www.linkedin.com/in/stefano-fiorucci/> <img alt=linkedin loading=lazy src=https://anakin87.github.io/social_icons/linkedin.svg title=linkedin> </a><li><a class="nav-links no-hover-padding social" rel=" me" href=https://x.com/theanakin87> <img alt=x loading=lazy src=https://anakin87.github.io/social_icons/x.svg title=x> </a><li><a class="nav-links no-hover-padding social" rel=" me" href=mailto:stefanofiorucci@gmail.com> <img alt=email loading=lazy src=https://anakin87.github.io/social_icons/email.svg title=email> </a></ul></nav><nav class=nav-navs></nav><div class=credits><small> Powered by <a href=https://www.getzola.org>Zola</a> & <a href=https://github.com/welpo/tabi>tabi</a> </small></div></section><div class="search-modal js" aria-labelledby=modalTitle id=searchModal role=dialog><h1 class=visually-hidden id=modalTitle>Search</h1><div id=modal-content><div id=searchBar><div aria-hidden=true class=search-icon><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="M784-120 532-372q-30 24-69 38t-83 14q-109 0-184.5-75.5T120-580q0-109 75.5-184.5T380-840q109 0 184.5 75.5T640-580q0 44-14 83t-38 69l252 252-56 56ZM380-400q75 0 127.5-52.5T560-580q0-75-52.5-127.5T380-760q-75 0-127.5 52.5T200-580q0 75 52.5 127.5T380-400Z"/></svg></div><input aria-controls=results-container aria-expanded=false autocomplete=off id=searchInput placeholder=Searchâ€¦ role=combobox spellcheck=false><div class="close-icon interactive-icon" title="Clear search" id=clear-search role=button tabindex=0><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="m256-200-56-56 224-224-224-224 56-56 224 224 224-224 56 56-224 224 224 224-56 56-224-224-224 224Z"/></svg></div></div><div id=results-container><div id=results-info><span id=zero_results> No results</span><span id=one_results> $NUMBER result</span><span id=many_results> $NUMBER results</span><span id=two_results> $NUMBER results</span><span id=few_results> $NUMBER results</span></div><div id=results role=listbox></div></div></div></div></footer>