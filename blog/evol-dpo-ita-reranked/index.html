<!doctype html><html lang=en><head><meta charset=UTF-8><meta content="default-src 'self';font-src 'self' data:;img-src 'self' https://* data:;media-src 'self';style-src 'self';frame-src 'self' player.vimeo.com https://www.youtube-nocookie.com;connect-src 'self';script-src 'self' 'self'" http-equiv=Content-Security-Policy><meta content="width=device-width,initial-scale=1.0" name=viewport><meta content=https://anakin87.github.io/ name=base><title>
~/anakin87 â€¢ New Italian Preference Dataset ğŸ‡®ğŸ‡¹ğŸ‘ğŸ‘</title><link href='data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100"><text y="50%" x="50%" dominant-baseline="central" text-anchor="middle" font-size="88">ğŸ§‘â€ğŸš€</text></svg>' rel=icon><link title="~/anakin87 - Atom Feed" href=https://anakin87.github.io/atom.xml rel=alternate type=application/atom+xml><link href="https://anakin87.github.io/custom_subset.css?h=0b9535a28bc3d5bf2321" rel=stylesheet><link href="https://anakin87.github.io/main.css?h=045c365e19a4d50a64bb" rel=stylesheet><link href="https://anakin87.github.io/skins/indigo_ingot.css?h=d429472afbb246441b1a" rel=stylesheet><meta content="light dark" name=color-scheme><meta content="How I improved an existing Italian dataset for DPO." name=description><meta content="How I improved an existing Italian dataset for DPO." property=og:description><meta content="New Italian Preference Dataset ğŸ‡®ğŸ‡¹ğŸ‘ğŸ‘" property=og:title><meta content=article property=og:type><meta content=en_GB property=og:locale><meta content=https://anakin87.github.io/blog/evol-dpo-ita-reranked/ property=og:url><meta content=~/anakin87 property=og:site_name><noscript><link href=https://anakin87.github.io/no_js.css rel=stylesheet></noscript><script src=https://anakin87.github.io/js/initializeTheme.min.js></script><script defer src=https://anakin87.github.io/js/themeSwitcher.min.js></script><script src="https://anakin87.github.io/js/searchElasticlunr.min.js?h=3626c0ef99daa745b31e" defer></script><body><a href=#main-content id=skip-link>Skip to content</a><header><nav class=navbar><div class=nav-title><a class=home-title href=https://anakin87.github.io/>~/anakin87</a></div><div class=nav-navs><ul><li><a class="nav-links no-hover-padding" href=https://anakin87.github.io/about/>about </a><li><a class="nav-links no-hover-padding" href=https://anakin87.github.io/blog/>blog </a><li><a class="nav-links no-hover-padding" href=https://anakin87.github.io/tags/tutorials/>tutorials </a><li><a class="nav-links no-hover-padding" href=https://anakin87.github.io/archive/>archive </a><li><a class="nav-links no-hover-padding" href=https://anakin87.github.io/tags/>tags </a><li class=menu-icons-container><ul class=menu-icons-group><li class="js menu-icon"><div aria-label="Click or press $SHORTCUT to open search" class="search-icon interactive-icon" title="Click or press $SHORTCUT to open search" id=search-button role=button tabindex=0><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="M784-120 532-372q-30 24-69 38t-83 14q-109 0-184.5-75.5T120-580q0-109 75.5-184.5T380-840q109 0 184.5 75.5T640-580q0 44-14 83t-38 69l252 252-56 56ZM380-400q75 0 127.5-52.5T560-580q0-75-52.5-127.5T380-760q-75 0-127.5 52.5T200-580q0 75 52.5 127.5T380-400Z"/></svg></div><li class="theme-switcher-wrapper js"><div aria-label="Toggle dark mode" title="Toggle dark/light mode" aria-pressed=false class=theme-switcher role=button tabindex=0></div><div aria-label="Reset mode to default" class="theme-resetter arrow" title="Reset mode to default" aria-hidden=true role=button tabindex=0></div></ul></ul></div></nav></header><div class=content id=main-content><main><article class=h-entry><h1 class="p-name article-title">New Italian Preference Dataset ğŸ‡®ğŸ‡¹ğŸ‘ğŸ‘</h1><a class="u-url u-uid" href=https://anakin87.github.io/blog/evol-dpo-ita-reranked/></a><ul class=meta><span class="hidden p-author h-card"> <a title="Stefano Fiorucci" class=u-url href=https://anakin87.github.io/ rel=author>Stefano Fiorucci</a> </span><li><time class=dt-published datetime=2025-01-22>22nd Jan 2025</time><li title="307 words"><span aria-hidden=true class=separator>â€¢</span>2 min read<li class=tag><span aria-hidden=true class=separator>â€¢</span>Tags:Â <li class=tag><a class=p-category href=https://anakin87.github.io/tags/llm/>LLM</a>,Â <li class=tag><a class=p-category href=https://anakin87.github.io/tags/dpo/>DPO</a>,Â <li class=tag><a class=p-category href=https://anakin87.github.io/tags/dataset/>dataset</a>,Â <li class=tag><a class=p-category href=https://anakin87.github.io/tags/italian/>Italian</a>,Â <li class=tag><a class=p-category href=https://anakin87.github.io/tags/neogenesis/>neogenesis</a></ul><p class=p-summary hidden>How I improved an existing Italian dataset for DPO.<section class="e-content body"><p>The most common fine-tuning workflow of a Language Models involves two steps:<ul><li><p><em>Supervised Fine-Tuning (SFT)</em>: train the model to follow instructions. Datasets for this step include instruction-response pairs.</p><li><p><em>Preference Tuning</em>: align the model with human/AI preferences by training it to favor high-quality responses over poor ones. A simple and effective algorithm to do that is <strong>Direct Preference Optimization (DPO)</strong>. Data for this step follows this format: instruction, chosen response, rejected response.</p></ul><p>During the recent Gemma competition, I trained a nice SFT model and wanted to further improve it with Preference Tuning.<p>I identified some good datasets (by mii-llm and Ruggero Marino Lazzaroni ğŸ™) but had limited examples (&lt;3K).<p><strong>Then I found a hidden gem -> ğŸ’ <a class=external href=https://huggingface.co/datasets/efederici/evol-dpo-ita rel=external>evol-dpo-ita (by Edoardo Federici)</a></strong><p>This dataset contains 20K prompts translated from Evol-Instruct, with responses generated using GPT-3.5 Turbo and Claude 3 Opus.<p>âš ï¸ It only has a limitation: the response from the stronger model (Claude) is always classified as â€œchosenâ€ and the other one as â€œrejectedâ€. It is a good but not perfect approximation.<p><strong>I thought: I can improve it! ğŸª„</strong><p>I used Llama-3.1-70B-Instruct as a Judge ğŸ§‘â€âš–ï¸ to re-rank the responses.<p>I queried the model via the cheap Hugging Face API PRO. My prompt was inspired by the Ultrafeedback prompt (available in distilabel by Argilla).<p>ğŸ“Š Results:<ul><li>7% of the times chosen and rejected were swapped ğŸ”€<li>Another 7% of responses were ties<li>I used the obtained dataset to train 2 models with DPO, achieving significant improvements for Italian! ğŸ“ˆ</ul><p>Iâ€™ve published my new dataset (<a class=external href=https://huggingface.co/datasets/anakin87/evol-dpo-ita-reranked rel=external>anakin87/evol-dpo-ita-reranked</a>) on the ğŸ¤— HF Hub. ğŸ““ <strong><a class=external href=https://www.kaggle.com/code/anakin87/post-training-gemma-for-italian-and-beyond rel=external>Code</a></strong> <img alt="Evol DPO ita reranked" src=https://raw.githubusercontent.com/anakin87/gemma-neogenesis/refs/heads/main/images/evol_dpo_ita_reranked.png></section></article></main><div id=button-container><a title="Go to the top of the page" class=no-hover-padding href=# id=top-button> <svg viewbox="0 0 20 20" fill=currentColor><path d="M3.293 9.707a1 1 0 010-1.414l6-6a1 1 0 011.414 0l6 6a1 1 0 01-1.414 1.414L11 5.414V17a1 1 0 11-2 0V5.414L4.707 9.707a1 1 0 01-1.414 0z"/></svg> </a></div><span class=hidden id=copy-success> Copied! </span><span class=hidden id=copy-init> Copy code to clipboard </span><script defer src=https://anakin87.github.io/js/copyCodeToClipboard.min.js></script></div><footer><section><nav class="socials nav-navs"><ul><li><a class="nav-links no-hover-padding social" rel=" me" href=https://github.com/anakin87> <img alt=github loading=lazy src=https://anakin87.github.io/social_icons/github.svg title=github> </a><li><a class="nav-links no-hover-padding social" rel=" me" href=https://huggingface.co/anakin87> <img alt=huggingface loading=lazy src=https://anakin87.github.io/social_icons/huggingface.svg title=huggingface> </a><li><a class="nav-links no-hover-padding social" rel=" me" href=https://www.linkedin.com/in/stefano-fiorucci/> <img alt=linkedin loading=lazy src=https://anakin87.github.io/social_icons/linkedin.svg title=linkedin> </a><li><a class="nav-links no-hover-padding social" rel=" me" href=https://x.com/theanakin87> <img alt=x loading=lazy src=https://anakin87.github.io/social_icons/x.svg title=x> </a><li><a class="nav-links no-hover-padding social" rel=" me" href=mailto:stefanofiorucci@gmail.com> <img alt=email loading=lazy src=https://anakin87.github.io/social_icons/email.svg title=email> </a></ul></nav><nav class=nav-navs></nav><div class=credits><small> Powered by <a href=https://www.getzola.org>Zola</a> & <a href=https://github.com/welpo/tabi>tabi</a> </small></div></section><div class="search-modal js" aria-labelledby=modalTitle id=searchModal role=dialog><h1 class=visually-hidden id=modalTitle>Search</h1><div id=modal-content><div id=searchBar><div aria-hidden=true class=search-icon><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="M784-120 532-372q-30 24-69 38t-83 14q-109 0-184.5-75.5T120-580q0-109 75.5-184.5T380-840q109 0 184.5 75.5T640-580q0 44-14 83t-38 69l252 252-56 56ZM380-400q75 0 127.5-52.5T560-580q0-75-52.5-127.5T380-760q-75 0-127.5 52.5T200-580q0 75 52.5 127.5T380-400Z"/></svg></div><input aria-controls=results-container aria-expanded=false autocomplete=off id=searchInput placeholder=Searchâ€¦ role=combobox spellcheck=false><div class="close-icon interactive-icon" title="Clear search" id=clear-search role=button tabindex=0><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="m256-200-56-56 224-224-224-224 56-56 224 224 224-224 56 56-224 224 224 224-56 56-224-224-224 224Z"/></svg></div></div><div id=results-container><div id=results-info><span id=zero_results> No results</span><span id=one_results> $NUMBER result</span><span id=many_results> $NUMBER results</span><span id=two_results> $NUMBER results</span><span id=few_results> $NUMBER results</span></div><div id=results role=listbox></div></div></div></div></footer>