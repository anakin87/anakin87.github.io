<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet href="https://anakin87.github.io/feed_style.xsl" type="text/xsl"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <tabi:metadata xmlns:tabi="https://github.com/welpo/tabi">
        <tabi:base_url>https:&#x2F;&#x2F;anakin87.github.io&#x2F;</tabi:base_url>
        <tabi:separator>
            â€¢
        </tabi:separator>
        <tabi:about_feeds>This is a web feed, also known as an Atom feed. Subscribe by copying the URL from the address bar into your newsreader. Visit About Feeds to learn more and get started. It&#x27;s free.</tabi:about_feeds>
        <tabi:visit_the_site>Visit website</tabi:visit_the_site>
        <tabi:recent_posts>Recent posts</tabi:recent_posts>
        <tabi:last_updated_on>Updated on $DATE</tabi:last_updated_on>
        <tabi:default_theme></tabi:default_theme>
        <tabi:post_listing_date>date</tabi:post_listing_date>
        <tabi:current_section>~&#x2F;anakin87</tabi:current_section>
    </tabi:metadata><link rel="extra-stylesheet" href="https://anakin87.github.io/skins/indigo_ingot.css?h=d429472afbb246441b1a" /><title>~/anakin87</title>
        <subtitle>Personal website of Stefano Fiorucci, AI&#x2F;NLP&#x2F;Software Engineer.</subtitle>
    <link href="https://anakin87.github.io/atom.xml" rel="self" type="application/atom+xml"/>
    <link href="https://anakin87.github.io" rel="alternate" type="text/html"/>
    <generator uri="https://www.getzola.org/">Zola</generator><updated>2025-11-12T00:00:00+00:00</updated><id>https://anakin87.github.io/atom.xml</id><entry xml:lang="en">
        <title>LLMs can leak their post-training data (RL included) ğŸ’§</title>
        <published>2025-11-12T00:00:00+00:00</published>
        <updated>2025-11-12T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/alignment-data-extraction/" type="text/html"/>
        <id>https://anakin87.github.io/blog/alignment-data-extraction/</id>
        
            <content type="html">&lt;!-- toc --&gt;
&lt;p&gt;New interesting paper on this topic from Google DeepMind: &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2510.18554&quot;&gt;Extracting alignment data in open models&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;alignment-data-extraction&#x2F;paper.png&quot; alt=&quot;Extracting alignment data in open models&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Itâ€™s known that Language Models memorize data that can be extracted via prompting.&lt;&#x2F;p&gt;
&lt;p&gt;In this paper, the authors investigate this aspect:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;using open models, where prompting can be fully customized by the user, including special tokens.&lt;&#x2F;li&gt;
&lt;li&gt;focusing on open-source models like Olmo, where full training data is available.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;outbox-tray-how-do-they-extract-data&quot;&gt;ğŸ“¤ How do they extract data?&lt;&#x2F;h2&gt;
&lt;p&gt;During post-training (like SFT), new tokens such as &amp;lt;|user|&amp;gt; are introduced.&lt;&#x2F;p&gt;
&lt;p&gt;The authors hypothesize prompting the model with these tokens can make it output its alignment data (remember &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2406.08464&quot;&gt;Magpie&lt;&#x2F;a&gt;?).&lt;&#x2F;p&gt;
&lt;p&gt;For example, for SFT, their extraction prompt is &amp;lt;|endoftext|&amp;gt;&amp;lt;|user|&amp;gt;.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;straight-ruler-evaluating-memorization&quot;&gt;ğŸ“ Evaluating memorization&lt;&#x2F;h2&gt;
&lt;p&gt;The authors compare each sampled example with the original data using vector search with embedding similarity.&lt;&#x2F;p&gt;
&lt;p&gt;They find that many outputs are semantically very similar to the original data, even if the exact words differ.&lt;&#x2F;p&gt;
&lt;p&gt;Traditional string-matching algorithms underestimate memorization by 10x.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;repeat-what-about-rl&quot;&gt;ğŸ” What about RL?&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;alignment-data-extraction&#x2F;rl_extraction.png&quot; alt=&quot;RL Extraction&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Surprisingly, the same technique works to extract data from Reinforcement Learning (PPO&#x2F;GRPO) phases.&lt;&#x2F;p&gt;
&lt;p&gt;This is counter-intuitive because the RL objective is not designed to increase sequence likelihoods (unlike SFT).&lt;&#x2F;p&gt;
&lt;p&gt;Practical limitation: in this case, extraction relies on using the initial part of the training prompt, which is not generally public.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;chart-with-upwards-trend-are-the-extracted-data-effective-for-post-training&quot;&gt;ğŸ“ˆ Are the extracted data effective for post-training?&lt;&#x2F;h2&gt;
&lt;p&gt;Both in SFT and RL, the extracted data can be used to fine-tune models to similar performance to the originals.&lt;&#x2F;p&gt;
&lt;p&gt;The authors suggest that model distillation, where a stronger model is used to drive the training of a weaker one, may be a form of indirect training on the original dataset.&lt;&#x2F;p&gt;
</content>
        <summary type="html">Notes on the DeepMind paper</summary>
        </entry><entry xml:lang="en">
        <title>ğŸŒ€ Exploring Environments Hub</title>
        <published>2025-09-05T00:00:00+00:00</published>
        <updated>2025-09-05T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/envs-hub/" type="text/html"/>
        <id>https://anakin87.github.io/blog/envs-hub/</id>
        
            <content type="html">&lt;p&gt;Reinforcement Learning for LLMs is too important to be locked away&lt;&#x2F;p&gt;
&lt;p&gt;When Prime Intellect released the Environments Hub, I couldnâ€™t wait to explore it.&lt;&#x2F;p&gt;
&lt;p&gt;Itâ€™s a space where people can share RL environments: tasks you can use to train LLMs or evaluate Agents.&lt;&#x2F;p&gt;
&lt;p&gt;RL holds great promise to improve LLMs, but if progress stays in the hands of a few closed labs, open models could fall behind.
We would become just users of systems built with tools we canâ€™t access or fully understand.&lt;&#x2F;p&gt;
&lt;p&gt;The Environments Hub and the Verifiers library (William Brown) are part of an effort to change this trajectory and keep
science and experimentation open. ğŸ”¬&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;I explored the Environments Hub and wrote a walkthrough ğŸ“&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;RL + LLMs basics&lt;&#x2F;li&gt;
&lt;li&gt;Environments Hub navigation&lt;&#x2F;li&gt;
&lt;li&gt;Evaluating models&#x2F;Agents&lt;&#x2F;li&gt;
&lt;li&gt;GRPO Training a tiny model on an alphabetical sort task&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Take a look!
&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;blog&#x2F;anakin87&#x2F;environments-hub&quot;&gt;ğŸ“ Blog post&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;envs-hub&#x2F;envs_hub.png&quot; alt=&quot;Environments Hub&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
</content>
        <summary type="html">A practical intro guide to the Environments Hub by Prime Intellect</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ•µï¸ğŸŒ Building Browser Agents</title>
        <published>2025-08-13T00:00:00+00:00</published>
        <updated>2025-08-13T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/browser-agent/" type="text/html"/>
        <id>https://anakin87.github.io/blog/browser-agent/</id>
        
            <content type="html">&lt;div class=&quot;admonition tip&quot;&gt;
    &lt;div class=&quot;admonition-icon admonition-icon-tip&quot;&gt;&lt;&#x2F;div&gt;
    &lt;div class=&quot;admonition-content&quot;&gt;
        &lt;strong class=&quot;admonition-title&quot;&gt;TIP&lt;&#x2F;strong&gt;
        &lt;p&gt;&lt;strong&gt;TL;DR&lt;&#x2F;strong&gt;: I built a Browser Agent from scratch using Haystack, Gemini, and Playwright MCP server ğŸ’«&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;browser_agents&quot;&gt;ğŸ““ Notebook&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;For a short intro, read on!&lt;&#x2F;p&gt;

    &lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;p&gt;&lt;video src=&quot;agent.mp4&quot; controls autoplay loop&gt;&lt;&#x2F;video&gt;&lt;&#x2F;p&gt;
&lt;p&gt;No API? No problem. Browser Agents can use websites like you do: click, type, wait, read.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ¥ In the video, Agent:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Goes to Hugging Face Spaces&lt;&#x2F;li&gt;
&lt;li&gt;Finds FLUX.1 [schnell] space (by Black Forest Labs)&lt;&#x2F;li&gt;
&lt;li&gt;Expands a short prompt (â€œmy holiday on Lake Comoâ€) into a detailed image generation prompt&lt;&#x2F;li&gt;
&lt;li&gt;Waits for the image&lt;&#x2F;li&gt;
&lt;li&gt;Returns the image URL&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;What else can it do?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Great for information gathering and summarization&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ—ï¸ğŸ—ï¸ Compare news websites and create a table of shared stories with links&lt;&#x2F;li&gt;
&lt;li&gt;â–¶ï¸ Find content creator social profiles from YouTube videos&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ›ï¸ Find a productâ€™s price range on Amazon&lt;&#x2F;li&gt;
&lt;li&gt;ğŸš‚ ğŸšŒ Gather public transportation travel optionsâ€¦&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;How is it built?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ—ï¸ deepset Hhaystack â†’ Agent execution logic&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ§  Google Gemini 2.5 Flash â†’ Good and fast LLM with a generous free tier&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ› ï¸ Microsoft Playwright MCP server â†’ Browser automation tools: navigate, click, type, waitâ€¦&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Even without vision capabilities, this setup can get quite far.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Next steps&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Move from notebook to real deployment&lt;&#x2F;li&gt;
&lt;li&gt;Try a local open model&lt;&#x2F;li&gt;
&lt;li&gt;Incorporate vision&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">Learn how to build an Agent that browses the web like a human</summary>
        </entry><entry xml:lang="en">
        <title>Haystack can now see ğŸ‘€</title>
        <published>2025-08-07T00:00:00+00:00</published>
        <updated>2025-08-07T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/haystack-image/" type="text/html"/>
        <id>https://anakin87.github.io/blog/haystack-image/</id>
        
            <content type="html">&lt;!-- toc --&gt;
&lt;p&gt;The 2.16.0 Haystack release adds a long-requested feature: &lt;strong&gt;image support&lt;&#x2F;strong&gt;!&lt;&#x2F;p&gt;
&lt;p&gt;This isnâ€™t just about passing images to an LLM. We built several features to enable practical multimodal use cases.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Whatâ€™s new?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ§  Support for multiple LLM providers: OpenAI, Amazon Bedrock, Google Gemini, Mistral AI, NVIDIA, OpenRouter, Ollama and more&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ›ï¸ Prompt template language to handle structured inputs, including images&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ“„ PDF and image converters&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ§¾ LLM-based extractor to pull text from images&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ” Image embedders using CLIP-like models&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ§© Components to build multimodal RAG pipelines and Agents&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;I had the chance of leading this effort with Sebastian Husch Lee (great collab).&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ““ Below you can find two notebooks to explore the new features:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;multimodal_intro&quot;&gt;Introduction to Multimodal Text Generation&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;tutorials&#x2F;46_multimodal_rag&quot;&gt;Creating Vision+Text RAG Pipelines&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;(ğŸ–¼ï¸ image by Bilge YÃ¼cel)&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;haystack-image&#x2F;image_agent.webp&quot; alt=&quot;Image Agent&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
</content>
        <summary type="html">Image support landed in Haystack! Tutorials inside.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ§ª Mergenetic: evolutionary model merging for all</title>
        <published>2025-07-29T00:00:00+00:00</published>
        <updated>2025-07-29T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/mergenetic/" type="text/html"/>
        <id>https://anakin87.github.io/blog/mergenetic/</id>
        
            <content type="html">&lt;!-- toc --&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;mergenetic&#x2F;mergenetic.gif&quot; alt=&quot;Mergenetic&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;model-merging-basics&quot;&gt;Model merging basics&lt;&#x2F;h2&gt;
&lt;p&gt;The idea of model merging is pretty simple&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;take 2 or more models with different capabilities (letâ€™s say ğŸ‡¯ğŸ‡µ Japanese and ğŸ§® Math) fine-tuned from the same base model&lt;&#x2F;li&gt;
&lt;li&gt;combine their weights using interpolation (SLERP) or other techniques&lt;&#x2F;li&gt;
&lt;li&gt;get a merged model with both capabilities (ğŸ‡¯ğŸ‡µğŸ§®)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;This approach is effective and works on consumer hardware (no GPU needed).&lt;&#x2F;p&gt;
&lt;p&gt;In 2024, model merging got popular, thanks to the Mergekit library (Charles Goddard&#x2F;Arcee AI). Maxime Labonne has released several impressive models and contributed to popularize this paradigm.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;evolutionary-model-merging&quot;&gt;Evolutionary Model Merging&lt;&#x2F;h2&gt;
&lt;p&gt;Despite this success, choosing the models to merge, the techniques and their parameters is a form of black art, relying on intuition and trial and error. ğŸ”®&lt;&#x2F;p&gt;
&lt;p&gt;To fix this, Sakana AI introduced ğŸ§¬ &lt;strong&gt;Evolutionary Model Merge&lt;&#x2F;strong&gt;, a general method using evolutionary algorithms to discover optimal ways to combine open models.&lt;&#x2F;p&gt;
&lt;p&gt;Evolutionary Algorithms are black-box optimization algorithms operating on a population of potential solutions by evolving them through generations with operators such as selection, mutation, recombination, and crossover. The fitness function is crucial, as it evaluates the quality of each solution, guiding the selection process by favoring higher-scoring solutions for reproduction.&lt;&#x2F;p&gt;
&lt;p&gt;Among the models Sakana AI released to demonstrate this technique is EvoLLM-JP, an LLM with Japanese and math capabilities, resulting from merging multiple models.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ’¸ Evolutionary Model Merging has one major problem: repeatedly evaluating the fitness function on candidate models is expensive. It requires these models to generate completions on a held-out validation set.&lt;&#x2F;p&gt;
&lt;p&gt;Reproducing EvoLLM-JPâ€™s evolutionary merging with an NVIDIA 4090 (24GB VRAM) would take 2 months ğŸ¤¯&lt;&#x2F;p&gt;
&lt;h2 id=&quot;merge3-and-mergenetic-evolutionary-model-merging-for-all&quot;&gt;MERGE3 and Mergenetic: evolutionary model merging for all&lt;&#x2F;h2&gt;
&lt;p&gt;ğŸª„ The researchers of GLADIA first invented a technique called MERGE3 that extracts a reduced dataset for evaluation, estimates model abilities using Item Response Theory (IRT), and evolves optimal merges via IRT-based performance estimators.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;MERGE3&lt;&#x2F;strong&gt; achieves similar results to EvoLLM-JP, while reducing fitness computation costs 50Ã—.
Evolving such a model can require hours instead of months!&lt;&#x2F;p&gt;
&lt;p&gt;GLADIA researchers are now releasing ğŸ§ª &lt;strong&gt;Mergenetic&lt;&#x2F;strong&gt;, a library for Evolutionary Model Merging&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;â­ User friendly and research oriented&lt;&#x2F;li&gt;
&lt;li&gt;â­ Rich in merging techniques and evolutionary algorithms&lt;&#x2F;li&gt;
&lt;li&gt;â­ Multi-objective optimization&lt;&#x2F;li&gt;
&lt;li&gt;â­ Accelerated evolution through subsampling and approximation (with techniques like MERGE3)&lt;&#x2F;li&gt;
&lt;li&gt;â­ integrates with LM Eval Harness and supports custom fitness functions&lt;&#x2F;li&gt;
&lt;li&gt;â­ offers a Python API, a CLI and a GUI&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;I recommend giving it a try to evolve your models affordably.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ‘¥ Authors: Adrian Robert Minut, Tommaso Mencattini, Andrea Santilli, Donato Crisostomi, Emanuele RodolÃ &lt;&#x2F;p&gt;
&lt;h2 id=&quot;books-resources&quot;&gt;ğŸ“š Resources&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;tommasomncttn&#x2F;mergenetic&quot;&gt;Mergenetic library&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2505.11427&quot;&gt;Mergenetic paper&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2502.10436&quot;&gt;MERGE3 paper&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Sakana AI - Evolutionary Model Merging&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s42256-024-00975-8&quot;&gt;Paper&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;sakana.ai&#x2F;evolutionary-model-merge&#x2F;&quot;&gt;Blog post&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">Intro to a recent libray&#x2F;papers on evolutionary model merging</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ›¡ï¸ AI Guardrails with Open Language Models</title>
        <published>2025-07-03T00:00:00+00:00</published>
        <updated>2025-07-03T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/ai-guardrails/" type="text/html"/>
        <id>https://anakin87.github.io/blog/ai-guardrails/</id>
        
            <content type="html">&lt;div class=&quot;admonition tip&quot;&gt;
    &lt;div class=&quot;admonition-icon admonition-icon-tip&quot;&gt;&lt;&#x2F;div&gt;
    &lt;div class=&quot;admonition-content&quot;&gt;
        &lt;strong class=&quot;admonition-title&quot;&gt;TIP&lt;&#x2F;strong&gt;
        &lt;p&gt;Here is a tutorial on how to implement Content Moderation and Safety with Open Language Models.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;safety_moderation_open_lms&quot;&gt;ğŸ““ Notebook&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;For a short intro, read on!&lt;&#x2F;p&gt;

    &lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;ai-guardrails&#x2F;ai-guardrails.png&quot; alt=&quot;AI Guardrails with Open Language Models&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;How do you ensure your AI application is safe from harmful or inappropriate user inputs?&lt;&#x2F;p&gt;
&lt;p&gt;This is a core requirement for real-world AI deployments. Luckily, several open Language Models are built specifically for safety moderation.&lt;&#x2F;p&gt;
&lt;p&gt;Iâ€™ve been exploring them and put together a hands-on tutorial using the Haystack framework to build your own AI guardrails.&lt;&#x2F;p&gt;
&lt;p&gt;In the &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;safety_moderation_open_lms&quot;&gt;notebook&lt;&#x2F;a&gt;, youâ€™ll learn how to use and customize:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Meta Llama Guard (via Hugging Face API)&lt;&#x2F;li&gt;
&lt;li&gt;Google ShieldGemma (via Ollama)&lt;&#x2F;li&gt;
&lt;li&gt;IBM Granite Guardian (via Ollama), which can also evaluate RAG specific risk dimensions&lt;&#x2F;li&gt;
&lt;li&gt;NVIDIA NemoGuard models family, including a model for topic control&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Youâ€™ll also see how to integrate content moderation into a ğŸ” RAG pipeline.&lt;&#x2F;p&gt;
</content>
        <summary type="html">Learn how to implement Content Moderation and Safety with Open Language Models</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ§° Free up space on the Hugging Face Hub with `super_squash_history` ğŸ§¹</title>
        <published>2025-06-30T00:00:00+00:00</published>
        <updated>2025-06-30T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/hf-super-squash-history/" type="text/html"/>
        <id>https://anakin87.github.io/blog/hf-super-squash-history/</id>
        
            <content type="html">&lt;p&gt;The Hugging Face Hub is the home of machine learning models and datasets.
They provide free storage for public repos.
For private repositories, there are limits: 100 GB for free users and 1 TB for PRO users.&lt;&#x2F;p&gt;
&lt;p&gt;This weekend I did some cleanup on my private repos&lt;&#x2F;p&gt;
&lt;p&gt;I went from 1.58 TB down to 1 GB. ğŸ˜…&lt;&#x2F;p&gt;
&lt;p&gt;Besides deleting old, unused models, the main tool I used was a lesser-known command:
&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;docs&#x2F;hub&#x2F;en&#x2F;storage-limits#super-squash-your-repository-using-the-api&quot;&gt;&lt;code&gt;super_squash_history&lt;&#x2F;code&gt;&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;When you train a model, you often push multiple checkpoints to the Hub.&lt;&#x2F;p&gt;
&lt;p&gt;Each checkpoint = a commit.&lt;&#x2F;p&gt;
&lt;p&gt;A 2.6B model in BF16 is ~5 GB.&lt;&#x2F;p&gt;
&lt;p&gt;So 10 checkpoints = 50 GB. That adds up fast.&lt;&#x2F;p&gt;
&lt;p&gt;While full commit history can be useful for rollbacks, itâ€™s often unnecessary for older experiments where only the final model matters.&lt;&#x2F;p&gt;
&lt;p&gt;In these cases, you can use super_squash_history: it reduces your entire repo history to a single commit.&lt;&#x2F;p&gt;
&lt;p&gt;âš ï¸ super_squash_history is a non-revertible operation. Once squashed, the commit history cannot be retrieved.&lt;&#x2F;p&gt;
&lt;p&gt;Hope this is useful to others.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;hf-super-squash-history&#x2F;hf_super_squash_history.jpeg&quot; alt=&quot;hf_super_squash_history&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
</content>
        </entry><entry xml:lang="en">
        <title>ğŸ My adventure at PyCon Italy 2025</title>
        <published>2025-06-24T00:00:00+00:00</published>
        <updated>2025-06-24T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/pyconita25/" type="text/html"/>
        <id>https://anakin87.github.io/blog/pyconita25/</id>
        
            <content type="html">&lt;p&gt;3 weeks ago I had a great time at PyCon Italia!&lt;&#x2F;p&gt;
&lt;p&gt;As always, the conference was full of sound technical content.&lt;&#x2F;p&gt;
&lt;p&gt;But above all, I came home with a sense of belonging and community.
I enjoyed the friendly and welcoming environment we participants found and contributed to.
ğŸ™ Thanks to the organizers and volunteers who made it possible.&lt;&#x2F;p&gt;
&lt;p&gt;I loved talking with old and new friends: Luca Corbucci, Michele Pangrazzi, Sara Callaioli, Tommaso Radicioni, David Berenstein, Simona Mazzarino, Luca Gilli, Edoardo Abati, and many others.&lt;&#x2F;p&gt;
&lt;p&gt;I also gave a talk on Fine-tuning Small Language Models.
I covered:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ‘£ Common techniques (SFT and DPO)&lt;&#x2F;li&gt;
&lt;li&gt;âš™ï¸ğŸ’° Memory-efficient training (QLoRA, Spectrum)&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ§© Model merging&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ§ ğŸ’­ Reasoning models and GRPO&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ“± Running small Language Models on a phone&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;Post-Training Small Language Models: the adventures of a practitioner&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ¿ &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=OrE-ocSltqg&quot;&gt;Video&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ§‘â€ğŸ« &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;anakin87&#x2F;posttraining-small-language-models-talk&quot;&gt;Slides and resources&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;pyconita25&#x2F;pyconita25.jpeg&quot; alt=&quot;My talk at PyCon Italy 2025&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;pyconita25&#x2F;pyconita25_2.jpeg&quot; alt=&quot;PyCon Italy 2025&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
</content>
        </entry><entry xml:lang="en">
        <title>Supervised Fine-Tuning vs Preference Alignment: Who does what in Post-Training?</title>
        <published>2025-06-05T00:00:00+00:00</published>
        <updated>2025-06-05T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/sft-vs-pa/" type="text/html"/>
        <id>https://anakin87.github.io/blog/sft-vs-pa/</id>
        
            <content type="html">&lt;p&gt;After pretraining a Language Model, you get a base model, powerful and rich in linguistic knowledge, but with several hidden capabilities.&lt;&#x2F;p&gt;
&lt;p&gt;For example, it is good at completing text but does not reliably follow instructions. âŒ&lt;&#x2F;p&gt;
&lt;p&gt;Before using the model in applications, you need to apply ğ—£ğ—¼ğ˜€ğ˜-ğ—§ğ—¿ğ—®ğ—¶ğ—»ğ—¶ğ—»ğ—´.&lt;&#x2F;p&gt;
&lt;p&gt;This involves several steps and techniques, including Supervised Fine-Tuning (&lt;strong&gt;SFT&lt;&#x2F;strong&gt;), Preference Alignment (with &lt;strong&gt;PPO&lt;&#x2F;strong&gt; or &lt;strong&gt;DPO&lt;&#x2F;strong&gt;), Reinforcement Learning with Verifiable Rewards (often using &lt;strong&gt;GRPO&lt;&#x2F;strong&gt;).&lt;&#x2F;p&gt;
&lt;p&gt;If youâ€™ve looked into Post-Training, youâ€™ve probably wondered (like I did):&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;What does each of these techniques do to the final model? ğŸ¤”&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;One great resource on this is the article ğŸ§¶ &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;mohit-raghavendra.notion.site&#x2F;Disentangling-Post-training-performance-elicitation-from-data-1a5db7f2a34480e18010d689a1f46f74&quot;&gt;â€œDisentangling Post-training performance elicitation from dataâ€ by Mohit Raghavendra&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ“ TL;DR from the article&lt;&#x2F;p&gt;
&lt;p&gt;Base Models are bad at reasoning in the response space.
A small amount of SFT initially aligns the modelâ€™s response distribution to the required multistep reasoning style - it imparts it the ability to do reasoning, even if it isnâ€™t necessarily always correct.
Further SFT is useful, but the data curation is expensive, when compared to marginal improvements gains.
Preference finetuning on the other has a weaker per-sample reward signal, which is why many models resort to large-scale RL tuning. However, starting from an SFT checkpoint improves RL sample efficiency, by using the (weaker) reward signal to improve on the reasoning accuracy rather than the style, since it doesnâ€™t have to stray too far from the response model distribution and incur a KL penalty.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;sft-vs-pa&#x2F;sft_vs_pa.jpeg&quot; alt=&quot;Disentangling Post-training performance elicitation from data&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
</content>
        </entry><entry xml:lang="en">
        <title>ğŸ“ GRPO: what I&#x27;ve learned</title>
        <published>2025-05-15T00:00:00+00:00</published>
        <updated>2025-05-15T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/grpo-what-i-learned/" type="text/html"/>
        <id>https://anakin87.github.io/blog/grpo-what-i-learned/</id>
        
            <content type="html">&lt;!-- toc --&gt;
&lt;p&gt;&lt;a href=&quot;..&#x2F;qwen-scheduler-grpo&quot;&gt;I recently experimented with GRPO&lt;&#x2F;a&gt; and I want to share what Iâ€™ve learned.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;grpo-is-great-for-verifiable-tasks&quot;&gt;ğ—šğ—¥ğ—£ğ—¢ ğ—¶ğ˜€ ğ—´ğ—¿ğ—²ğ—®ğ˜ ğ—³ğ—¼ğ—¿ ğ˜ƒğ—²ğ—¿ğ—¶ğ—³ğ—¶ğ—®ğ—¯ğ—¹ğ—² ğ˜ğ—®ğ˜€ğ—¸ğ˜€&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;grpo-what-i-learned&#x2F;raschka_grpo.jpeg&quot; alt=&quot;GRPO&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;It simplifies the typical Reinforcement Learning setup (used, for example, in PPO):&lt;&#x2F;p&gt;
&lt;p&gt;âœ… No value model&lt;&#x2F;p&gt;
&lt;p&gt;âœ… Reward model often replaced by deterministic reward functions (Reinforcement Learning with Verifiable Rewards).&lt;&#x2F;p&gt;
&lt;p&gt;Since only prompts are required for your dataset (no completions), data collection becomes much easier and cheaper than in Supervised Fine-Tuning.&lt;&#x2F;p&gt;
&lt;p&gt;For a solid introduction, read the &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;sebastianraschka.com&#x2F;blog&#x2F;2025&#x2F;the-state-of-reinforcement-learning-for-llm-reasoning.html&quot;&gt;âœï¸ recent article by Sebastian Raschka, PhD&lt;&#x2F;a&gt;. Image credit: same author.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;when-to-use-grpo&quot;&gt;ğ—ªğ—µğ—²ğ—» ğ˜ğ—¼ ğ˜‚ğ˜€ğ—² ğ—šğ—¥ğ—£ğ—¢?&lt;&#x2F;h2&gt;
&lt;p&gt;Use GRPO if:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;You can clearly explain the task to the model in a prompt.&lt;&#x2F;li&gt;
&lt;li&gt;You can figure out how to reward good outputs.&lt;&#x2F;li&gt;
&lt;li&gt;You can sometimes identify encouraging behaviors in the model to train.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;elicitation&quot;&gt;ğ—˜ğ—¹ğ—¶ğ—°ğ—¶ğ˜ğ—®ğ˜ğ—¶ğ—¼ğ—»&lt;&#x2F;h2&gt;
&lt;p&gt;Using GRPO and similar algorithms is more about eliciting desired behaviors from the trained model than teaching completely new stuff to it.&lt;&#x2F;p&gt;
&lt;p&gt;If you need fundamentally new skills, Supervised Fine-Tuning (and distillation) might be more effective .&lt;&#x2F;p&gt;
&lt;p&gt;(&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2504.13837&quot;&gt;ğŸ“– Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?&lt;&#x2F;a&gt;).&lt;&#x2F;p&gt;
&lt;p&gt;If you are curious about these topics, follow Nathan Lambert and the &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.interconnects.ai&#x2F;&quot;&gt;âœï¸ Interconnects AI blog&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;base-model-matters&quot;&gt;ğ—•ğ—®ğ˜€ğ—² ğ—ºğ—¼ğ—±ğ—²ğ—¹ ğ—ºğ—®ğ˜ğ˜ğ—²ğ—¿ğ˜€&lt;&#x2F;h2&gt;
&lt;p&gt;If the base model never shows promising behaviors on the task during sampling, GRPO likely wonâ€™t help.
You probably need a bigger or better base model first.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;reward-functions-design-is-crucial&quot;&gt;ğ—¥ğ—²ğ˜„ğ—®ğ—¿ğ—± ğ—³ğ˜‚ğ—»ğ—°ğ˜ğ—¶ğ—¼ğ—»ğ˜€ ğ—±ğ—²ğ˜€ğ—¶ğ—´ğ—» ğ—¶ğ˜€ ğ—°ğ—¿ğ˜‚ğ—°ğ—¶ğ—®ğ—¹&lt;&#x2F;h2&gt;
&lt;p&gt;Your rewards should capture your goal, provide a learnable signal (an encouragement to the model), and be robust.&lt;&#x2F;p&gt;
&lt;p&gt;If they are not robust, you may experiment reward hacking: the model finds shortcuts to maximize the reward without
actually solving the problem you had in mind. Nice and frustrating ğŸ˜…&lt;&#x2F;p&gt;
&lt;h2 id=&quot;aha-moment-might-be-over-hyped&quot;&gt;â€œğ—”ğ—µğ—® ğ—ºğ—¼ğ—ºğ—²ğ—»ğ˜â€ ğ—ºğ—¶ğ—´ğ—µğ˜ ğ—¯ğ—² ğ—¼ğ˜ƒğ—²ğ—¿-ğ—µğ˜†ğ—½ğ—²ğ—±&lt;&#x2F;h2&gt;
&lt;p&gt;In the DeepSeek-R1 paper, the authors showed that during GRPO â€œthe model learns to rethink using an anthropomorphic toneâ€.&lt;&#x2F;p&gt;
&lt;p&gt;A miracle? Recent studies have cast some doubt on this. (&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;oatllm.notion.site&#x2F;oat-zero&quot;&gt;ğŸ“– There May Not be Aha Moment in R1-Zero-like Training&lt;&#x2F;a&gt;; &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2503.20783&quot;&gt;ğŸ“– Understanding R1-Zero-Like Training: A Critical Perspective&lt;&#x2F;a&gt;)&lt;&#x2F;p&gt;
&lt;p&gt;They found that similar â€œaha momentsâ€ could be found in the base models before any GRPO training even started.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;unsloth-great-for-saving-gpu-but-beware&quot;&gt;ğ—¨ğ—»ğ˜€ğ—¹ğ—¼ğ˜ğ—µ: ğ—´ğ—¿ğ—²ğ—®ğ˜ ğ—³ğ—¼ğ—¿ ğ˜€ğ—®ğ˜ƒğ—¶ğ—»ğ—´ ğ—šğ—£ğ—¨, ğ—¯ğ˜‚ğ˜ ğ—¯ğ—²ğ˜„ğ—®ğ—¿ğ—²&lt;&#x2F;h2&gt;
&lt;p&gt;Unsloth is one of the most popular libraries for fine-tuning Language Models, especially if you donâ€™t have much GPU.&lt;&#x2F;p&gt;
&lt;p&gt;These guys do impressive things in terms of GPU efficiency.
However, it currently patches many other libraries and comes with some tricky bugs. ğŸ›&lt;&#x2F;p&gt;
&lt;p&gt;If you have enough VRAM, TRL is more stable.&lt;&#x2F;p&gt;
</content>
        </entry><entry xml:lang="en">
        <title>ğŸ’ I&#x27;m one of the winners of the Gemma fine-tuning competition! ğŸ†</title>
        <published>2025-05-06T00:00:00+00:00</published>
        <updated>2025-05-06T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/gemma-competition-win/" type="text/html"/>
        <id>https://anakin87.github.io/blog/gemma-competition-win/</id>
        
            <content type="html">&lt;div class=&quot;admonition tip&quot;&gt;
    &lt;div class=&quot;admonition-icon admonition-icon-tip&quot;&gt;&lt;&#x2F;div&gt;
    &lt;div class=&quot;admonition-content&quot;&gt;
        &lt;strong class=&quot;admonition-title&quot;&gt;TIP&lt;&#x2F;strong&gt;
        &lt;p&gt;Resources:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ““ &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.kaggle.com&#x2F;code&#x2F;anakin87&#x2F;post-training-gemma-for-italian-and-beyond&quot;&gt;Kaggle notebook&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ¤— &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;collections&#x2F;anakin87&#x2F;gemma-neogenesis-67824b7bf13ac9cfe091fe2e&quot;&gt;Hugging Face collection&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ¬ &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=RFPp4ycQ0fA&quot;&gt;Project talk @ Pi School&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;

    &lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;gemma-competition-win&#x2F;gemma_competition_win.jpeg&quot; alt=&quot;Iâ€™m one of the winners of the Gemma fine-tuning competition!&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Unlock global communication with Gemma, a Kaggle competition organized by Google, invited participants to fine-tune Gemma 2 for a specific language or cultural context.&lt;&#x2F;p&gt;
&lt;p&gt;I prepared a cheap recipe to improve Gemma on a single language, combining:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Synthetic data generation (with LLM-as-a-judge)&lt;&#x2F;li&gt;
&lt;li&gt;Supervised Fine-Tuning&lt;&#x2F;li&gt;
&lt;li&gt;Direct Preference Optimization&lt;&#x2F;li&gt;
&lt;li&gt;Efficient training with Spectrum.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;I applied it to ğŸ‡®ğŸ‡¹ Italian, releasing new datasets and models.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ™ Thanks to everyone who helped me:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Daniel Vila Suero - for his suggestions about datasets&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Maziyar PANAHI - for tips on synthetic data generation via Hugging Face API&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Maxime Labonne - for datasets and constant educational work&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Edoardo Federici - for good Italian datasets&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Alessandro Ercolani and Samuele Colombo (mii-llm) - for running the Italian Open LLM Leaderboard&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Michele Montebovi - for being an example in crafting and sharing Italian models&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;The folks at Hugging Face (Quentin GallouÃ©dec, Lewis Tunstall, â€¦) - for maintaining TRL, a great LLM training library&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Eric Hartford, Lucas Atkins, Fernando Fernandes Neto, and David Golchinfar - for creating Spectrum, a clever technique for module selection and memory-efficient training.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Thanks everyone, itâ€™s been fun!&lt;&#x2F;p&gt;
</content>
        </entry><entry xml:lang="en">
        <title>ğŸ‘‘ ğŸ—“ï¸ I trained a Language Model to schedule events with GRPO!</title>
        <published>2025-04-29T00:00:00+00:00</published>
        <updated>2025-04-29T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/qwen-scheduler-grpo/" type="text/html"/>
        <id>https://anakin87.github.io/blog/qwen-scheduler-grpo/</id>
        
            <content type="html">&lt;div class=&quot;admonition tip&quot;&gt;
    &lt;div class=&quot;admonition-icon admonition-icon-tip&quot;&gt;&lt;&#x2F;div&gt;
    &lt;div class=&quot;admonition-content&quot;&gt;
        &lt;strong class=&quot;admonition-title&quot;&gt;TIP&lt;&#x2F;strong&gt;
        &lt;p&gt;Iâ€™ve published an &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;blog&#x2F;anakin87&#x2F;qwen-scheduler-grpo&quot;&gt;extensive post on this topic on the ğŸ¤— Hugging Face blog&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;All code is available on &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;anakin87&#x2F;qwen-scheduler-grpo&quot;&gt;GitHub&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;For a short intro, read on!&lt;&#x2F;p&gt;

    &lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;!-- toc --&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;qwen-scheduler-grpo&#x2F;qwen_scheduler_grpo.gif&quot; alt=&quot;Qwen Scheduler GRPO&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I experimented with GRPO lately.&lt;&#x2F;p&gt;
&lt;p&gt;I am fascinated by models learning from prompts and rewards - no example answers needed like in Supervised Fine-Tuning.&lt;&#x2F;p&gt;
&lt;p&gt;After the DeepSeek boom, everyone is trying GRPO with GSM8K or the Countdown Gameâ€¦&lt;&#x2F;p&gt;
&lt;p&gt;I wanted a different challenge, like teaching a model to create a schedule from a list of events and priorities.&lt;&#x2F;p&gt;
&lt;p&gt;Choosing an original problem forced me to:&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ¤” Think about the problem setting&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ§¬ Generate data&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ¤ Choose the right base model&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ† Design reward functions (and experiencing reward hacking)&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ”„ Run multiple rounds of training, hoping that my model would learn something.&lt;&#x2F;p&gt;
&lt;p&gt;A fun and rewarding ğŸ˜„ experience.&lt;&#x2F;p&gt;
&lt;p&gt;I learned a lot of things, that I want to share with you.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;âœï¸ &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;blog&#x2F;anakin87&#x2F;qwen-scheduler-grpo&quot;&gt;Blog post&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ’» &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;anakin87&#x2F;qwen-scheduler-grpo&quot;&gt;Code&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ¤— &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;collections&#x2F;anakin87&#x2F;qwen-scheduler-grpo-680bcc583e817390525a8837&quot;&gt;Hugging Face collection&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">An experiment on using GRPO on a new task + all what I learned</summary>
        </entry><entry xml:lang="en">
        <title>Minerva: the Italian LLM ğŸ§ ğŸ‡®ğŸ‡¹</title>
        <published>2025-02-17T00:00:00+00:00</published>
        <updated>2025-02-17T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/minerva/" type="text/html"/>
        <id>https://anakin87.github.io/blog/minerva/</id>
        
            <content type="html">&lt;p&gt;I had the pleasure of joining Luca Corbucci in a special interview.&lt;&#x2F;p&gt;
&lt;p&gt;With Simone Conia we explored Minerva, a family of LLM trained from scratch on the Italian language by Sapienza NLP researchers.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ™ï¸ &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;pointerpodcast.it&#x2F;p&#x2F;pointer243-minerva-lllm-italiano-con-simone-conia&#x2F;&quot;&gt;Pointer Podcast episode - in Italian&lt;&#x2F;a&gt; ğŸ™ï¸&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;minerva&#x2F;minerva_podcast.png&quot; alt=&quot;Minerva podcast&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;If you are passionate about language models, this interview is not to be missed:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;How to train a Language Model&lt;&#x2F;li&gt;
&lt;li&gt;The selection of data and the creation of a specific tokenizer&lt;&#x2F;li&gt;
&lt;li&gt;Pre-training&lt;&#x2F;li&gt;
&lt;li&gt;Phases of fine-tuning and Online Direct Preference Optimization&lt;&#x2F;li&gt;
&lt;li&gt;Model evaluation&lt;&#x2F;li&gt;
&lt;li&gt;Ethical aspects and environmental impact&lt;&#x2F;li&gt;
&lt;li&gt;The future of Minerva.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Thank you for the opportunity!&lt;&#x2F;p&gt;
</content>
        <summary type="html">Interview with Simone Conia, one of the creators of Minerva, LLM trained from scratch in Italian.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ¯ Selective fine-tuning of Language Models with Spectrum</title>
        <published>2025-02-04T00:00:00+00:00</published>
        <updated>2025-02-04T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/spectrum/" type="text/html"/>
        <id>https://anakin87.github.io/blog/spectrum/</id>
        
            <content type="html">&lt;div class=&quot;admonition tip&quot;&gt;
    &lt;div class=&quot;admonition-icon admonition-icon-tip&quot;&gt;&lt;&#x2F;div&gt;
    &lt;div class=&quot;admonition-content&quot;&gt;
        &lt;strong class=&quot;admonition-title&quot;&gt;TIP&lt;&#x2F;strong&gt;
        &lt;p&gt;Iâ€™ve published an &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;blog&#x2F;anakin87&#x2F;spectrum&quot;&gt;extensive tutorial on Spectrum on the ğŸ¤— Hugging Face blog&lt;&#x2F;a&gt;.
For a short intro, read on!&lt;&#x2F;p&gt;

    &lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;!-- toc --&gt;
&lt;h2 id=&quot;qlora&quot;&gt;QLoRA&lt;&#x2F;h2&gt;
&lt;p&gt;QLoRA revolutionized LLM fine-tuning in May 2023.&lt;&#x2F;p&gt;
&lt;p&gt;This method trains Low Rank Adapters on top of a quantized Language Model, drastically reducing GPU memory usage.&lt;&#x2F;p&gt;
&lt;p&gt;QLoRA made fine-tuning accessible on consumer hardware and became incredibly popular.&lt;&#x2F;p&gt;
&lt;p&gt;However, &lt;strong&gt;QLoRA has some limitations&lt;&#x2F;strong&gt; â›”&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Lower performance compared to full fine-tuning.&lt;&#x2F;li&gt;
&lt;li&gt;Highly sensitive to hyperparameters (rank and alpha).&lt;&#x2F;li&gt;
&lt;li&gt;LoRA-trained models introduce â€œintruderâ€ dimensions, potentially misaligning them with pre-training distribution and limiting adaptability to new tasks (see &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2410.21228&quot;&gt;LoRA vs Full Fine-tuning: An Illusion of Equivalence&lt;&#x2F;a&gt;).&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Looking for simplicity, full performance, and memory savings?&lt;&#x2F;p&gt;
&lt;h2 id=&quot;spectrum&quot;&gt;Spectrum&lt;&#x2F;h2&gt;
&lt;p&gt;ğŸ¯ &lt;strong&gt;Spectrum&lt;&#x2F;strong&gt; is an interesting alternative.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;github.com&#x2F;anakin87&#x2F;gemma-neogenesis&#x2F;blob&#x2F;main&#x2F;images&#x2F;spectrum_diagram.png?raw=true&quot; alt=&quot;Spectrum diagram&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ”¬ Analyzes weight matrices for all layers in a Language Model and calculates a Signal to Noise Ratio (SNR) for each one.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ”¹ Uses Random Matrix Theory (Marchenko-Pastur distribution) to distinguish signal from noise.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ”¹ Based on a chosen percentage (say, 25%), Spectrum selects the most informative layers of each type (e.g., mlp.down_proj, self_attn.o_proj, etc.).&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ”¹ You can then â„ï¸ freeze the entire model except for these selected layers ğŸ”¥ and focus your fine-tuning on them.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;spectrum-evaluation-and-results&quot;&gt;Spectrum: evaluation and results&lt;&#x2F;h3&gt;
&lt;p&gt;In the paper, the authors fine-tuned Llama-3-8B and Mistral-7B-v0.1 on the airoboros-3.1 dataset using Spectrum-50 and Spectrum-25, comparing results with full fine-tuning and QLoRA.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ“Š Spectrum is competitive with full fine-tuning and outperforms QLoRA on benchmark performance.&lt;&#x2F;p&gt;
&lt;p&gt;âš¡ More memory-efficient than QLoRA in distributed training. QLoRA uses less memory on a single GPU.&lt;&#x2F;p&gt;
&lt;p&gt;Several impressive Language Models have been trained using Spectrum, including Dolphin models, Llama 3.1 Storm, numerous models by VAGO Solutionsâ€¦&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ’ Spectrum helps mitigate catastrophic forgettingâ€”as Fernando (one of the authors) puts it:
â€œTraining the layers with highest SNR implies training matrices with lower compression ratio. These are more prone to learn something new without forgetting. Learn more, forget less.â€&lt;&#x2F;p&gt;
&lt;h3 id=&quot;raising-hand-male-sign-my-experience-with-spectrum&quot;&gt;ğŸ™‹â€â™‚ï¸ My experience with Spectrum&lt;&#x2F;h3&gt;
&lt;p&gt;Since my first experiments with this method, Iâ€™ve found it both effective and enjoyable to work withâ€”I quickly became a fan.
I used it to create Italian versions of Phi 3.5 Mini and Gemma 2.&lt;&#x2F;p&gt;
&lt;p&gt;Spectrum is usable out of the box with the Axolotl fine-tuning framework,
but with a small effort, you can make it work with Hugging Face TRL.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ™ Great work by Eric Hartford, Lucas Atkins, Fernando Fernandes Neto, and David Golchinfar (Arcee AI + VAGO Solutions)!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;books-resources&quot;&gt;ğŸ“š Resources&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;blog&#x2F;anakin87&#x2F;spectrum&quot;&gt;Spectrum tutorial&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.kaggle.com&#x2F;code&#x2F;anakin87&#x2F;post-training-gemma-for-italian-and-beyond&quot;&gt;Post-Training Gemma for Italian and beyond&lt;&#x2F;a&gt; (makes extensive use of Spectrum)&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2406.06623&quot;&gt;Spectrum paper&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;cognitivecomputations&#x2F;spectrum&quot;&gt;Spectrum code&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">An introduction to Spectrum, a method for selection of model parameters for efficient training.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ§¬ Use Language Model responses to improve it</title>
        <published>2025-01-28T00:00:00+00:00</published>
        <updated>2025-01-28T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/dpo-onpolicy/" type="text/html"/>
        <id>https://anakin87.github.io/blog/dpo-onpolicy/</id>
        
            <content type="html">&lt;div class=&quot;admonition tip&quot;&gt;
    &lt;div class=&quot;admonition-icon admonition-icon-tip&quot;&gt;&lt;&#x2F;div&gt;
    &lt;div class=&quot;admonition-content&quot;&gt;
        &lt;strong class=&quot;admonition-title&quot;&gt;TIP&lt;&#x2F;strong&gt;
        &lt;p&gt;ğŸ‘¨â€ğŸ’» You can find the code on &lt;strong&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.kaggle.com&#x2F;code&#x2F;anakin87&#x2F;post-training-gemma-for-italian-and-beyond&quot;&gt;this Kaggle notebook&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;.
For a short intro, read on!&lt;&#x2F;p&gt;

    &lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;!-- toc --&gt;
&lt;h2 id=&quot;intro-to-dpo&quot;&gt;Intro to DPO&lt;&#x2F;h2&gt;
&lt;p&gt;Preference tuning is a common step in fine-tuning Language Models,
where the model learns to favor desirable responses over less helpful ones.&lt;&#x2F;p&gt;
&lt;p&gt;A popular approach for this is &lt;strong&gt;Direct Preference Optimization (DPO)&lt;&#x2F;strong&gt;.
It trains models on examples like:
&lt;strong&gt;Prompt; chosen response; rejected response&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Compared to other Preference Tuning methods like Reinforcement Learning from Human Feedback (e.g. PPO),
DPO has several advantages:&lt;&#x2F;p&gt;
&lt;p&gt;âœ… Simplicity&lt;&#x2F;p&gt;
&lt;p&gt;âœ… Stability&lt;&#x2F;p&gt;
&lt;p&gt;âœ… Memory efficiency&lt;&#x2F;p&gt;
&lt;p&gt;DPO is popular among practitioners, and not only: even &lt;strong&gt;Llama-3&lt;&#x2F;strong&gt; was trained with DPO.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;dpo-limitations&quot;&gt;DPO limitations&lt;&#x2F;h2&gt;
&lt;p&gt;âŒ Research has shown that DPO often falls short of PPO in terms of model performance (see &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2404.10719&quot;&gt;Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study&lt;&#x2F;a&gt;).&lt;&#x2F;p&gt;
&lt;p&gt;One common critique is that DPO often uses only off-policy dataâ€”data generated by models other than the one being trained.
This can introduce distribution shifts during training, which may impact performance.&lt;&#x2F;p&gt;
&lt;p&gt;However, this isnâ€™t a limitation of DPO itself, but just a common practice.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ’ We can overcome this limit by using on-policy data: data generated by the model being trained.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;how-to-create-an-on-policy-dataset-for-dpo&quot;&gt;How to create an on-policy dataset for DPO&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;github.com&#x2F;anakin87&#x2F;gemma-neogenesis&#x2F;blob&#x2F;main&#x2F;images&#x2F;onpolicy_data_generation.png?raw=true&quot; alt=&quot;On-policy data generation&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;Select a source of prompts (ideally different from data used to previously train the model).&lt;&#x2F;li&gt;
&lt;li&gt;Sample the original model to generate 2 (or more) responses ğŸ².&lt;&#x2F;li&gt;
&lt;li&gt;Evaluate and rank the responses with a Reward Model or LLM as a Judge ğŸ§‘â€âš–ï¸.&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;In fact, the &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2411.15124&quot;&gt;TÃœLU 3 technical report&lt;&#x2F;a&gt; shows that combining off-policy + on-policy data gives better performance compared to off-policy data alone.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;raising-hand-male-sign-personal-experience&quot;&gt;ğŸ™‹â€â™‚ï¸ Personal Experience&lt;&#x2F;h3&gt;
&lt;p&gt;In my recent Gemma competition, I followed this approach and observed improvements in my modelâ€™s performance.&lt;&#x2F;p&gt;
&lt;p&gt;I did with a simple setup and limited resources:
ğŸ› ï¸ Kaggle (free GPU) + vLLM (efficient model sampling) + Hugging Face API (calling the Judge)&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ‘¨â€ğŸ’» &lt;strong&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.kaggle.com&#x2F;code&#x2F;anakin87&#x2F;post-training-gemma-for-italian-and-beyond&quot;&gt;Code&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
</content>
        <summary type="html">Why you should use on-policy data for DPO and how to do that simply.</summary>
        </entry><entry xml:lang="en">
        <title>New Italian Preference Dataset ğŸ‡®ğŸ‡¹ğŸ‘ğŸ‘</title>
        <published>2025-01-22T00:00:00+00:00</published>
        <updated>2025-01-22T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/evol-dpo-ita-reranked/" type="text/html"/>
        <id>https://anakin87.github.io/blog/evol-dpo-ita-reranked/</id>
        
            <content type="html">&lt;p&gt;The most common fine-tuning workflow of a Language Models involves two steps:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Supervised Fine-Tuning (SFT)&lt;&#x2F;em&gt;: train the model to follow instructions.
Datasets for this step include instruction-response pairs.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Preference Tuning&lt;&#x2F;em&gt;: align the model with human&#x2F;AI preferences by training it to favor high-quality responses over poor ones. A simple and effective algorithm to do that is &lt;strong&gt;Direct Preference Optimization (DPO)&lt;&#x2F;strong&gt;.
Data for this step follows this format: instruction, chosen response, rejected response.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;During the recent Gemma competition, I trained a nice SFT model and wanted to further improve it with Preference Tuning.&lt;&#x2F;p&gt;
&lt;p&gt;I identified some good datasets (by mii-llm and Ruggero Marino Lazzaroni ğŸ™) but had limited examples (&amp;lt;3K).&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Then I found a hidden gem -&amp;gt; ğŸ’ &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;efederici&#x2F;evol-dpo-ita&quot;&gt;evol-dpo-ita (by Edoardo Federici)&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This dataset contains 20K prompts translated from Evol-Instruct, with responses generated using GPT-3.5 Turbo and Claude 3 Opus.&lt;&#x2F;p&gt;
&lt;p&gt;âš ï¸ It only has a limitation: the response from the stronger model (Claude) is always classified as â€œchosenâ€ and the other one as â€œrejectedâ€. It is a good but not perfect approximation.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;I thought: I can improve it! ğŸª„&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I used Llama-3.1-70B-Instruct as a Judge ğŸ§‘â€âš–ï¸ to re-rank the responses.&lt;&#x2F;p&gt;
&lt;p&gt;I queried the model via the cheap Hugging Face API PRO.
My prompt was inspired by the Ultrafeedback prompt (available in distilabel by Argilla).&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ“Š Results:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;7% of the times chosen and rejected were swapped ğŸ”€&lt;&#x2F;li&gt;
&lt;li&gt;Another 7% of responses were ties&lt;&#x2F;li&gt;
&lt;li&gt;I used the obtained dataset to train 2 models with DPO, achieving significant improvements for Italian! ğŸ“ˆ&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Iâ€™ve published my new dataset (&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;anakin87&#x2F;evol-dpo-ita-reranked&quot;&gt;anakin87&#x2F;evol-dpo-ita-reranked&lt;&#x2F;a&gt;) on the ğŸ¤— HF Hub.
ğŸ““ &lt;strong&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.kaggle.com&#x2F;code&#x2F;anakin87&#x2F;post-training-gemma-for-italian-and-beyond&quot;&gt;Code&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;
&lt;img src=&quot;https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;anakin87&#x2F;gemma-neogenesis&#x2F;refs&#x2F;heads&#x2F;main&#x2F;images&#x2F;evol_dpo_ita_reranked.png&quot; alt=&quot;Evol DPO ita reranked&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
</content>
        <summary type="html">How I improved an existing Italian dataset for DPO.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸˆ¯ğŸ¦™ Translate instruction datasets using a LLM + LLM as a Judge ğŸ§‘â€âš–ï¸</title>
        <published>2025-01-20T00:00:00+00:00</published>
        <updated>2025-01-20T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/translate-instruction-dataset/" type="text/html"/>
        <id>https://anakin87.github.io/blog/translate-instruction-dataset/</id>
        
            <content type="html">&lt;div class=&quot;admonition tip&quot;&gt;
    &lt;div class=&quot;admonition-icon admonition-icon-tip&quot;&gt;&lt;&#x2F;div&gt;
    &lt;div class=&quot;admonition-content&quot;&gt;
        &lt;strong class=&quot;admonition-title&quot;&gt;TIP&lt;&#x2F;strong&gt;
        &lt;p&gt;ğŸ’» You can find the code on &lt;strong&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.kaggle.com&#x2F;code&#x2F;anakin87&#x2F;post-training-gemma-for-italian-and-beyond&quot;&gt;this Kaggle notebook&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;.
For a short intro, read on!&lt;&#x2F;p&gt;

    &lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;!-- toc --&gt;
&lt;h2 id=&quot;motivation&quot;&gt;Motivation&lt;&#x2F;h2&gt;
&lt;p&gt;If you want to fine-tune a Language Model in a specific language, you usually need an instruction dataset (prompt + response) in your target language.&lt;&#x2F;p&gt;
&lt;p&gt;âŒ Good instruction datasets in your target language may not be available.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ’¡ Translate an English dataset into your target language.&lt;&#x2F;p&gt;
&lt;p&gt;This common approach is not perfect, but using LLM as a Judge can improve quality&lt;&#x2F;p&gt;
&lt;p&gt;Hereâ€™s how I approached this for the recent Gemma competition. ğŸ‘‡&lt;&#x2F;p&gt;
&lt;h2 id=&quot;recipe&quot;&gt;Recipe&lt;&#x2F;h2&gt;
&lt;p&gt;I wanted to improve Gemma for Italian ğŸ‡®ğŸ‡¹.
I already identified the &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;efederici&#x2F;capybara-claude-15k-ita&quot;&gt;capybara-claude-15k-ita dataset&lt;&#x2F;a&gt; (by Edoardo Federici): good but relatively small.&lt;&#x2F;p&gt;
&lt;p&gt;So, I did the following:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;anakin87&#x2F;gemma-neogenesis&#x2F;refs&#x2F;heads&#x2F;main&#x2F;images&#x2F;llm_aided_translation_diagram.png&quot; alt=&quot;Recipe&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;ol start=&quot;0&quot;&gt;
&lt;li&gt;
&lt;p&gt;Start with a strong base dataset&lt;br &#x2F;&gt;
I started from &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;mlabonne&#x2F;FineTome-100k&quot;&gt;FineTome-100k&lt;&#x2F;a&gt; (by Maxime Labonne), a subset of &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;arcee-ai&#x2F;The-Tome&quot;&gt;The-Tome (Arcee AI)&lt;&#x2F;a&gt;, filtered to include examples with high educational value. Contains quality conversations, reasoning problems, â€¦&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Extract single-turn conversations and deduplicate&lt;br &#x2F;&gt;
To minimize API calls for translation, I focused on single-turn conversations (the other dataset includes multi-turn examples).
For deduplication, I used MinHash (implementation from distilabel by Argilla).&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Translate the instructions&lt;br &#x2F;&gt;
For this step, you need a LLM proficient in your target language.
I used Llama-3.1-70B-Instruct via Hugging Face API.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Evaluate the translated instructions using a LLM as a Judge ğŸ§‘â€âš–ï¸&lt;br &#x2F;&gt;
Same model and same API.
LLM as a Judge is simple: we ask the LLM to evaluate both the quality of the instruction and its Italian fluency.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Remove low-quality instructions&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Evaluate the Italian correctness and fluency&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Evaluate the translated responses using a LLM as a Judge ğŸ§‘â€âš–ï¸&lt;br &#x2F;&gt;
I evaluated the Italian correctness and how well the response aligned with the instruction.
The prompt is inspired by the Ultrafeedback prompt (available in distilabel).&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Remove low-quality responses&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;With my final dataset &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;anakin87&#x2F;fine-instructions-ita-70k&quot;&gt;ğŸ·ğŸ‡®ğŸ‡¹ fine-instructions-ita-70k&lt;&#x2F;a&gt;, Gemmaâ€™s Italian performance improved. ğŸ¥³&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ’» &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.kaggle.com&#x2F;code&#x2F;anakin87&#x2F;post-training-gemma-for-italian-and-beyond&quot;&gt;&lt;strong&gt;Code&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;pinching-hand-costs-and-model-provider&quot;&gt;ğŸ¤ Costs and model provider&lt;&#x2F;h2&gt;
&lt;p&gt;Hugging Face PRO gives you 20K daily requests for just $9&#x2F;month!&lt;&#x2F;p&gt;
&lt;p&gt;If you are patient and on a budget, this is a great solution ğŸ¤©&lt;&#x2F;p&gt;
&lt;p&gt;Thanks to Maziyar PANAHI for this suggestion!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;warning-caveats&quot;&gt;âš ï¸ Caveats&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;While LLM as a Judge helps remove bad translations and low-quality instructions and responses cheaply, it is not perfect.&lt;&#x2F;li&gt;
&lt;li&gt;Translating English datasets can result in fluent and correct text in your target language, but lacking cultural nuances and idiomatic expressions.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">A cheap recipe to translate instruction datasets and ensure data quality.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ¤ New Italian Small Language Models: Neogenesis collection</title>
        <published>2025-01-17T00:00:00+00:00</published>
        <updated>2025-01-17T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/neogenesis-collection/" type="text/html"/>
        <id>https://anakin87.github.io/blog/neogenesis-collection/</id>
        
            <content type="html">&lt;p&gt;I am happy to release two new language models for the Italian Language!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;neogenesis-collection&#x2F;models.gif&quot; alt=&quot;models&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ’ª &lt;strong&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;anakin87&#x2F;gemma-2-9b-neogenesis-ita&quot;&gt;Gemma 2 9B Neogenesis ITA&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Building on the impressive work by VAGO Solutions, I applied Direct Preference Optimization with a mix of Italian and English data.
Using Spectrum, I trained 20% of model layers.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ“Š Evaluated on the Open ITA LLM leaderboard, this model achieves strong performance.
To beat it on this benchmark, youâ€™d need a 27B model ğŸ˜&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ¤ &lt;strong&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;anakin87&#x2F;gemma-2-2b-neogenesis-ita&quot;&gt;Gemma 2 2B Neogenesis ITA&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This smaller variant is fine-tuned from the original Gemma 2 2B it by Google DeepMind.
Through a combination of Supervised Fine-Tuning and Direct Preference Optimization, I trained 25% of the layers using Spectrum.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ“ˆ Compared to the original model, it shows improved Italian proficiency, good for its small size.&lt;&#x2F;p&gt;
&lt;p&gt;Both models were developed during the recent Gemma competition on Kaggle.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ™ Thanks Samuele Colombo and mii-llm for the help during evaluation.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ¤— &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;collections&#x2F;anakin87&#x2F;gemma-neogenesis-67824b7bf13ac9cfe091fe2e&quot;&gt;HF collection with all models and datasets&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ““ &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.kaggle.com&#x2F;code&#x2F;anakin87&#x2F;post-training-gemma-for-italian-and-beyond&quot;&gt;Training code&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</content>
        <summary type="html">Meet two new Gemma 2 variants with improved Italian performance.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ’ğŸŒğŸ‡®ğŸ‡¹ Gemma Neogenesis - Improving Gemma 2 for a Specific Language on a Budget: Post-Training Recipe</title>
        <published>2025-01-15T00:00:00+00:00</published>
        <updated>2025-01-15T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/gemma-competition/" type="text/html"/>
        <id>https://anakin87.github.io/blog/gemma-competition/</id>
        
            <content type="html">&lt;div class=&quot;admonition tip&quot;&gt;
    &lt;div class=&quot;admonition-icon admonition-icon-tip&quot;&gt;&lt;&#x2F;div&gt;
    &lt;div class=&quot;admonition-content&quot;&gt;
        &lt;strong class=&quot;admonition-title&quot;&gt;TIP&lt;&#x2F;strong&gt;
        &lt;p&gt;ğŸ‘¨â€ğŸ’» You can find the code on &lt;strong&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.kaggle.com&#x2F;code&#x2F;anakin87&#x2F;post-training-gemma-for-italian-and-beyond&quot;&gt;this Kaggle notebook&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;.&lt;&#x2F;p&gt;

    &lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;p&gt;Hey, it has been a whileâ€¦ I was busy participating in &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.kaggle.com&#x2F;competitions&#x2F;gemma-language-tuning&quot;&gt;ğŸ’ Gemma competition&lt;&#x2F;a&gt;!&lt;&#x2F;p&gt;
&lt;p&gt;So, whatâ€™s this Kaggle competition about?&lt;&#x2F;p&gt;
&lt;p&gt;Gemma open models have a large vocabulary size (256K), so improving them for a specific language or cultural context should be pretty affordable - no need for continued pre-training.&lt;&#x2F;p&gt;
&lt;p&gt;My submission: &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.kaggle.com&#x2F;code&#x2F;anakin87&#x2F;post-training-gemma-for-italian-and-beyond&quot;&gt;ğŸ’ğŸŒğŸ‡®ğŸ‡¹ Neogenesis - Post-Training Gemma for Italian and beyond&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;In my notebook, I show how I improve the performance of Gemma 2 2B on Italian via Post-Training.
I believe this method is adaptable to other languages and model sizes.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Key steps:&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ“Š Choose reference metrics&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ§‘â€ğŸ”¬ Data curation for Instruction Fine Tuning: identify existing datasets + generate synthetic data&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ‹ï¸â€â™‚ï¸ Efficient Instruction Fine Tuning with Spectrum&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ§‘â€ğŸ”¬ Data curation for Preference Tuning: identify existing datasets + generate synthetic data&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ‘ğŸ‘ Efficient Direct Preference Optimization with Spectrum&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ“ˆ Evaluation&lt;&#x2F;p&gt;
&lt;p&gt;Check out the full details in the &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.kaggle.com&#x2F;code&#x2F;anakin87&#x2F;post-training-gemma-for-italian-and-beyond&quot;&gt;ğŸ““ notebook&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;github.com&#x2F;anakin87&#x2F;gemma-neogenesis&#x2F;blob&#x2F;main&#x2F;images&#x2F;neogenesis.jpg?raw=true&quot; alt=&quot;Gemma Neogenesis&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
</content>
        <summary type="html">My submission to the Kaggle Gemma competition.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ„ Build an Agent to manage Santa&#x27;s Inventory ğŸ…</title>
        <published>2024-12-18T00:00:00+00:00</published>
        <updated>2024-12-18T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/santas-agent/" type="text/html"/>
        <id>https://anakin87.github.io/blog/santas-agent/</id>
        
            <content type="html">&lt;p&gt;Want to learn how to create Agents using Tool Calling? ğŸ› ï¸&lt;&#x2F;p&gt;
&lt;p&gt;Bilge YÃ¼cel and I have created a ğŸ„ Christmas Challenge for you!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;santas-agent&#x2F;elf.jpeg&quot; alt=&quot;Elf&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;In this assignment, youâ€™ll help Santaâ€™s elves build an Agent that can:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Check whatâ€™s in the inventory&lt;&#x2F;li&gt;
&lt;li&gt;Add or remove items from stock&lt;&#x2F;li&gt;
&lt;li&gt;Look up gift prices online and make purchases&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;advent-of-haystack&#x2F;day-8#challenge&quot;&gt;Challenge&lt;&#x2F;a&gt; - &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;colab.research.google.com&#x2F;drive&#x2F;10llkWo2vPnRYJWUp6lvqmZgwfvXJ0E07?usp=sharing&quot;&gt;Solution&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</content>
        <summary type="html">A Christmas challenge to build Agents using Tool Calling</summary>
        </entry><entry xml:lang="en">
        <title>ğŸğŸğŸ A Swarm of Agents with Llama 3.2, GPT-4o mini and Claude 3.5 Sonnet</title>
        <published>2024-11-26T00:00:00+00:00</published>
        <updated>2024-11-26T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/swarm/" type="text/html"/>
        <id>https://anakin87.github.io/blog/swarm/</id>
        
            <content type="html">&lt;div class=&quot;admonition tip&quot;&gt;
    &lt;div class=&quot;admonition-icon admonition-icon-tip&quot;&gt;&lt;&#x2F;div&gt;
    &lt;div class=&quot;admonition-content&quot;&gt;
        &lt;strong class=&quot;admonition-title&quot;&gt;TIP&lt;&#x2F;strong&gt;
        &lt;p&gt;&lt;strong&gt;TL;DR&lt;&#x2F;strong&gt;: I reimplemented the Swarm concept using Haystack, but made it work with both open and proprietary models ğŸ’«&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;blog&#x2F;swarm-of-agents&quot;&gt;âœï¸ Blog article&lt;&#x2F;a&gt; - &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;swarm&quot;&gt;ğŸ““ Notebook&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;For a short intro, read on!&lt;&#x2F;p&gt;

    &lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;swarm&#x2F;swarm_thumbnail.png&quot; alt=&quot;Swarm thumbnail&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Some time ago OpenAI published Swarm: an educational framework for building multi-agent systems.&lt;&#x2F;p&gt;
&lt;p&gt;Their approach focuses on two main concepts:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Routines&lt;&#x2F;strong&gt;: Each agent follows specific ğŸ“œ instructions and uses ğŸ› ï¸ tools to execute them.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Handoffs&lt;&#x2F;strong&gt; ğŸ¤: Agents can transfer control to one another using tool&#x2F;function calling.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;When I first read these ideas, I thought: &lt;em&gt;simple but powerful!&lt;&#x2F;em&gt; And they pair well with the recent unified tool support in Haystack.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ§‘â€ğŸ’» So, I decided to re-implement these concepts using Haystack, and in just a few lines of code, I had a working prototype.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ†’ Bonus feature: this implementation isnâ€™t tied to a single model provider - different agents can be powered by different models!&lt;&#x2F;p&gt;
&lt;p&gt;I replicated the ACME customer service example from the original article, with 3 Agents:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ Triage Agent - Llama 3.2 running on Ollama&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ Sales Agent - Anthropic Claude 3.5 Sonnet&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ Issues and Repairs Agent - OpenAI GPT-4o mini&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Want to see the full implementation and give it a try? ğŸ‘‡&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;blog&#x2F;swarm-of-agents&quot;&gt;âœï¸ Haystack blog article&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;swarm&quot;&gt;ğŸ““ Notebook&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;swarm&#x2F;swarm_terminal.gif&quot; alt=&quot;Swarm in action&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
</content>
        <summary type="html">Learn how to reimplement OpenAI Swarm and make it work with both open and proprietary models.</summary>
        </entry><entry xml:lang="en">
        <title>TÃ¼lu 3: a massive work in open LM post-training</title>
        <published>2024-11-21T00:00:00+00:00</published>
        <updated>2024-11-21T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/tulu3/" type="text/html"/>
        <id>https://anakin87.github.io/blog/tulu3/</id>
        
            <content type="html">&lt;p&gt;ğŸš¨ Ai2 just published a massive work on &lt;strong&gt;Post-training Language Models&lt;&#x2F;strong&gt;
and theyâ€™ve made everything completely &lt;strong&gt;public and reproducible&lt;&#x2F;strong&gt;!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;tulu3&#x2F;tulu.webp&quot; alt=&quot;TÃ¼lu 3 recipe&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What is post-training?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Itâ€™s what happens after pre-training to make a model truly usable:
instruction tuning, alignment to human preferences with different techniques, etc.&lt;&#x2F;p&gt;
&lt;p&gt;Completely Public efforts in this space have been rare - like &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;collections&#x2F;HuggingFaceH4&#x2F;zephyr-7b-6538c6d6d5ddd1cbb1744a66&quot;&gt;Zephyr by Hugging Face&lt;&#x2F;a&gt;. But TÃ¼lu 3 is big step forward.&lt;&#x2F;p&gt;
&lt;p&gt;AllenAIâ€™s latest collection of SOTA models, TÃ¼lu 3, is fine-tuned from Llama 3.1.&lt;&#x2F;p&gt;
&lt;p&gt;The release includes:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;models&lt;&#x2F;li&gt;
&lt;li&gt;data&lt;&#x2F;li&gt;
&lt;li&gt;training and evaluation code&lt;&#x2F;li&gt;
&lt;li&gt;a detailed (and impressive) technical report&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;They are also introducing a new technique: &lt;em&gt;Reinforcement Learning on Verifiable Rewards&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ‘ Kudos to Nathan Lambert and team!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Resources&lt;&#x2F;strong&gt;:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;allenai.org&#x2F;blog&#x2F;tulu-3-technical&quot;&gt;AllenAI blog post&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2411.15124&quot;&gt;Technical report&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.interconnects.ai&#x2F;p&#x2F;tulu-3&quot;&gt;Blog post by Nathan Lambert&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        </entry><entry xml:lang="en">
        <title>ğŸ”® Decoding strategies and the future of Language Models</title>
        <published>2024-11-12T00:00:00+00:00</published>
        <updated>2024-11-12T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/decoding-strategies/" type="text/html"/>
        <id>https://anakin87.github.io/blog/decoding-strategies/</id>
        
            <content type="html">&lt;!-- toc --&gt;
&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;&#x2F;h2&gt;
&lt;p&gt;The performance of a Generative Language Model depends not just on how itâ€™s trained, but also on &lt;em&gt;how inference is performed&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;OpenAI o1 model hints at this.
SmolLM2 + entropix (entropy based sampling) show impressive improvements in GSM8K.&lt;&#x2F;p&gt;
&lt;p&gt;How does inference work and how can we influence it?&lt;&#x2F;p&gt;
&lt;h2 id=&quot;gear-basics-of-text-generation&quot;&gt;âš™ï¸ Basics of text generation&lt;&#x2F;h2&gt;
&lt;p&gt;Most Generative Language Models are auto-regressive:
given an input text, they generate one token at a time, using the sequence so far to predict the next token until reaching a stopping criterion (e.g., specific token or max length).&lt;&#x2F;p&gt;
&lt;p&gt;But each time we feed a prompt into a Language Model, we actually get a list of logits (unnormalized confidence scores), one for each token in the model vocabulary.&lt;&#x2F;p&gt;
&lt;p&gt;(Llama 3 vocabulary size is 128K tokens, while Gemma 2 is 256K.)&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;How do we turn these logits into a token?&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;mantelpiece-clock-deterministic-strategies&quot;&gt;ğŸ•°ï¸ Deterministic strategies&lt;&#x2F;h2&gt;
&lt;p&gt;The simplest method is greedy search: transform the logits into probabilities using softmax, select the token with the highest probability, and repeat.&lt;&#x2F;p&gt;
&lt;p&gt;Easy, right?&lt;&#x2F;p&gt;
&lt;p&gt;Picking the highest probability token each step can limit exploration of better sequences. ğŸ¤”&lt;&#x2F;p&gt;
&lt;p&gt;To address this, beam search generates multiple sequences and selects the most probable one.
Yet, for open-ended tasks, it often results in repetitive, generic texts.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;game-die-sampling-strategies&quot;&gt;ğŸ² Sampling strategies&lt;&#x2F;h2&gt;
&lt;p&gt;To make text generation more human-like, we introduce some randomness. ğŸƒ&lt;&#x2F;p&gt;
&lt;p&gt;In its simplest form, sampling means selecting the next token based on its probability (multinomial sampling).&lt;&#x2F;p&gt;
&lt;p&gt;Temperature plays a key role in controlling randomness. It scales logits before softmax, altering the sharpness of the output distribution:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Higher temperatures produce a more uniform, random output.&lt;&#x2F;li&gt;
&lt;li&gt;Lower temperature creates a sharper distribution, approaching greedy search predictability.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Top-K and Top-p sampling are also popular.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸª Patrick von Platen wrote a &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;blog&#x2F;how-to-generate&quot;&gt;classic practical guide on decoding strategies&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;cyclone-the-future-of-sampling-entropy-is-all-you-need&quot;&gt;ğŸŒ€ The future of sampling: Entropy is all you need?&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;decoding-strategies&#x2F;decoding.png&quot; alt=&quot;modern decoding strategies&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Recent projects and papers, like &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2410.01104&quot;&gt;â€œSoftmax is Not Enoughâ€&lt;&#x2F;a&gt;, &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2407.01082&quot;&gt;â€œMin-p Samplingâ€&lt;&#x2F;a&gt;, and &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;xjdr-alt&#x2F;entropix&quot;&gt;entropix&lt;&#x2F;a&gt;, explore fresh approaches to sampling during inference.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The common idea is to adjust token selection techniques&#x2F;parameters during inference. For example, temperature can be dynamically adapted during generation.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;â€œSoftmax is not enoughâ€ and entropix explore using entropy as a measure of model uncertainty. High entropy means more uncertainty (a wider range of viable token choices), while low entropy suggests confidence in a smaller set.
This measure can guide generation tuning.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;em&gt;Itâ€™s a vast and fascinating landscape.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;ğŸª For an intro to these recent techniques, check out the &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;Pleias&#x2F;Quest-Best-Tokens&#x2F;blob&#x2F;main&#x2F;New%20physics%20of%20LLM.pdf&quot;&gt;great slide deck by Pierre-Carl Langlais&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
</content>
        <summary type="html">An intro to classic and modern decoding&#x2F;sampling strategies for LLMs</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ‘©â€ğŸ« Banks (Python library): a Swiss Army Knife for prompting	</title>
        <published>2024-10-31T00:00:00+00:00</published>
        <updated>2024-10-31T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/banks/" type="text/html"/>
        <id>https://anakin87.github.io/blog/banks/</id>
        
            <content type="html">&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;banks&#x2F;banks.gif&quot; alt=&quot;Banks&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;When you start building with Language Models, itâ€™s likely youâ€™ll play around with various prompts before achieving your goal.&lt;&#x2F;p&gt;
&lt;p&gt;Soon, you realize you need:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Templating to include dynamic elements in your prompts.&lt;&#x2F;li&gt;
&lt;li&gt;Versioning and storing prompts - to avoid losing the results of your experiments.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Thatâ€™s where &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;masci&#x2F;banks&quot;&gt;&lt;em&gt;Banks&lt;&#x2F;em&gt;&lt;&#x2F;a&gt; comes in.&lt;&#x2F;p&gt;
&lt;p&gt;My friend Massimiliano Pippi developed this lightweight Python library based on Jinja2.&lt;&#x2F;p&gt;
&lt;p&gt;Itâ€™s named after Louise Banks, the character portrayed by Amy Adams in Arrival, who is enlisted by the United States Army to communicate with extraterrestrials.&lt;&#x2F;p&gt;
&lt;p&gt;Banks focuses on:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ“™ Templating for text and chat messages&lt;&#x2F;li&gt;
&lt;li&gt;ğŸŸï¸ Prompt Versioning&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ—„ï¸ Prompt Management&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Once you start exploring it, youâ€™ll discover several bonus ğŸğğšğ­ğ®ğ«ğğ¬:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;âœ¨ LM-assisted prompt creation&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ”§ tool calling directly from the prompt&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ’¾ prompt caching&lt;&#x2F;li&gt;
&lt;li&gt;ğŸš… LiteLLM (YC W23) support&lt;&#x2F;li&gt;
&lt;li&gt;ã€°ï¸ Async support&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;â­â­ Give &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;masci&#x2F;banks&quot;&gt;Banks&lt;&#x2F;a&gt; a star! â­â­&lt;&#x2F;p&gt;
&lt;p&gt;(This is not a sponsored post, Banks is MIT, and at best, Iâ€™ll earn a beer for it ğŸ˜Š)&lt;&#x2F;p&gt;
</content>
        </entry><entry xml:lang="en">
        <title>ğŸ‡®ğŸ‡¹ğŸ‡¯ğŸ‡µğŸ‡§ğŸ‡· Generating multilingual instruction datasets with Magpie ğŸ¦â€â¬›</title>
        <published>2024-10-21T00:00:00+00:00</published>
        <updated>2024-10-21T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/multilingual-magpie/" type="text/html"/>
        <id>https://anakin87.github.io/blog/multilingual-magpie/</id>
        
            <content type="html">&lt;div class=&quot;admonition tip&quot;&gt;
    &lt;div class=&quot;admonition-icon admonition-icon-tip&quot;&gt;&lt;&#x2F;div&gt;
    &lt;div class=&quot;admonition-content&quot;&gt;
        &lt;strong class=&quot;admonition-title&quot;&gt;TIP&lt;&#x2F;strong&gt;
        &lt;p&gt;Ok, youâ€™re finally convinced that synthetic data worksâ€¦ âš—ï¸&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Now you want to generate an instruction dataset in a language other than English.&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;But how do you get started?&lt;&#x2F;p&gt;
&lt;p&gt;I explore how to do this with Magpie &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;blog&#x2F;anakin87&#x2F;multilingual-magpie&quot;&gt;in my new tutorial&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;For a short intro, read on!&lt;&#x2F;p&gt;

    &lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;!-- toc --&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;multilingual-magpie&#x2F;multilingual_magpie.jpeg&quot; alt=&quot;Generating multilingual instruction datasets with Magpie&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;bird-black-large-square-what-is-magpie&quot;&gt;ğŸ¦â€â¬› What is Magpie?&lt;&#x2F;h2&gt;
&lt;p&gt;Itâ€™s a recent technique for creating synthetic instruction datasets.&lt;&#x2F;p&gt;
&lt;p&gt;Magpie is based on a simple but ingenious idea ğŸ‘‡&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;If you prompt an instruction-tuned model with a pre-query template, you can make it generate a plausible user instruction.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Hereâ€™s an example:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;model: Llama-3-8B-Instruct&lt;&#x2F;li&gt;
&lt;li&gt;pre-query template: &lt;code&gt;&amp;lt;|begin_of_text|&amp;gt;&amp;lt;|start_header_id|&amp;gt;user&amp;lt;|end_header_id|&amp;gt;&lt;&#x2F;code&gt;&lt;&#x2F;li&gt;
&lt;li&gt;generated user instruction: â€œWhat are some of the responsibilities of a commercial pilot?â€&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;You can then feed this instruction back into the same model to get the assistant response.&lt;&#x2F;p&gt;
&lt;p&gt;By repeating this process, itâ€™s possible to generate large synthetic datasets with relatively little effort.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸª„ The authors demonstrate that using these datasets for Supervised Fine Tuning (SFT) can yield strong performance, even competitive with the original instruct model.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;climbing-generating-non-english-data&quot;&gt;ğŸ§— Generating non-English data&lt;&#x2F;h2&gt;
&lt;p&gt;Most Language Models are primarily trained on English texts, so they tend to produce data in English.&lt;&#x2F;p&gt;
&lt;p&gt;How can we overcome this?&lt;&#x2F;p&gt;
&lt;p&gt;Earlier approaches were complex or costly.&lt;&#x2F;p&gt;
&lt;p&gt;Then Manuel Romero found a simple solution: add the target language to the pre-query template.
For Spanish, the template becomes &lt;code&gt;&amp;lt;|begin_of_text|&amp;gt;&amp;lt;|start_header_id|&amp;gt;user&amp;lt;|end_header_id|&amp;gt;spanish:&lt;&#x2F;code&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;This method works for Spanish and German!&lt;&#x2F;p&gt;
&lt;p&gt;âŒ Unfortunately, it does not work well for other languages (ğŸ‡®ğŸ‡¹, ğŸ‡³ğŸ‡±, â€¦)&lt;&#x2F;p&gt;
&lt;h2 id=&quot;bulb-magpie-with-system-message&quot;&gt;ğŸ’¡ Magpie with system message&lt;&#x2F;h2&gt;
&lt;p&gt;I had another idea: use the system message to steer generation towards a specific language.&lt;&#x2F;p&gt;
&lt;p&gt;The system message should be in the target language, like:
â€œYou are an artificial intelligence that answers usersâ€™ questions in TARGET_LANGUAGE in a useful and detailed way. The user asks complex questions in TARGET_LANGUAGE.â€&lt;&#x2F;p&gt;
&lt;p&gt;It is a simple approach, but it might workâ€¦&lt;&#x2F;p&gt;
&lt;p&gt;It turns out the authors had a similar idea, which they included in the latest revision of their paper. ğŸ‰&lt;&#x2F;p&gt;
&lt;h2 id=&quot;cookie-resources&quot;&gt;ğŸª Resources&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;blog&#x2F;anakin87&#x2F;multilingual-magpie&quot;&gt;My article - â€œGenerating multilingual instruction datasets with Magpieâ€&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2406.08464&quot;&gt;Magpie paper and repository&lt;&#x2F;a&gt; &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;magpie-align&#x2F;magpie&quot;&gt;https:&#x2F;&#x2F;github.com&#x2F;magpie-align&#x2F;magpie&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;davanstrien&#x2F;magpie&quot;&gt;Magpie demo by Daniel van Strien&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;mrm8488&#x2F;magpie-ollama-datagen&quot;&gt;Magpie Ollama Datagen by Manuel Romero&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;argilla&#x2F;magpie-ultra-v0.1&quot;&gt;magpie-ultra dataset&lt;&#x2F;a&gt; - massive dataset built with Magpie by Argilla&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;distilabel.argilla.io&#x2F;latest&#x2F;&quot;&gt;âš—ï¸ distilabel framework&lt;&#x2F;a&gt; - framework for synthetic data generation and AI feedback at scale&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">A tutorial on how to generate synthetic instruction datasets in languages other than English.</summary>
        </entry><entry xml:lang="en">
        <title>Create a ğŸ“° Newsletter Agent with Haystack Tools ğŸ› ï¸</title>
        <published>2024-10-17T00:00:00+00:00</published>
        <updated>2024-10-17T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/newsletter-agent/" type="text/html"/>
        <id>https://anakin87.github.io/blog/newsletter-agent/</id>
        
            <content type="html">&lt;p&gt;In the Haystack framework, weâ€™ve recently implemented unified Tool Calling support across different model providers.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;newsletter-agent&#x2F;newsletter_agent.jpeg&quot; alt=&quot;Newsletter Agent&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;In the following resources, weâ€™ll walk through building a Newsletter Agent using three tools:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;A tool to fetch top stories from Hacker News&lt;&#x2F;li&gt;
&lt;li&gt;A tool to create newsletters for a particular audience&lt;&#x2F;li&gt;
&lt;li&gt;A tool to send emails via Gmail.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;Resources&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;newsletter-agent&quot;&gt;ğŸ““ Notebook&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;ğŸ¬ Video: &lt;div &gt;
    &lt;iframe src=&quot;https:&#x2F;&#x2F;www.youtube-nocookie.com&#x2F;embed&#x2F;QWx3OzW2Pvo&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;&#x2F;iframe&gt;
&lt;&#x2F;div&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">Learn how to create an Agent that can fetch information, write a newsletter for a specific audience and send it.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ§° From my toolbox: ğŸ’¬ Chat Template Viewer</title>
        <published>2024-10-07T00:00:00+00:00</published>
        <updated>2024-10-07T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/chat-template-viewer/" type="text/html"/>
        <id>https://anakin87.github.io/blog/chat-template-viewer/</id>
        
            <content type="html">&lt;p&gt;When you interact with a Language Model, itâ€™s typically through a Messages API, like this:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #F6F6F4; background-color: #282A36;&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;[{&lt;&#x2F;span&gt;&lt;span style=&quot;color: #97E2F2;&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color: #97E1F1;&quot;&gt;role&lt;&#x2F;span&gt;&lt;span style=&quot;color: #97E2F2;&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color: #F286C4;&quot;&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color: #DEE492;&quot;&gt; &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color: #E7EE98;&quot;&gt;user&lt;&#x2F;span&gt;&lt;span style=&quot;color: #DEE492;&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;,&lt;&#x2F;span&gt;&lt;span style=&quot;color: #97E2F2;&quot;&gt; &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color: #97E1F1;&quot;&gt;content&lt;&#x2F;span&gt;&lt;span style=&quot;color: #97E2F2;&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color: #F286C4;&quot;&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color: #DEE492;&quot;&gt; &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color: #E7EE98;&quot;&gt;What is the capital of Italy?&lt;&#x2F;span&gt;&lt;span style=&quot;color: #DEE492;&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;},&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; {&lt;&#x2F;span&gt;&lt;span style=&quot;color: #97E2F2;&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color: #97E1F1;&quot;&gt;role&lt;&#x2F;span&gt;&lt;span style=&quot;color: #97E2F2;&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color: #F286C4;&quot;&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color: #DEE492;&quot;&gt; &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color: #E7EE98;&quot;&gt;assistant&lt;&#x2F;span&gt;&lt;span style=&quot;color: #DEE492;&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;,&lt;&#x2F;span&gt;&lt;span style=&quot;color: #97E2F2;&quot;&gt; &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color: #97E1F1;&quot;&gt;content&lt;&#x2F;span&gt;&lt;span style=&quot;color: #97E2F2;&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color: #F286C4;&quot;&gt;:&lt;&#x2F;span&gt;&lt;span style=&quot;color: #DEE492;&quot;&gt; &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color: #E7EE98;&quot;&gt;Rome&lt;&#x2F;span&gt;&lt;span style=&quot;color: #DEE492;&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;}]&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;em&gt;But whatâ€™s happening under the hood? How does it get translated into a prompt?&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Open models give us the ability to peek inside.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ¦™ Llama 3 transforms messages into a format like:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;code&gt;&amp;lt;|begin_of_text|&amp;gt;&amp;lt;|start_header_id|&amp;gt;user&amp;lt;|end_header_id|&amp;gt; What is the capital of Italy?&amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt; Rome&amp;lt;|eot_id|&amp;gt;&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Mistral does it a bit differently:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;code&gt;&amp;lt;s&amp;gt;[INST]What is the capital of Italy?[&#x2F;INST]Rome&amp;lt;&#x2F;s&amp;gt;&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;&lt;em&gt;ğ˜ğ˜©ğ˜º ğ˜¥ğ˜°ğ˜¦ğ˜´ ğ˜µğ˜©ğ˜ªğ˜´ ğ˜®ğ˜¢ğ˜µğ˜µğ˜¦ğ˜³?&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Knowing how these templates are structured helps with debugging (for AI engineers) and is critical when fine-tuning models.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ¤— Hugging Face did a great job unifying different chat formats, but manually inspecting Jinja templates isnâ€™t exactly fun.&lt;&#x2F;p&gt;
&lt;p&gt;Thatâ€™s why I often rely on a hidden gem: &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;Jofthomas&#x2F;Chat_template_viewer&quot;&gt;ğŸ’ Chat Template Viewer by Joffrey THOMAS&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;Itâ€™s a HF space that lets you ğŸ•¹ï¸ interactively experiment with messages and see how they translate to a final prompt across different open models.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;chat-template-viewer&#x2F;chat_template_viewer.jpeg&quot; alt=&quot;Chat Template Viewer&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
</content>
        </entry><entry xml:lang="en">
        <title>ğŸ•µğŸ» Agentic RAG with ğŸ¦™ Llama 3.2 3B</title>
        <published>2024-09-26T00:00:00+00:00</published>
        <updated>2024-09-26T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/agentic-rag-llama32/" type="text/html"/>
        <id>https://anakin87.github.io/blog/agentic-rag-llama32/</id>
        
            <content type="html">&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;agentic-rag-llama32&#x2F;agentic_rag_llama.jpeg&quot; alt=&quot;Agentic RAG with Llama 3.2 3B&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I was excited to explore Llama 3.2, but as a simple ğŸ‡ªğŸ‡º EU guy, I donâ€™t have access to Metaâ€™s multimodal models. ğŸ˜¿&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ¤” So I thought: why not challenge the small 3B text model with Agentic RAG?&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ¯ The plan:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Build a system that tries to answer questions using a knowledge base.&lt;&#x2F;li&gt;
&lt;li&gt;If the documents donâ€™t contain the answer, use Web search for additional context.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;Check out my &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;llama32_agentic_rag&quot;&gt;experimental notebook&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;My stack:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ—ï¸ Haystack: open-source LLM orchestration framework&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ¦™ Llama-3.2-3B-Instruct&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ¦†ğŸŒ free DuckDuckGo API, integrated with Haystack - huge thanks to Giovanni Alzetta!&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;âœ¨ &lt;em&gt;The results? Encouraging - a few months ago, this level of performance from a small model would have been unthinkable.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This probably reflects the impressive IFEval score of the model (comparable to Llama 3.1 8B).&lt;&#x2F;p&gt;
</content>
        <summary type="html">Combine RAG on a knowledge base with Web Search to intelligently answer user questions.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ’¬ğŸ‡®ğŸ‡¹ Phi 3.5 mini ITA: my Italian Small Language Model</title>
        <published>2024-08-29T00:00:00+00:00</published>
        <updated>2024-08-29T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/phi-35-mini-ita/" type="text/html"/>
        <id>https://anakin87.github.io/blog/phi-35-mini-ita/</id>
        
            <content type="html">&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;phi-35-mini-ita&#x2F;phi_35_mini_ita.png&quot; alt=&quot;Phi 3.5 mini ITA&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;!-- toc --&gt;
&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;&#x2F;h2&gt;
&lt;p&gt;Lately, Iâ€™ve spent some time fine-tuning language models.&lt;&#x2F;p&gt;
&lt;p&gt;Now I am happy to release Phi 3.5 mini ITA: a fine-tuned version of Phi-3.5-mini-instruct to improve performance on the Italian language&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Small (3.82 B parameters) but capable model&lt;&#x2F;li&gt;
&lt;li&gt;128k context length&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;ğŸ“Š Vibe check and performance on Italian benchmarks seem encouraging&lt;&#x2F;p&gt;
&lt;h2 id=&quot;speech-balloon-resources&quot;&gt;ğŸ’¬ Resources&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;anakin87&#x2F;Phi-3.5-mini-ITA&quot;&gt;Chat with it on ğŸ¤— Spaces&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;anakin87&#x2F;Phi-3.5-mini-ITA&quot;&gt;Model card&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;blog&#x2F;anakin87&#x2F;spectrum&quot;&gt;ğŸ“” ğŸ‘£ Full training walkthrough&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;card-file-box-data&quot;&gt;ğŸ—ƒï¸ Data&lt;&#x2F;h2&gt;
&lt;p&gt;Supervised fine-tuning using a good mix of English and Italian data:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;mlabonne&#x2F;FineTome-100k&quot;&gt;FineTome-100k by Maxime Labonne&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;efederici&#x2F;Capybara-Claude-15k-ita&quot;&gt;Capybara-Claude-15k-ita by Edoardo Federici&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;ğŸ™ Thanks to the authors for the datasets.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;dart-targeted-training-with-spectrum&quot;&gt;ğŸ¯ Targeted training with Spectrum&lt;&#x2F;h2&gt;
&lt;p&gt;I used Spectrum, a relatively new technique for parameter-efficient learning.&lt;&#x2F;p&gt;
&lt;p&gt;The idea is to train only the layers of the model with high Signal-to-Noise Ratio (SNR) and â„ï¸ freeze the rest.
I trained the top 30% of model layers.&lt;&#x2F;p&gt;
</content>
        <summary type="html">Combine RAG on a knowledge base with Web Search to intelligently answer user questions.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ“ Fine-tuning LLMs: what I&#x27;ve learned</title>
        <published>2024-08-26T00:00:00+00:00</published>
        <updated>2024-08-26T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/fine-tuning-llms/" type="text/html"/>
        <id>https://anakin87.github.io/blog/fine-tuning-llms/</id>
        
            <content type="html">&lt;!-- toc --&gt;
&lt;h2 id=&quot;0-familiarize-with-the-jargon&quot;&gt;0ï¸âƒ£ Familiarize with the jargon&lt;&#x2F;h2&gt;
&lt;p&gt;SFT, PPO, DPO, QLoRAâ€¦ ğŸ¤¯&lt;&#x2F;p&gt;
&lt;p&gt;For a simple and visual overview, I recommend a recent &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.linkedin.com&#x2F;posts&#x2F;804250ab_llm-fine-tuning-activity-7229073338042593280-i_1R&quot;&gt;post by Leonie Monigatti&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;1-not-all-models-are-made-equal&quot;&gt;1ï¸âƒ£ Not all models are made equal&lt;&#x2F;h2&gt;
&lt;p&gt;Besides performance, some models from big labs are easier to fine-tune than others.&lt;&#x2F;p&gt;
&lt;p&gt;You can get a sense of this by looking at how many fine-tunes a specific model has on HF Hub.&lt;&#x2F;p&gt;
&lt;p&gt;For example, there are many fine-tunes of Llama and Mistral models; Phi-3-small, despite strong on benchmarks, has a very custom architecture that makes it tough to fine-tune.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;2-data-card-file-box&quot;&gt;2ï¸âƒ£ Data ğŸ—ƒï¸&lt;&#x2F;h2&gt;
&lt;p&gt;Good, relevant data matters. If you are fine-tuning on creative writing examples, donâ€™t expect improvements on general knowledge&#x2F;reasoning benchmarks.&lt;&#x2F;p&gt;
&lt;p&gt;Despite some skepticism, synthetic data is a thing. Donâ€™t trust me: read the recent technical reports on Llama3.1 and Gemma2.
Then check out &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;argilla-io&#x2F;distilabel&quot;&gt;âš—ï¸ distilabel by Argilla&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;3-data-preparation&quot;&gt;3ï¸âƒ£ Data preparation&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Ensure youâ€™re correctly applying the chat template to your examples (if needed).&lt;&#x2F;li&gt;
&lt;li&gt;Fine-tuning libraries like HF TRL (Aloxotl, Unsloth AIâ€¦) expose parameters like &lt;code&gt;max_seq_length&lt;&#x2F;code&gt; (for SFT), &lt;code&gt;max_prompt_length&lt;&#x2F;code&gt; and &lt;code&gt;max_length&lt;&#x2F;code&gt; (for DPO). Using default values might truncate your examples, which can be fine, but itâ€™s better to be aware. For more details, check out &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.philschmid.de&#x2F;dpo-align-llms-in-2024-with-trl&quot;&gt;a great article by Philipp Schmid&lt;&#x2F;a&gt;.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;4-no-space-left-on-device-stop-sign&quot;&gt;4ï¸âƒ£ No space left on device ğŸ›‘&lt;&#x2F;h2&gt;
&lt;p&gt;This is silly but real. Make sure you have enough storage space before starting fine-tuning. Also, configure your training to save a manageable number of checkpoints.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;5-evaluation-and-benchmarks-scales&quot;&gt;5ï¸âƒ£ Evaluation and benchmarks âš–ï¸&lt;&#x2F;h2&gt;
&lt;p&gt;Take some time to understand how these work.&lt;&#x2F;p&gt;
&lt;p&gt;For example, &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;EleutherAI&#x2F;lm-evaluation-harness&quot;&gt;lm-evaluation-harness by EleutherAI&lt;&#x2F;a&gt; is the evaluation framework that powers the HF Open LLM Leaderboard, standardizing many tasks.&lt;&#x2F;p&gt;
&lt;p&gt;Something I didnâ€™t know: for multiple-choice benchmarks (like MMLU), the framework scores an example using the (log) probability of each option instead of the full-text response.
To dig deeper into LLM benchmarks, I recommend &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.latent.space&#x2F;p&#x2F;benchmarks-201&quot;&gt;the interview with ClÃ©mentine Fourrier (maintainer of Open LLM Leaderboard) on the Latent Space podcast&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;6-need-a-gpu&quot;&gt;6ï¸âƒ£ Need a GPU?&lt;&#x2F;h2&gt;
&lt;p&gt;Take a look at &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.primeintellect.ai&#x2F;&quot;&gt;PrimeIntellect compute&lt;&#x2F;a&gt;: a new product, that acts as a GPU marketplace. Itâ€™s not fully refined yet, but itâ€™s easy to use and promising.&lt;&#x2F;p&gt;
&lt;p&gt;Iâ€™m not sponsored by them, but hey, if they want to give me some free GPUs, I wonâ€™t complain :-)&lt;&#x2F;p&gt;
</content>
        <summary type="html">Lessons learned from my fine-tuning failures ğŸ˜Š.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ—‚ï¸â›ï¸ Structured data extraction with Small Language Models</title>
        <published>2024-08-02T00:00:00+00:00</published>
        <updated>2024-08-02T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/structured-data-extraction/" type="text/html"/>
        <id>https://anakin87.github.io/blog/structured-data-extraction/</id>
        
            <content type="html">&lt;p&gt;I like playing with small language models and applying them to practical problems.&lt;&#x2F;p&gt;
&lt;p&gt;Recently, I turned one of these experiments into a step-by-step recipe for the Open-Source AI cookbook (by ğŸ¤— Hugging Face)!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;learn&#x2F;cookbook&#x2F;en&#x2F;information_extraction_haystack_nuextract&quot;&gt;ğŸ‘¨â€ğŸ³ğŸ““ Check it out&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;video src=&quot;data_extraction.mp4&quot; controls autoplay loop&gt;&lt;&#x2F;video&gt;&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ¯ Goal: automatically extract structured information from startup funding announcements found on the web.&lt;&#x2F;p&gt;
&lt;p&gt;In this notebook, youâ€™ll discover how to:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ—ï¸ Build an Information Extraction pipeline orchestrated by Haystack&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ§  Use &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;numind&#x2F;NuExtract&quot;&gt;NuExtract&lt;&#x2F;a&gt;, a powerful Small Language Model (3.8B) fine-tuned for data extraction (by NuMind)&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ—’ï¸ Visualize results with Pandas&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ•µï¸ Create a simple graph to derive insights, such as the relationships between companies and investors&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;ğŸ™ Tuana Ã‡elik, Merve Noyan, Steven Liu for their help and support!&lt;&#x2F;p&gt;
</content>
        <summary type="html">Combine RAG on a knowledge base with Web Search to intelligently answer user questions.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ¤” What does a LLM think when it thinks?</title>
        <published>2024-08-01T00:00:00+00:00</published>
        <updated>2024-08-01T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/mechanistic-interpretability/" type="text/html"/>
        <id>https://anakin87.github.io/blog/mechanistic-interpretability/</id>
        
            <content type="html">&lt;!-- toc --&gt;
&lt;p&gt;Yesterdayâ€™s Gemma release was big!&lt;&#x2F;p&gt;
&lt;p&gt;Not only because the 2B model surpasses GPT-3.5-Turbo in the Chatbot Arenaâ€¦&lt;&#x2F;p&gt;
&lt;p&gt;Deepmind folks also released Gemma Scope, which opens new doors in LLM interpretability.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;memo-mechanistic-interpretability-recap&quot;&gt;ğŸ“ Mechanistic interpretability recap&lt;&#x2F;h2&gt;
&lt;p&gt;ğŸ”¹ When you ask an LLM a question, your text is turned into a series of activations that map the relations between words.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ”¹ These activations, at different layers in the modelâ€™s neural network, represent increasingly complex concepts, called features.&lt;&#x2F;p&gt;
&lt;p&gt;â›” Researchers face a key challenge: the modelâ€™s activations mix many different features together.&lt;&#x2F;p&gt;
&lt;p&gt;â›” Features do not match individual neurons.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ’¡ This is where &lt;strong&gt;sparse autoencoders&lt;&#x2F;strong&gt; come in. They can be trained for each layer&#x2F;sublayer to identify a small number of significant features for each activation.
(Remember Golden Gate Claude? ğŸŒ‰)&lt;&#x2F;p&gt;
&lt;h2 id=&quot;gem-gemma-scope&quot;&gt;ğŸ’ Gemma Scope&lt;&#x2F;h2&gt;
&lt;p&gt;Google DeepMind trained sparse autoencoders for every layer and sublayer output of Gemma 2 2B and 9B.&lt;&#x2F;p&gt;
&lt;p&gt;Gemma Scope is a collection of over 400 sparse autoencoders with more than 30 million learned features.&lt;&#x2F;p&gt;
&lt;p&gt;You can easily use these to investigate and inspect the inner behavior of the LLM.&lt;&#x2F;p&gt;
&lt;p&gt;Comes with an interactive demo and a Colab notebook! ğŸ““&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;mechanistic-interpretability&#x2F;gemma_scope.jpeg&quot; alt=&quot;Gemma Scope&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;books-resources&quot;&gt;ğŸ“š Resources&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;theory&quot;&gt;Theory&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;adamkarvonen.github.io&#x2F;machine_learning&#x2F;2024&#x2F;06&#x2F;11&#x2F;sae-intuitions.html&quot;&gt;Introduction to Sparse Autoencoders for LLM interpretability (by Adam Karvonen)&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;transformer-circuits.pub&#x2F;2024&#x2F;scaling-monosemanticity&#x2F;index.html&quot;&gt;Scaling monosemanticity - with Golden Gate experiment (by Anthropic)&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;gem-gemma-scope-1&quot;&gt;ğŸ’ Gemma Scope&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;deepmind.google&#x2F;discover&#x2F;blog&#x2F;gemma-scope-helping-the-safety-community-shed-light-on-the-inner-workings-of-language-models&#x2F;&quot;&gt;Blog post&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;storage.googleapis.com&#x2F;gemma-scope&#x2F;gemma-scope-report.pdf&quot;&gt;Technical report&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.neuronpedia.org&#x2F;gemma-scope&quot;&gt;Interactive demo&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;colab.research.google.com&#x2F;drive&#x2F;17dQFYUYnuKnP6OwQPH9v_GSYUW5aj-Rp&quot;&gt;Colab notebook&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">Introduction to mechanistic interpretability of LLMs.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ¤ yo-Llama ğŸ¦™: a model that raps</title>
        <published>2024-07-01T00:00:00+00:00</published>
        <updated>2024-07-01T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/yo-llama/" type="text/html"/>
        <id>https://anakin87.github.io/blog/yo-llama/</id>
        
            <content type="html">&lt;!-- toc --&gt;
&lt;h2 id=&quot;how-to-alter-the-behavior-of-a-language-model-without-fine-tuning-or-prompting&quot;&gt;How to alter the behavior of a Language Model without fine-tuning or prompting?&lt;&#x2F;h2&gt;
&lt;p&gt;Say hello to ğŸ¤ yo-Llama ğŸ¦™! -&amp;gt; &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;anakin87&#x2F;yo-Llama-3-8B-Instruct&quot;&gt;Model on HF ğŸ¤—&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This experiment steers Llama-3-8B-Instruct to respond in a rap style.&lt;&#x2F;p&gt;
&lt;p&gt;How? Amplifying the rap direction in the activation space. ğŸ˜&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-sparked-this-idea&quot;&gt;What sparked this idea?&lt;&#x2F;h2&gt;
&lt;p&gt;Lately, I got interested in mechanistic interpretability of LLMs.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ’¡ A recent paper, &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2406.11717&quot;&gt;â€œRefusal in Language Models Is Mediated by a Single Directionâ€&lt;&#x2F;a&gt;, showed how to find the refusal direction in the activation space of Chat Language Models and either erase or amplify it.
A clever jailbreak method for open weights models.&lt;&#x2F;p&gt;
&lt;p&gt;Then, Failspy took it a step further by modifying the models to amplify different traits, such as making a model seem grumpy or irritable.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;how-did-i-create-yo-llama&quot;&gt;How did I create yo-Llama?&lt;&#x2F;h2&gt;
&lt;p&gt;(&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;anakin87&#x2F;yo-Llama-3-8B-Instruct&#x2F;blob&#x2F;main&#x2F;steer_llama_to_rap_style.ipynb&quot;&gt;ğŸ““ Notebook&lt;&#x2F;a&gt;, heavily inspired by Failspyâ€™s work)&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;Load the Llama-3-8B-Instruct model.&lt;&#x2F;li&gt;
&lt;li&gt;Load 1024 examples from Alpaca (instruction dataset).&lt;&#x2F;li&gt;
&lt;li&gt;Prepare a system prompt to make the original model act like a rapper.&lt;&#x2F;li&gt;
&lt;li&gt;Run inference on the examples, with and without the system prompt, and cache the activations.&lt;&#x2F;li&gt;
&lt;li&gt;Compute the rap feature directions (one for each layer) from the activations.&lt;&#x2F;li&gt;
&lt;li&gt;Apply the feature directions one by one, checking the results on some examples.&lt;&#x2F;li&gt;
&lt;li&gt;Pick the best-performing feature direction.&lt;&#x2F;li&gt;
&lt;li&gt;Apply this feature direction and voilÃ !
yo-Llama-3-8B-Instruct is born! ğŸ¥³ğŸ¶&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;This was a fun experiment.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;yo-llama&#x2F;yo_llama.gif&quot; alt=&quot;yo-Llama&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;books-resources&quot;&gt;ğŸ“š Resources&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2406.11717&quot;&gt;Refusal in Language Models Is Mediated by a Single Direction&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;blog&#x2F;mlabonne&#x2F;abliteration&quot;&gt;Uncensor any LLM with abliteration&lt;&#x2F;a&gt;: great practical blog post by Maxime Labonne&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Practical materials by Failspy:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;FailSpy&#x2F;abliterator&quot;&gt;abliterator library&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;failspy&#x2F;Llama-3-8B-Instruct-MopeyMule&quot;&gt;Llama-MopeyMule-3-8B-Instruct model&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;failspy&#x2F;Llama-3-8B-Instruct-MopeyMule&#x2F;blob&#x2F;main&#x2F;MopeyMule-Induce-Melancholy.ipynb&quot;&gt;Induce Melancholy notebook&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">Alter the behavior of a LLM by amplifying a feature direction in the activation space.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸŒŒ Creating adventures with local LLMs</title>
        <published>2024-06-24T00:00:00+00:00</published>
        <updated>2024-06-24T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/adventures-local-llms/" type="text/html"/>
        <id>https://anakin87.github.io/blog/adventures-local-llms/</id>
        
            <content type="html">&lt;p&gt;What if ğŸ¤”â€¦ Homer Simpson met Spider-Man and they went on a quest for donuts? ğŸ©&lt;&#x2F;p&gt;
&lt;p&gt;Or if Fred Astaire and Corporal Hicks teamed up to fight xenomorphs? ğŸ‘¾&lt;&#x2F;p&gt;
&lt;p&gt;In the words of Karpathy, LLMs are dream machinesâ€¦
they seem specially made to simulate these wild scenarios!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Experimenting with this idea ğŸ‘‡&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Nous Research&#x2F;teknium recently released &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;NousResearch&#x2F;CharacterCodex&quot;&gt;Character Codex&lt;&#x2F;a&gt;:
a massive dataset with information on 16k characters, both fictional and real.
I couldnâ€™t wait to play itâ€¦&lt;&#x2F;p&gt;
&lt;p&gt;After a few attempts, I found that combining the information in this dataset with a good model (like Llama-3-8B)
opens the doors to a myriad of chat adventures.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ› ï¸ Stack:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Haystack for orchestration ğŸ—ï¸&lt;&#x2F;li&gt;
&lt;li&gt;llamafile ğŸ¦™ğŸ—‚ï¸ (by Mozilla) to run our model locally.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;Check out the &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;charactercodex_llamafile&quot;&gt;ğŸ““ notebook&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;
(includes a bonus ğŸ•µï¸ Mystery Character Quiz)&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;adventures-local-llms&#x2F;adventures.jpeg&quot; alt=&quot;Adventures&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
</content>
        <summary type="html">Make LLMs simulate adventures with llamafile + Character Codex.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ§ª RAG Evaluation with ğŸ”¥ Prometheus 2</title>
        <published>2024-06-17T00:00:00+00:00</published>
        <updated>2024-06-17T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/rag-eval-prometheus/" type="text/html"/>
        <id>https://anakin87.github.io/blog/rag-eval-prometheus/</id>
        
            <content type="html">&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;rag-eval-prometheus&#x2F;prometheus.png&quot; alt=&quot;Prometheus 2&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;When evaluating LLMsâ€™ responses, &lt;strong&gt;proprietary models&lt;&#x2F;strong&gt; like GPT-4 are commonly used due to their strong performance.&lt;&#x2F;p&gt;
&lt;p&gt;However, relying on closed models presents challenges related to data privacy ğŸ”’, transparency, controllability, and cost ğŸ’¸.&lt;&#x2F;p&gt;
&lt;p&gt;On the other hand, &lt;strong&gt;open models&lt;&#x2F;strong&gt; typically do not correlate well with human judgments and lack flexibility.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ”¥ &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2405.01535&quot;&gt;Prometheus 2&lt;&#x2F;a&gt; (by KAIST AI) is a new family of open-source models designed to address these gaps:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;two variants (&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;prometheus-eval&#x2F;prometheus-7b-v2.0&quot;&gt;7B&lt;&#x2F;a&gt; and &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;prometheus-eval&#x2F;prometheus-8x7b-v2.0&quot;&gt;8x7B&lt;&#x2F;a&gt;)&lt;&#x2F;li&gt;
&lt;li&gt;trained on open-source data&lt;&#x2F;li&gt;
&lt;li&gt;high correlation with human evaluations and proprietary models&lt;&#x2F;li&gt;
&lt;li&gt;highly flexible: capable of performing direct assessments and pairwise rankings, and allowing the definition of custom evaluation criteria.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;I experimented with Prometheus 2 + Haystack to evaluate RAG across different dimensions.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;blog&#x2F;rag-evaluation-with-prometheus-2&quot;&gt;ğŸ“ Blog post&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;prometheus2_evaluation&quot;&gt;ğŸ““ Notebook&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">Learn how to evaluate RAG pipelines with an open model.</summary>
        </entry><entry xml:lang="en">
        <title>âš™ï¸ Prompt Optimization with Haystack + DSPy</title>
        <published>2024-06-05T00:00:00+00:00</published>
        <updated>2024-06-05T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/haystack-dspy/" type="text/html"/>
        <id>https://anakin87.github.io/blog/haystack-dspy/</id>
        
            <content type="html">&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;haystack-dspy&#x2F;haystack_dspy.jpeg&quot; alt=&quot;Haystack + DSPy&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;When building applications with LLMs, writing effective prompts is a long process of trial and error. ğŸ”„&lt;&#x2F;p&gt;
&lt;p&gt;Often, if you switch models, you also have to change the prompt. ğŸ˜©&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What if you could automate this process?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ’¡ Thatâ€™s where DSPy comes in - a framework designed to algorithmically optimize prompts for Language Models.&lt;&#x2F;p&gt;
&lt;p&gt;By applying classical machine learning concepts (training and evaluation data, metrics, optimization), DSPy generates better prompts for a given model and task.&lt;&#x2F;p&gt;
&lt;p&gt;Recently, I explored combining DSPy with the robustness of Haystack Pipelines.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Check out the &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;prompt_optimization_with_dspy&quot;&gt;ğŸ§ªğŸ““ experimental notebook&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Hereâ€™s how it works:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;â–¶ï¸ Start from a Haystack RAG pipeline with a basic prompt&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ¯ Define a goal (in this case, get correct and concise answers)&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ“Š Create a DSPy program, define data and metrics&lt;&#x2F;li&gt;
&lt;li&gt;âœ¨ Optimize and evaluate -&amp;gt; improved prompt&lt;&#x2F;li&gt;
&lt;li&gt;ğŸš€ Build a refined Haystack RAG pipeline using the optimized prompt&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">Automate prompt engineering with DSPy and Haystack.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ§‘â€ğŸ« AutoQuizzer: create a quiz from a URL and play&#x2F;let the LLM play</title>
        <published>2024-05-16T00:00:00+00:00</published>
        <updated>2024-05-16T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/autoquizzer/" type="text/html"/>
        <id>https://anakin87.github.io/blog/autoquizzer/</id>
        
            <content type="html">&lt;!-- toc --&gt;
&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;&#x2F;h2&gt;
&lt;p&gt;Do you want to play a game against Llama 3? ğŸ¦™ğŸ¦™ğŸ¦™&lt;&#x2F;p&gt;
&lt;p&gt;Meet &lt;strong&gt;ğŸ§‘â€ğŸ« AutoQuizzer&lt;&#x2F;strong&gt;, a new LLM application that you can use for learning or just for fun.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Try it out on &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;deepset&#x2F;autoquizzer&quot;&gt;ğŸ¤— Hugging Face Spaces&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;how-it-works&quot;&gt;How it works&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;anakin87&#x2F;autoquizzer&#x2F;main&#x2F;autoquizzer.png&quot; alt=&quot;AutoQuizzer&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;You provide an URL -&amp;gt; A multiple-choice quiz is instantly generated.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;You can play the quiz yourself.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;You can let the LLM play in two different ways&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ“• Closed book: the LLM responds only by knowing the general topic and using its parametric knowledge and reasoning abilities.&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ”ğŸŒ Web RAG: for each question, a Google search is done and the top 3 snippets are included in the prompt for the LLM.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;Stack&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ—ï¸ Haystack LLM framework&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ¦™ Llama 3 8B Instruct&lt;&#x2F;li&gt;
&lt;li&gt;âš¡ Groq&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Original idea: Tuana Ã‡elik&lt;&#x2F;p&gt;
&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ¬ Project walkthrough video by Tuana Ã‡elik: &lt;div &gt;
    &lt;iframe src=&quot;https:&#x2F;&#x2F;www.youtube-nocookie.com&#x2F;embed&#x2F;C1oJ1ArYYZA&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;&#x2F;iframe&gt;
&lt;&#x2F;div&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;anakin87&#x2F;autoquizzer&quot;&gt;ğŸ‘¨â€ğŸ’» Code&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.theregister.com&#x2F;2024&#x2F;05&#x2F;29&#x2F;autoquizzer_llm_quiz_generation&#x2F;&quot;&gt;ğŸ“° LLMs can write and answer quizzes â€“ but arenâ€™t quite ready to disrupt trivia night&lt;&#x2F;a&gt; - The Register&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">Learn how I built this ğŸ”¥ application.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ” Sparse Embedding Retrieval in Haystack</title>
        <published>2024-04-29T00:00:00+00:00</published>
        <updated>2024-04-29T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/splade-haystack/" type="text/html"/>
        <id>https://anakin87.github.io/blog/splade-haystack/</id>
        
            <content type="html">&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;splade-haystack&#x2F;splade_haystack.jpeg&quot; alt=&quot;Splade&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Keyword-based retrieval methods like BM25 are efficient but lack semantic understanding.&lt;&#x2F;p&gt;
&lt;p&gt;On the other hand, dense vector retrieval requires considerable computational resources and may struggle in new domains.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ’¡ &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;naver&#x2F;splade&quot;&gt;SPLADE&lt;&#x2F;a&gt;, a sparse embedding retrieval technique, tries to combine the strengths of both methods.&lt;&#x2F;p&gt;
&lt;p&gt;Leveraging Language Models like BERT, SPLADE evaluates the relevance of query terms and performs automatic term expansion.&lt;&#x2F;p&gt;
&lt;p&gt;For a deep and visual overview of SPLADE, check out &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.pinecone.io&#x2F;learn&#x2F;splade&#x2F;&quot;&gt;this article by Pinecone and James Briggs&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;SPLADE is promising and we are happy to introduce this technique into the Haystack LLM framework! ğŸ‰
This integration features:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;FastEmbed Sparse Embedders&lt;&#x2F;li&gt;
&lt;li&gt;new Qdrant retrievers.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;This integration owes much to the dedication of our community member Corentin Meyer ğŸ‘ and to the help of Qdrant folks ğŸ™Œ.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ™ A special mention also goes to Prithivi Da, who created an industry-ready SPLADE model with a permissive license.&lt;&#x2F;p&gt;
&lt;p&gt;Curious to see SPLADE in action? Check out the notebook ğŸ‘‡
&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;sparse_embedding_retrieval&quot;&gt;ğŸ““ Sparse Embedding Retrieval with Qdrant and FastEmbed&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</content>
        <summary type="html">Learn how to use SPLADE for better retrieval with Haystack + Qdrant</summary>
        </entry><entry xml:lang="en">
        <title>Playing with ğŸ¦™ Llama 3 - RAG about Oscar night ğŸ¬</title>
        <published>2024-04-19T00:00:00+00:00</published>
        <updated>2024-04-19T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/rag-oscar-night/" type="text/html"/>
        <id>https://anakin87.github.io/blog/rag-oscar-night/</id>
        
            <content type="html">&lt;p&gt;What I find great about the new Llama 3 models is that
the small 8B instruct variant outperforms larger proprietary models such as GPT-3.5-Turbo-0613
in the &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;lmarena.ai&#x2F;?leaderboard&quot;&gt;ğŸ† LMSYS Chatbot Arena&lt;&#x2F;a&gt; (crowdsourced human evaluation)!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;rag-oscar-night&#x2F;llama3_arena.jpeg&quot; alt=&quot;Llama 3 8B in LMSYS Chatbot Arena&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Ofc, you can build with Llama 3 in the Haystack LLM framework from day one ğŸ˜&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;RAG about Oscar night ğŸ†ğŸ¬&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Stack: Haystack + Snowflake Arctic embeddings + Llama3&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;llama3_rag&quot;&gt;ğŸ““ Notebook&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</content>
        </entry><entry xml:lang="en">
        <title>ğŸ¦™ğŸ“± Running Small Language Models on a cheap smartphone</title>
        <published>2024-04-09T00:00:00+00:00</published>
        <updated>2024-04-09T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/gemma-2b-orpo-phone/" type="text/html"/>
        <id>https://anakin87.github.io/blog/gemma-2b-orpo-phone/</id>
        
            <content type="html">&lt;p&gt;&lt;video src=&quot;gemma-2b-orpo-phone.mp4&quot; controls autoplay loop&gt;&lt;&#x2F;video&gt;&lt;&#x2F;p&gt;
&lt;p&gt;You may have noticed that this is not Groq ğŸ˜‰&lt;&#x2F;p&gt;
&lt;p&gt;Itâ€™s my recent small language model running on the CPU of my cheap Nokia X10 phone.&lt;&#x2F;p&gt;
&lt;p&gt;After quantizing &lt;a href=&quot;..&#x2F;gemma_2b_orpo_quantization&#x2F;&quot;&gt;gemma-2b-orpo with the GGUF format&lt;&#x2F;a&gt;,
I got eager to get it running on my phone
and I found several ways ğŸ‘‡&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ¥± &lt;strong&gt;Lazy way&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;download Layla Lite app (free APK) from their &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.layla-network.ai&#x2F;&quot;&gt;website&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;download a GGUF model&lt;&#x2F;li&gt;
&lt;li&gt;from the app settings, choose your local model and an appropriate Chat template (ChatML in my case)&lt;&#x2F;li&gt;
&lt;li&gt;put your phone in airplane mode âœˆï¸&lt;&#x2F;li&gt;
&lt;li&gt;you are ready to chat!&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;There is also a ğŸ§‘â€ğŸ’» &lt;strong&gt;hardcore way&lt;&#x2F;strong&gt;, that involves using Termux and compiling Llama.cpp on the phone ğŸ‘‡&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;14rncnb&#x2F;local_llama_on_android_phone&#x2F;&quot;&gt;reddit&#x2F;LocalLLaMA thread&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ”® This was a fun experiment that gives an idea of what we might see in the future.&lt;&#x2F;p&gt;
</content>
        </entry><entry xml:lang="en">
        <title>Quantization love ğŸ’™</title>
        <published>2024-04-08T00:00:00+00:00</published>
        <updated>2024-04-08T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/gemma-2b-orpo-quantization/" type="text/html"/>
        <id>https://anakin87.github.io/blog/gemma-2b-orpo-quantization/</id>
        
            <content type="html">&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;gemma-2b-orpo-quantization&#x2F;gemma_quantized.jpeg&quot; alt=&quot;Gemma Quantized&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;!-- toc --&gt;
&lt;h2 id=&quot;gemma-2b-orpo-gguf&quot;&gt;Gemma 2B ORPO GGUF&lt;&#x2F;h2&gt;
&lt;p&gt;I am happy to release a GGUF quantized version of &lt;a href=&quot;..&#x2F;gemma-2b-orpo&quot;&gt;ğŸ¦«ğŸ’ gemma-2b-orpo&lt;&#x2F;a&gt;: my small Language Model trained with the ORPO paradigm.&lt;&#x2F;p&gt;
&lt;p&gt;You can run this model on a CPU-only machine, using less than 2 GB of RAM!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;anakin87&#x2F;gemma-2b-orpo-GGUF&quot;&gt;ğŸ¤— Quantized Model&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Quantizing the original PyTorch model was fun, thanks to &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;kaitchup.substack.com&#x2F;p&#x2F;gguf-quantization-for-fast-and-memory&quot;&gt;this blog post by Benjamin Marie&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-is-quantization&quot;&gt;What is Quantizationâ“&lt;&#x2F;h2&gt;
&lt;p&gt;In the context of Machine Learning models, quantization involves shrinking models to run efficiently on standard devices. ğŸ“±&lt;&#x2F;p&gt;
&lt;p&gt;Various techniques exist to transform models from their original numerical representations (FP32, FP16, BF16) to more compact forms.&lt;&#x2F;p&gt;
&lt;p&gt;The aim? To slash model memory usage without severely compromising inference quality.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;crazy-exciting-times-exploding-head&quot;&gt;Crazy exciting times ğŸ¤¯&lt;&#x2F;h2&gt;
&lt;p&gt;The progress made in this field over the past 1.5 years has been stunning.&lt;&#x2F;p&gt;
&lt;p&gt;Thanks to the efforts of researchers and practitioners, a 7B language model that once required at least 15 GB of GPU VRAM can now run on a 5 GB GPU VRAM or even on a standard machine with 8 GB CPU RAM without significant quality loss.&lt;&#x2F;p&gt;
&lt;p&gt;Today, there are popular techniques such as NF4, GPTQ, AWQ, GGUF, and many other experimental ones.&lt;&#x2F;p&gt;
&lt;p&gt;Particularly, GGUF originated in ther experimentâ€™s Llama.cpp project and focuses on running LLMs on standard machines. It allows you to run an LLM on the CPU and offload some of its layers to the GPU (if available) to achieve higher speed.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;adult-school-book-resources&quot;&gt;ğŸ§‘â€ğŸ« ğŸ“– Resources&lt;&#x2F;h2&gt;
&lt;p&gt;To learn more about quantization, I found and recommend these excellent resources:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.maartengrootendorst.com&#x2F;blog&#x2F;quantization&#x2F;&quot;&gt;Beginner-friendly blog post by Maarten Grootendorst&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;mlabonne.github.io&#x2F;blog&#x2F;posts&#x2F;Introduction_to_Weight_Quantization.html&quot;&gt;Thorough series of articles by Maxime Labonne&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">Notes on LLM Quantization.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ’ gemma-2b-orpo: a Small Language Model trained with ORPO</title>
        <published>2024-03-26T00:00:00+00:00</published>
        <updated>2024-03-26T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/gemma-2b-orpo/" type="text/html"/>
        <id>https://anakin87.github.io/blog/gemma-2b-orpo/</id>
        
            <content type="html">&lt;div class=&quot;admonition tip&quot;&gt;
    &lt;div class=&quot;admonition-icon admonition-icon-tip&quot;&gt;&lt;&#x2F;div&gt;
    &lt;div class=&quot;admonition-content&quot;&gt;
        &lt;strong class=&quot;admonition-title&quot;&gt;TIP&lt;&#x2F;strong&gt;
        &lt;p&gt;ğŸ’» You can find the Training code on &lt;strong&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;anakin87&#x2F;gemma-2b-orpo&#x2F;blob&#x2F;main&#x2F;notebooks&#x2F;training.ipynb&quot;&gt;this notebook&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;.
For a short intro, read on!&lt;&#x2F;p&gt;

    &lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;gemma-2b-orpo&#x2F;gemma-2b-orpo.png&quot; alt=&quot;Gemma 2B ORPO&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;!-- toc --&gt;
&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;&#x2F;h2&gt;
&lt;p&gt;Meet my weekend experiment: gemma-2b-orpo&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ‘‰ &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;anakin87&#x2F;gemma-2b-orpo&quot;&gt;Model&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;A Small Language Model trained from google&#x2F;gemma-2b base model using ORPO.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-is-orpo&quot;&gt;What is ORPO?&lt;&#x2F;h2&gt;
&lt;p&gt;It stands for Odds Ratio Preference Optimization and is a new training paradigm for Language Models.&lt;&#x2F;p&gt;
&lt;p&gt;Typically, to obtain a helpful LM, you start with a pre-trained model, perform Supervised Fine-Tuning (SFT), and then Preference Alignment (with methods like RLHF or DPO). So far, these two steps have been necessary to achieve a model that follows instructions but is also aligned with human preferences.&lt;&#x2F;p&gt;
&lt;p&gt;ORPO collapses these two steps into one.&lt;&#x2F;p&gt;
&lt;p&gt;Working with preference data, this method introduces a penalty (based on log odds ratio) to the NLL loss function, to favor generations in the chosen response sets.&lt;&#x2F;p&gt;
&lt;p&gt;The first applications of ORPO show âš¡ï¸ faster training, lower memory usage and good results!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;my-small-weeekend-language-model&quot;&gt;â˜€ï¸ My Small (weeekend) Language Model&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Started with gemma-2b base model&lt;&#x2F;li&gt;
&lt;li&gt;Installed Hugging Face TRL from the main branch to use the new ORPOTrainer âœ¨&lt;&#x2F;li&gt;
&lt;li&gt;Chose a good dataset: &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;alvarobartt&#x2F;dpo-mix-7k-simplified&quot;&gt;dpo-mix-7k-simplified&lt;&#x2F;a&gt; by Ãlvaro BartolomÃ© del Canto and the Argilla friends&lt;&#x2F;li&gt;
&lt;li&gt;Trained the model for 4 hours on an NVIDIA A40 GPU (&amp;lt;3$ on RunPod)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;ğŸ“Š The model performs well for its size, with good results on the Nous Research benchmark suite ğŸŒ&lt;&#x2F;p&gt;
&lt;h2 id=&quot;books-resources&quot;&gt;ğŸ“š Resources&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2403.07691&quot;&gt;ORPO: Monolithic Preference Optimization without Reference Model&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;anakin87&#x2F;gemma-2b-orpo&#x2F;blob&#x2F;main&#x2F;notebooks&#x2F;training.ipynb&quot;&gt;gemma-2b-orpo Training notebook ğŸ““&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;anakin87&#x2F;gemma-2b-orpo&#x2F;blob&#x2F;main&#x2F;notebooks&#x2F;usage.ipynb&quot;&gt;gemma-2b-orpo Usage notebook (with the Haystack framework ğŸ’™)&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">Learn how fine-tuned a Small Language Model, collapsing SFT+DPO into a single step with ORPO.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ§ªğŸ¦â€â¬›ğŸ“‘ From raw text to structured data with open LLMs and function calling</title>
        <published>2024-03-20T00:00:00+00:00</published>
        <updated>2024-03-20T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/raven-info-extraction/" type="text/html"/>
        <id>https://anakin87.github.io/blog/raven-info-extraction/</id>
        
            <content type="html">&lt;!-- toc --&gt;
&lt;h2 id=&quot;dart-the-challenge&quot;&gt;ğŸ¯ The challenge&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;you have a pile of unstructured texts from which you want to extract information in structured form&lt;&#x2F;li&gt;
&lt;li&gt;the desired information can vary dynamically&lt;&#x2F;li&gt;
&lt;li&gt;you want to combine tasks like text classification, NER, summarization, etc.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Language Models with function calling capabilities can be flexible tools ğŸ› ï¸ for this job!&lt;&#x2F;p&gt;
&lt;!-- Linking the exact notebook because it&#x27;s going to be deleted from the cookbook --&gt;
&lt;p&gt;&lt;strong&gt;ğŸ““ Take a look at the &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;colab.research.google.com&#x2F;github&#x2F;deepset-ai&#x2F;haystack-cookbook&#x2F;blob&#x2F;c4e70ea69f8f3a36133bb239a0ade70e35577e85&#x2F;notebooks&#x2F;information_extraction_raven.ipynb&quot;&gt;notebook&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;div &gt;
    &lt;iframe class=&quot;pdf&quot; src=&quot;.&amp;#x2F;raven.pdf&quot;  height=&quot;700&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;&#x2F;iframe&gt;
&lt;&#x2F;div&gt;&lt;h2 id=&quot;key-a-personal-journey&quot;&gt;ğŸ—ï¸ A (personal) journey&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;It all began with &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;gist.github.com&#x2F;kylemcdonald&#x2F;dbac21de2d7855633689f5526225154c&quot;&gt;Kyle McDonaldâ€™s gist&lt;&#x2F;a&gt;, where GPT-3.5-turbo was used to extract structured information from an article.&lt;&#x2F;li&gt;
&lt;li&gt;Fascinated by this idea, I explored the use of open models fine-tuned for function calling: I experimented with Gorilla OpenFunctions, to extract information about animals.&lt;&#x2F;li&gt;
&lt;li&gt;Now: armed with the powerful &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;Nexusflow&#x2F;NexusRaven-V2-13B&quot;&gt;ğŸ¦â€â¬› NexusRaven V2 model&lt;&#x2F;a&gt; (by Nexusflow) and Haystack 2.0, I revisited the experiment and made it more challenging.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;sparkles-results&quot;&gt;âœ¨ Results&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Haystackâ€™s LLM framework is model agnostic, so model switching went smoothly&lt;&#x2F;li&gt;
&lt;li&gt;Nexus Raven outperforms Gorilla OpenFunctions for this use case&lt;&#x2F;li&gt;
&lt;li&gt;Using a statistical model carries some caveats, which I have outlined in the notebook.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;â€œLetâ€™s unlock the potential of unstructured text, one function call at a time.â€&lt;&#x2F;p&gt;
&lt;p&gt;â˜ The last sentence is generated by ChatGPT, but I found it silly and funny. ğŸ˜&lt;&#x2F;p&gt;
</content>
        <summary type="html">Discover a hacky but effective way to extract structured using open LLMs with function calling capabilities (NexusRaven V2)</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ§­ Choosing an embedding inference solution for open models</title>
        <published>2024-03-10T00:00:00+00:00</published>
        <updated>2024-03-10T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/embedding-inference/" type="text/html"/>
        <id>https://anakin87.github.io/blog/embedding-inference/</id>
        
            <content type="html">&lt;!-- toc --&gt;
&lt;p&gt;These days we have many good open embedding models - think for example of the models released by Mixedbread a few days ago.&lt;&#x2F;p&gt;
&lt;p&gt;There are also several libraries to use&#x2F;serve them.
Navigating this landscape can be complex, so letâ€™s explore together (thanks to Luca Santuari for the question). ğŸ‘‡&lt;&#x2F;p&gt;
&lt;h2 id=&quot;sentence-transformers&quot;&gt;â­ Sentence Transformers&lt;&#x2F;h2&gt;
&lt;p&gt;A cornerstone library for computing text embeddings. Most of the embedding models available on Hugging Face are compatible with it.&lt;&#x2F;p&gt;
&lt;p&gt;Originally developed by Ubiquitous Knowledge Processing (UKP) Lab and Nils Reimers, it was recently revamped by HuggingFace and is maintained by Tom Aarsen. ğŸ’™&lt;&#x2F;p&gt;
&lt;p&gt;Python library, depends on PyTorch, may not be the most efficient and fast. Runs best on GPU.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;2025 Update&lt;&#x2F;strong&gt;: Sentence Transformers now also offers ONNX and OpenVINO support, for speeding up inference on different hardware.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;rocket-hf-text-embeddings-inference&quot;&gt;ğŸš€ HF Text Embeddings Inference&lt;&#x2F;h2&gt;
&lt;p&gt;Toolkit for deploying and serving open-source text embedding models.&lt;&#x2F;p&gt;
&lt;p&gt;Very fast and efficient: based on the Rust candle framework. Runs via docker and supports both CPU and GPU.&lt;&#x2F;p&gt;
&lt;p&gt;Compatible with several Sentence Transformers model architectures.&lt;&#x2F;p&gt;
&lt;p&gt;Not fully liberal open source license.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;2025 Update&lt;&#x2F;strong&gt;: Switched to Apache 2.0 license. ğŸ‰&lt;&#x2F;p&gt;
&lt;h2 id=&quot;hugs-hf-optimum&quot;&gt;ğŸ¤— HF Optimum&lt;&#x2F;h2&gt;
&lt;p&gt;This project is an extension of Transformers that provides a set of performance optimization tools to train and run models with maximum efficiency.&lt;&#x2F;p&gt;
&lt;p&gt;It supports different specialized hardware options from various vendors (Nvidia, Intelâ€¦) and the cross-platform ONNX runtime.&lt;&#x2F;p&gt;
&lt;p&gt;This toolkit can also be used to compute embeddings with different and efficient CPU and GPU options.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;zap-fastembed&quot;&gt;âš¡ï¸ FastEmbed&lt;&#x2F;h2&gt;
&lt;p&gt;Originally developed by Nirant Kasliwal and maintained by Qdrant, this library provides fast and efficient embedding generation. Easy to use.
It is based on the ONNX runtime and runs on CPU and GPU. Supports a limited but growing selection of models.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;llama-ollama&quot;&gt;ğŸ¦™ Ollama&lt;&#x2F;h2&gt;
&lt;p&gt;Very popular library for LLM serving on standard machines, using the GGUF quantized format.
Recently improved support for embedding models. It uses CPU and GPU if available.
The embedding functionality is still immature compared to previous solutions, but it might make sense if you already use it for Generative Language Models.&lt;&#x2F;p&gt;
&lt;p&gt;You know what? ğŸ˜‰ All of these solutions are supported by the Haystack LLM framework ğŸ‘‰ https:&#x2F;&#x2F;docs.haystack.deepset.ai&#x2F;docs&#x2F;embedders&lt;&#x2F;p&gt;
&lt;p&gt;A special mention goes to â™¾ï¸ Infinity, by Michael Feil, which I have not tried yet, but looks great!&lt;&#x2F;p&gt;
</content>
        <summary type="html">Notes on the landscape of embedding inference solutions&#x2F;libraries for open models</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ§‘â€ğŸ« LLMs 4 Devs: from 0 to your 1st LLM application</title>
        <published>2024-03-08T00:00:00+00:00</published>
        <updated>2024-03-08T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/llm4devs/" type="text/html"/>
        <id>https://anakin87.github.io/blog/llm4devs/</id>
        
            <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;&#x2F;h2&gt;
&lt;p&gt;The rise of ChatGPT and Large Language Models has revolutionized the tech landscape, leaving developers overwhelmed by the infinite opportunities and intrigued by the technical challenges posed by their complex nature.
This session provides a developer-centric introduction to LLMs, focused on practical applications. No pre-existing knowledge of LLMs and NLP is required.&lt;&#x2F;p&gt;
&lt;p&gt;You will gain insights into: using closed and open-source models, how to effectively prompt LLMs, vector databases, implementing Retrieval Augmented Generation applications (answer generation based on your data), building more complex applications.&lt;&#x2F;p&gt;
&lt;p&gt;Through a hands-on approach, I will show code examples using open-source tools: Haystack LLM framework, Hugging Face Transformers, Ollama, and more. I will also show how you can switch from proprietary to open models.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ¿ Talk - 1st edition - Open Source Day 2024: &lt;div &gt;
    &lt;iframe src=&quot;https:&#x2F;&#x2F;www.youtube-nocookie.com&#x2F;embed&#x2F;L6sUztYJXT8&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;&#x2F;iframe&gt;
&lt;&#x2F;div&gt;&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ¿ Talk - 2nd edition - PyCon Italy 2024: &lt;div &gt;
    &lt;iframe src=&quot;https:&#x2F;&#x2F;www.youtube-nocookie.com&#x2F;embed&#x2F;R_C0IJmAHrQ&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;&#x2F;iframe&gt;
&lt;&#x2F;div&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;anakin87&#x2F;llm4devs&quot;&gt;Repository with slides, code, and more&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">Introductory talk on LLMs for developers</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ™ï¸ Haystack Podcasts</title>
        <published>2024-03-01T00:00:00+00:00</published>
        <updated>2024-03-01T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/haystack-podcasts/" type="text/html"/>
        <id>https://anakin87.github.io/blog/haystack-podcasts/</id>
        
            <content type="html">&lt;p&gt;Two Italian podcasts where I was interviewed with my colleagues about Haystack, LLMs and open source:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ¤ &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;pointerpodcast.it&#x2F;p&#x2F;pointer183-haystack-creare-llm-applications-in-modo-facile-con-stefano-fiorucci-e-sara-zanzottera&#x2F;&quot;&gt;Pointer Podcast: Haystack, creare LLM Applications in modo facile - con Sara Zanzottera&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ¤ Intevista Pythonista: Haystack. Un framework open per app LLM. - con Massimiliano Pippi
&lt;div &gt;
    &lt;iframe src=&quot;https:&#x2F;&#x2F;www.youtube-nocookie.com&#x2F;embed&#x2F;HwhR1wb-0t4&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;&#x2F;iframe&gt;
&lt;&#x2F;div&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">A collection of podcasts interviews about the Haystack LLM orchestration framework</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ’ Playing with Gemma</title>
        <published>2024-02-21T00:00:00+00:00</published>
        <updated>2024-02-21T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/gemma-haystack/" type="text/html"/>
        <id>https://anakin87.github.io/blog/gemma-haystack/</id>
        
            <content type="html">&lt;p&gt;Everyone is excited about Gemma, the new family of open Language Models by Google DeepMind:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ”¹ different sizes (2B and 7B)&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ”¹ base models and instruction-tuned models&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ”¹ can be commercially used!&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;I tried it right away! ğŸ”¥&lt;&#x2F;p&gt;
&lt;p&gt;In Colab, using the Haystack LLM framework&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ”¸ Chat with Gemma (travel assistant) ğŸ›©&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ”¸ RAG with Gemma (about Rock music) ğŸ¸&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;ğŸ““ Here is the &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;colab.research.google.com&#x2F;github&#x2F;deepset-ai&#x2F;haystack-cookbook&#x2F;blob&#x2F;c4e70ea69f8f3a36133bb239a0ade70e35577e85&#x2F;notebooks&#x2F;gemma_chat_rag.ipynb&quot;&gt;notebook&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</content>
        </entry><entry xml:lang="en">
        <title>ğŸ§©ğŸ§© Merging Language Models: what I&#x27;ve learned</title>
        <published>2024-02-05T00:00:00+00:00</published>
        <updated>2024-02-05T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/model-merging/" type="text/html"/>
        <id>https://anakin87.github.io/blog/model-merging/</id>
        
            <content type="html">&lt;!-- toc --&gt;
&lt;p&gt;Merging LLMs is a recent trend in the AI community, with merged models taking the top ranks in Language Models leaderboards.
Using &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;arcee-ai&#x2F;mergekit&quot;&gt;mergekit&lt;&#x2F;a&gt;, merging LLMs is easy and you donâ€™t even need a GPU!&lt;&#x2F;p&gt;
&lt;p&gt;But how does it work?&lt;&#x2F;p&gt;
&lt;h2 id=&quot;why-merging-models&quot;&gt;Why merging models?&lt;&#x2F;h2&gt;
&lt;p&gt;Traditionally, models are fine-tuned to acquire new capabilities - a process demanding time and resources.&lt;&#x2F;p&gt;
&lt;p&gt;Model merging allows combining the capabilities of two (or more) existing models, without fine-tuning.&lt;&#x2F;p&gt;
&lt;p&gt;It is possible, for example, to combine two 7B models (one good at conversation ğŸ’¬, the other good at math ğŸ§®) to make a single 7B model with similar abilities to the original models.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;model-merging&#x2F;model_merging.jpeg&quot; alt=&quot;Model merging&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;gear-what-happens-under-the-hood&quot;&gt;âš™ï¸ What happens under the hood?&lt;&#x2F;h2&gt;
&lt;p&gt;We often think of a Generative Language Model as a text-generation machine.&lt;&#x2F;p&gt;
&lt;p&gt;We can also see it as a neural network: a matrix of weights (scalars) + activation functions.&lt;&#x2F;p&gt;
&lt;p&gt;Model merging manipulates these weights mathematically&#x2F;geometrically without training.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;tools-techniques&quot;&gt;ğŸ› ï¸ Techniques&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The simplest approach involves merging models by computing a weighted average of their weights -&amp;gt; Model soups ğŸ¥£&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;SLERP (Spherical Linear Interpolation) is a more advanced interpolation method that ensures better preservation of distinct characteristics from the original models.
This method is very popular and has been used to create SOTA merged models!&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2212.04089&quot;&gt;â€œEditing Models with Task Arithmeticâ€ paper&lt;&#x2F;a&gt; introduced the concept of â€œtask vectorâ€: the vector associated with a specific task&#x2F;capability.
It is obtained by subtracting the weights of a pre-trained model from the weights of the same model after fine-tuning.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;By manipulating these task vectors through addition or subtraction, more targeted model merges become feasible.&lt;&#x2F;p&gt;
&lt;p&gt;Recent techniques like TIES and DARE build upon the Task Arithmetic framework, enabling the merging of a larger number of models while retaining their strengths.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;crystal-ball-looking-ahead&quot;&gt;ğŸ”® Looking ahead&lt;&#x2F;h2&gt;
&lt;p&gt;Merging LLMs seems promising, allowing the production of good models quickly and inexpensively.
Charles Goddard, the creator of mergekit, has recently joined Arcee AI (quite active in the area of Small Language Models) and I expect progress in this fieldâ€¦&lt;&#x2F;p&gt;
&lt;h2 id=&quot;books-resources&quot;&gt;ğŸ“š Resources&lt;&#x2F;h2&gt;
&lt;p&gt;Check out these great blog posts:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;mlabonne.github.io&#x2F;blog&#x2F;posts&#x2F;2024-01-08_Merge_LLMs_with_mergekit.html&quot;&gt;Merge Large Language Models with mergekit&lt;&#x2F;a&gt; by Maxime Labonne&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;slgero.medium.com&#x2F;merge-large-language-models-29897aeb1d1a&quot;&gt;Merge Large Language Models&lt;&#x2F;a&gt; by Sergei Savvov&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Also Omar Sanseviero recently experimented with these techniques.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ§ª &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;posts&#x2F;osanseviero&#x2F;691474247332404&quot;&gt;Recap&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ“– &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;collections&#x2F;osanseviero&#x2F;model-merging-65097893623330a3a51ead66&quot;&gt;Collection of papers&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        </entry><entry xml:lang="en">
        <title>Can Language Models self-improve? ğŸ‹ï¸ğŸ“ˆ</title>
        <published>2024-01-22T00:00:00+00:00</published>
        <updated>2024-01-22T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/self-rewarding-llms/" type="text/html"/>
        <id>https://anakin87.github.io/blog/self-rewarding-llms/</id>
        
            <content type="html">&lt;!-- toc --&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;self-rewarding-llms&#x2F;self_rewarding.gif&quot; alt=&quot;Self-Rewarding Language Models&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;&#x2F;h2&gt;
&lt;p&gt;Can Language Models self-improve?&lt;&#x2F;p&gt;
&lt;p&gt;A &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2401.10020&quot;&gt;recent paper&lt;&#x2F;a&gt; by Meta and NYU also tackles this topic and the answer is:
yes, to some extent.&lt;&#x2F;p&gt;
&lt;p&gt;In â€œSelf-Rewarding Language Modelsâ€, they propose a novel iterative training approach.&lt;&#x2F;p&gt;
&lt;p&gt;Letâ€™s briefly recall the &lt;strong&gt;common approach to train LLMs&lt;&#x2F;strong&gt;:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Start with a pretrained base Language Model, capable of generating text but not following instructions.&lt;&#x2F;li&gt;
&lt;li&gt;Supervised Fine-Tuning (SFT): train the base model on an instruction dataset.&lt;&#x2F;li&gt;
&lt;li&gt;Alignment to human preferences: further train the model using (human or AI) preference data.
This step can be performed with RLHF or simpler techniques like Direct Preference Optimization (DPO)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;bookmark-tabs-self-rewarding-language-models&quot;&gt;ğŸ“‘ Self-Rewarding Language Models&lt;&#x2F;h2&gt;
&lt;ol start=&quot;0&quot;&gt;
&lt;li&gt;
&lt;p&gt;Start from a base model (Llama 2 70B) -&amp;gt; Model M0&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Warm start: train the base model (SFT) using the Open Assistant dataset -&amp;gt; Model M1&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Notably, Evaluation Fine Tuning data is used to teach the model to act as a Judge.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Self-Instruction creation ğŸ’¡&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;given new prompts (generated with the Self-Instruct approach), Model M1 generates candidate responses.&lt;&#x2F;li&gt;
&lt;li&gt;Model M1 evaluates the candidate responses (LLM-as-a-Judge approach).&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;AI Feedback Training: the generated preference pairs are used to train Model M1 via DPO -&amp;gt; Model M2&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;ğŸ”„ Repeat steps 2 and 3&lt;&#x2F;p&gt;
&lt;h2 id=&quot;bar-chart-experimental-results&quot;&gt;ğŸ“Š Experimental results&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;ğŸŒ±ğŸŒ± The trained models exhibit progressively stronger capabilities in both instruction following and self-rewarding.&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ“ˆ the M3 Model strongly outperforms previous iterations on AlpacaEval 2.0&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ† the M3 Model shows good overall performance on AlpacaEval 2.0: its win rate vs GPT-4 Turbo is on par with larger proprietary models&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;ğŸ”® Despite the limitations highlighted in the paper, IMHO this is an interesting and promising direction!&lt;&#x2F;p&gt;
</content>
        <summary type="html">Notes on the Self-Rewarding Language Models paper</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ¦™ Ollama lands in the Haystack ecosystem</title>
        <published>2024-01-09T00:00:00+00:00</published>
        <updated>2024-01-09T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/ollama-haystack/" type="text/html"/>
        <id>https://anakin87.github.io/blog/ollama-haystack/</id>
        
            <content type="html">&lt;p&gt;ğŸ‰ Today Iâ€™m very happy to announce the integration between the Haystack LLM orchestration framework and the Ollama project.&lt;&#x2F;p&gt;
&lt;p&gt;Ollama is the equivalent of ğŸ³ Docker for LLMs:
a smart and easy way to pack and run quantized LLMs everywhere, even in cheap laptops (wo GPUs).&lt;&#x2F;p&gt;
&lt;p&gt;This integration, driven by community demand, was also implemented by the community:
thanks Alistair Rogers and Sachin Sachdeva! ğŸ™Œ&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ¿ğŸ¬ In the image, I am seeking movie suggestions from the great Notus 7B model (by Argilla ğŸ’•).&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;ollama-haystack&#x2F;ollama_haystack.jpeg&quot; alt=&quot;Ollama in action&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;books-resources&quot;&gt;ğŸ“š Resources&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;integrations&#x2F;ollama&quot;&gt;Haystack-Ollama integration page&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;docs.haystack.deepset.ai&#x2F;docs&#x2F;ollamachatgenerator&quot;&gt;Haystack-Ollama docs&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=8qqaqefugWQ&quot;&gt;Video tutorial by Mervin Praison&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        </entry><entry xml:lang="en">
        <title>ğŸ¦™ Ollama - beyond the surface (unpolished notes)</title>
        <published>2024-01-05T00:00:00+00:00</published>
        <updated>2024-01-05T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/ollama/" type="text/html"/>
        <id>https://anakin87.github.io/blog/ollama/</id>
        
            <content type="html">&lt;p&gt;If you are in the LLM game, chances are youâ€™ve come across Ollama.
These days I am doing a deep dive on it (for something that will be announced soon).&lt;&#x2F;p&gt;
&lt;p&gt;The official project description is â€œGet up and running with large language models locallyâ€.&lt;&#x2F;p&gt;
&lt;p&gt;Iâ€™d go a step further: itâ€™s akin to &lt;strong&gt;Docker for LLMs&lt;&#x2F;strong&gt;.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;you can quickly run models on different operating systems&lt;&#x2F;li&gt;
&lt;li&gt;you can package models and templates for reproducible runs (using a Modelfile)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Letâ€™s delve a bit deeper ğŸ•µï¸&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;locally&lt;&#x2F;strong&gt; means your cheap laptop (no GPU for LLM inference), your Mac or even a server located anywhere&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;llama.cpp popularized the idea of running LLMs on a standard laptop and introduced the GGUF quantized format, to perform inference on CPU (+GPU if available).
Ollama abstracts away the complexity of installing llama.cpp on different platforms.&lt;&#x2F;p&gt;
&lt;p&gt;Using GGUF models in Ollama is as simple as typing &lt;code&gt;ollama run llama2&lt;&#x2F;code&gt; or &lt;code&gt;ollama run llama2:7b-text-q5_K_M&lt;&#x2F;code&gt; (to specify quantization options).&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;the goal of Ollama is to easily run LLMs everywhere. In contrast, vLLM and TGI are robust solutions for LLM inference&#x2F;serving on GPUs.
Although the goals are quite different, I can see some overlap in the future, if Ollama becomes one of the default ways for running open-source language models.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        </entry><entry xml:lang="en">
        <title>ğŸ‡®ğŸ‡¹ğŸ‡¬ğŸ‡§ Multilingual RAG from a ğŸ§ podcast</title>
        <published>2024-01-03T00:00:00+00:00</published>
        <updated>2024-01-03T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/multilingual-rag-podcast/" type="text/html"/>
        <id>https://anakin87.github.io/blog/multilingual-rag-podcast/</id>
        
            <content type="html">&lt;!-- toc --&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;multilingual-rag-podcast&#x2F;thumbnail.jpeg&quot; alt=&quot;Multilingual RAG from a podcast&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;idea&quot;&gt;Idea&lt;&#x2F;h2&gt;
&lt;p&gt;Happy new year, LLM aficionados!&lt;&#x2F;p&gt;
&lt;p&gt;A few weeks ago &lt;a href=&quot;..&#x2F;haystack-podcasts&quot;&gt;Sara Zanzottera and I were interviewed on the PointerPodcast&lt;&#x2F;a&gt;.
We talked about LLMs, open-source, RAGâ€¦ It was a blast!
Unfortunately, you can only enjoy it if you know Italianâ€¦&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ§ª So I came up with an experimental idea: create a multilingual RAG app based on that podcast.
This means you can pose questions in English and receive responses in English, even if the original content is in Italian.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;toolbox-the-open-source-stack&quot;&gt;ğŸ§° The open-source stack&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Haystack LLM orchestration framework, to build indexing and RAG pipelines&lt;&#x2F;li&gt;
&lt;li&gt;Whisper model for transcribing audio into text&lt;&#x2F;li&gt;
&lt;li&gt;Qdrant vector database to efficiently store and search embeddings corresponding to different chunks&lt;&#x2F;li&gt;
&lt;li&gt;intfloat&#x2F;multilingual-e5-large: a good multilingual embedding model&lt;&#x2F;li&gt;
&lt;li&gt;Mixtral 8x7B Instruct-v0.1: the powerful multilingual mixture of experts model&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“’ Explore the &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;multilingual_rag_podcast&quot;&gt;notebook&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;paperclip-findings&quot;&gt;ğŸ“ Findings&lt;&#x2F;h2&gt;
&lt;p&gt;Although the transcription does not have excellent quality (I used Whisper small), the application works quite well.&lt;&#x2F;p&gt;
&lt;p&gt;Mixtral can easily handle information in Italian and use it to formulate answers in English, without an intermediate translation step.&lt;&#x2F;p&gt;
</content>
        <summary type="html">Learn how to build a multilingual RAG pipeline based on a podcast episode transcript</summary>
        </entry>
</feed>
