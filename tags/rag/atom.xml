<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet href="https://anakin87.github.io/feed_style.xsl" type="text/xsl"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <tabi:metadata xmlns:tabi="https://github.com/welpo/tabi">
        <tabi:base_url>https:&#x2F;&#x2F;anakin87.github.io&#x2F;</tabi:base_url>
        <tabi:separator>
            â€¢
        </tabi:separator>
        <tabi:about_feeds>This is a web feed, also known as an Atom feed. Subscribe by copying the URL from the address bar into your newsreader. Visit About Feeds to learn more and get started. It&#x27;s free.</tabi:about_feeds>
        <tabi:visit_the_site>Visit website</tabi:visit_the_site>
        <tabi:recent_posts>Recent posts</tabi:recent_posts>
        <tabi:last_updated_on>Updated on $DATE</tabi:last_updated_on>
        <tabi:default_theme></tabi:default_theme>
        <tabi:post_listing_date>date</tabi:post_listing_date>
        <tabi:current_section>RAG</tabi:current_section>
    </tabi:metadata><link rel="extra-stylesheet" href="https://anakin87.github.io/skins/indigo_ingot.css?h=d429472afbb246441b1a" /><title>~/anakin87 - RAG</title>
        <subtitle>Personal website of Stefano Fiorucci, AI&#x2F;NLP&#x2F;Software Engineer.</subtitle>
    <link href="https://anakin87.github.io/tags/rag/atom.xml" rel="self" type="application/atom+xml"/>
    <link href="https://anakin87.github.io/tags/rag/" rel="alternate" type="text/html"/>
    <generator uri="https://www.getzola.org/">Zola</generator><updated>2025-08-07T00:00:00+00:00</updated><id>https://anakin87.github.io/tags/rag/atom.xml</id><entry xml:lang="en">
        <title>Haystack can now see ğŸ‘€</title>
        <published>2025-08-07T00:00:00+00:00</published>
        <updated>2025-08-07T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/haystack-image/" type="text/html"/>
        <id>https://anakin87.github.io/blog/haystack-image/</id>
        
            <content type="html">&lt;!-- toc --&gt;
&lt;p&gt;The 2.16.0 Haystack release adds a long-requested feature: &lt;strong&gt;image support&lt;&#x2F;strong&gt;!&lt;&#x2F;p&gt;
&lt;p&gt;This isnâ€™t just about passing images to an LLM. We built several features to enable practical multimodal use cases.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Whatâ€™s new?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ§  Support for multiple LLM providers: OpenAI, Amazon Bedrock, Google Gemini, Mistral AI, NVIDIA, OpenRouter, Ollama and more&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ›ï¸ Prompt template language to handle structured inputs, including images&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ“„ PDF and image converters&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ§¾ LLM-based extractor to pull text from images&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ” Image embedders using CLIP-like models&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ§© Components to build multimodal RAG pipelines and Agents&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;I had the chance of leading this effort with Sebastian Husch Lee (great collab).&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ““ Below you can find two notebooks to explore the new features:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;multimodal_intro&quot;&gt;Introduction to Multimodal Text Generation&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;tutorials&#x2F;46_multimodal_rag&quot;&gt;Creating Vision+Text RAG Pipelines&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;(ğŸ–¼ï¸ image by Bilge YÃ¼cel)&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;haystack-image&#x2F;image_agent.webp&quot; alt=&quot;Image Agent&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
</content>
        <summary type="html">Image support landed in Haystack! Tutorials inside.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ›¡ï¸ AI Guardrails with Open Language Models</title>
        <published>2025-07-03T00:00:00+00:00</published>
        <updated>2025-07-03T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/ai-guardrails/" type="text/html"/>
        <id>https://anakin87.github.io/blog/ai-guardrails/</id>
        
            <content type="html">&lt;div class=&quot;admonition tip&quot;&gt;
    &lt;div class=&quot;admonition-icon admonition-icon-tip&quot;&gt;&lt;&#x2F;div&gt;
    &lt;div class=&quot;admonition-content&quot;&gt;
        &lt;strong class=&quot;admonition-title&quot;&gt;TIP&lt;&#x2F;strong&gt;
        &lt;p&gt;Here is a tutorial on how to implement Content Moderation and Safety with Open Language Models.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;safety_moderation_open_lms&quot;&gt;ğŸ““ Notebook&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;For a short intro, read on!&lt;&#x2F;p&gt;

    &lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;ai-guardrails&#x2F;ai-guardrails.png&quot; alt=&quot;AI Guardrails with Open Language Models&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;How do you ensure your AI application is safe from harmful or inappropriate user inputs?&lt;&#x2F;p&gt;
&lt;p&gt;This is a core requirement for real-world AI deployments. Luckily, several open Language Models are built specifically for safety moderation.&lt;&#x2F;p&gt;
&lt;p&gt;Iâ€™ve been exploring them and put together a hands-on tutorial using the Haystack framework to build your own AI guardrails.&lt;&#x2F;p&gt;
&lt;p&gt;In the &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;safety_moderation_open_lms&quot;&gt;notebook&lt;&#x2F;a&gt;, youâ€™ll learn how to use and customize:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Meta Llama Guard (via Hugging Face API)&lt;&#x2F;li&gt;
&lt;li&gt;Google ShieldGemma (via Ollama)&lt;&#x2F;li&gt;
&lt;li&gt;IBM Granite Guardian (via Ollama), which can also evaluate RAG specific risk dimensions&lt;&#x2F;li&gt;
&lt;li&gt;NVIDIA NemoGuard models family, including a model for topic control&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Youâ€™ll also see how to integrate content moderation into a ğŸ” RAG pipeline.&lt;&#x2F;p&gt;
</content>
        <summary type="html">Learn how to implement Content Moderation and Safety with Open Language Models</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ•µğŸ» Agentic RAG with ğŸ¦™ Llama 3.2 3B</title>
        <published>2024-09-26T00:00:00+00:00</published>
        <updated>2024-09-26T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/agentic-rag-llama32/" type="text/html"/>
        <id>https://anakin87.github.io/blog/agentic-rag-llama32/</id>
        
            <content type="html">&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;agentic-rag-llama32&#x2F;agentic_rag_llama.jpeg&quot; alt=&quot;Agentic RAG with Llama 3.2 3B&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I was excited to explore Llama 3.2, but as a simple ğŸ‡ªğŸ‡º EU guy, I donâ€™t have access to Metaâ€™s multimodal models. ğŸ˜¿&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ¤” So I thought: why not challenge the small 3B text model with Agentic RAG?&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ¯ The plan:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Build a system that tries to answer questions using a knowledge base.&lt;&#x2F;li&gt;
&lt;li&gt;If the documents donâ€™t contain the answer, use Web search for additional context.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;Check out my &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;llama32_agentic_rag&quot;&gt;experimental notebook&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;My stack:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ—ï¸ Haystack: open-source LLM orchestration framework&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ¦™ Llama-3.2-3B-Instruct&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ¦†ğŸŒ free DuckDuckGo API, integrated with Haystack - huge thanks to Giovanni Alzetta!&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;âœ¨ &lt;em&gt;The results? Encouraging - a few months ago, this level of performance from a small model would have been unthinkable.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This probably reflects the impressive IFEval score of the model (comparable to Llama 3.1 8B).&lt;&#x2F;p&gt;
</content>
        <summary type="html">Combine RAG on a knowledge base with Web Search to intelligently answer user questions.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ§ª RAG Evaluation with ğŸ”¥ Prometheus 2</title>
        <published>2024-06-17T00:00:00+00:00</published>
        <updated>2024-06-17T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/rag-eval-prometheus/" type="text/html"/>
        <id>https://anakin87.github.io/blog/rag-eval-prometheus/</id>
        
            <content type="html">&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;rag-eval-prometheus&#x2F;prometheus.png&quot; alt=&quot;Prometheus 2&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;When evaluating LLMsâ€™ responses, &lt;strong&gt;proprietary models&lt;&#x2F;strong&gt; like GPT-4 are commonly used due to their strong performance.&lt;&#x2F;p&gt;
&lt;p&gt;However, relying on closed models presents challenges related to data privacy ğŸ”’, transparency, controllability, and cost ğŸ’¸.&lt;&#x2F;p&gt;
&lt;p&gt;On the other hand, &lt;strong&gt;open models&lt;&#x2F;strong&gt; typically do not correlate well with human judgments and lack flexibility.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ”¥ &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2405.01535&quot;&gt;Prometheus 2&lt;&#x2F;a&gt; (by KAIST AI) is a new family of open-source models designed to address these gaps:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;two variants (&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;prometheus-eval&#x2F;prometheus-7b-v2.0&quot;&gt;7B&lt;&#x2F;a&gt; and &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;prometheus-eval&#x2F;prometheus-8x7b-v2.0&quot;&gt;8x7B&lt;&#x2F;a&gt;)&lt;&#x2F;li&gt;
&lt;li&gt;trained on open-source data&lt;&#x2F;li&gt;
&lt;li&gt;high correlation with human evaluations and proprietary models&lt;&#x2F;li&gt;
&lt;li&gt;highly flexible: capable of performing direct assessments and pairwise rankings, and allowing the definition of custom evaluation criteria.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;I experimented with Prometheus 2 + Haystack to evaluate RAG across different dimensions.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;blog&#x2F;rag-evaluation-with-prometheus-2&quot;&gt;ğŸ“ Blog post&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;prometheus2_evaluation&quot;&gt;ğŸ““ Notebook&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">Learn how to evaluate RAG pipelines with an open model.</summary>
        </entry><entry xml:lang="en">
        <title>âš™ï¸ Prompt Optimization with Haystack + DSPy</title>
        <published>2024-06-05T00:00:00+00:00</published>
        <updated>2024-06-05T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/haystack-dspy/" type="text/html"/>
        <id>https://anakin87.github.io/blog/haystack-dspy/</id>
        
            <content type="html">&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;haystack-dspy&#x2F;haystack_dspy.jpeg&quot; alt=&quot;Haystack + DSPy&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;When building applications with LLMs, writing effective prompts is a long process of trial and error. ğŸ”„&lt;&#x2F;p&gt;
&lt;p&gt;Often, if you switch models, you also have to change the prompt. ğŸ˜©&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What if you could automate this process?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ’¡ Thatâ€™s where DSPy comes in - a framework designed to algorithmically optimize prompts for Language Models.&lt;&#x2F;p&gt;
&lt;p&gt;By applying classical machine learning concepts (training and evaluation data, metrics, optimization), DSPy generates better prompts for a given model and task.&lt;&#x2F;p&gt;
&lt;p&gt;Recently, I explored combining DSPy with the robustness of Haystack Pipelines.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Check out the &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;prompt_optimization_with_dspy&quot;&gt;ğŸ§ªğŸ““ experimental notebook&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Hereâ€™s how it works:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;â–¶ï¸ Start from a Haystack RAG pipeline with a basic prompt&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ¯ Define a goal (in this case, get correct and concise answers)&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ“Š Create a DSPy program, define data and metrics&lt;&#x2F;li&gt;
&lt;li&gt;âœ¨ Optimize and evaluate -&amp;gt; improved prompt&lt;&#x2F;li&gt;
&lt;li&gt;ğŸš€ Build a refined Haystack RAG pipeline using the optimized prompt&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">Automate prompt engineering with DSPy and Haystack.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ§‘â€ğŸ« AutoQuizzer: create a quiz from a URL and play&#x2F;let the LLM play</title>
        <published>2024-05-16T00:00:00+00:00</published>
        <updated>2024-05-16T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/autoquizzer/" type="text/html"/>
        <id>https://anakin87.github.io/blog/autoquizzer/</id>
        
            <content type="html">&lt;!-- toc --&gt;
&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;&#x2F;h2&gt;
&lt;p&gt;Do you want to play a game against Llama 3? ğŸ¦™ğŸ¦™ğŸ¦™&lt;&#x2F;p&gt;
&lt;p&gt;Meet &lt;strong&gt;ğŸ§‘â€ğŸ« AutoQuizzer&lt;&#x2F;strong&gt;, a new LLM application that you can use for learning or just for fun.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Try it out on &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;deepset&#x2F;autoquizzer&quot;&gt;ğŸ¤— Hugging Face Spaces&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;how-it-works&quot;&gt;How it works&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;anakin87&#x2F;autoquizzer&#x2F;main&#x2F;autoquizzer.png&quot; alt=&quot;AutoQuizzer&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;You provide an URL -&amp;gt; A multiple-choice quiz is instantly generated.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;You can play the quiz yourself.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;You can let the LLM play in two different ways&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ“• Closed book: the LLM responds only by knowing the general topic and using its parametric knowledge and reasoning abilities.&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ”ğŸŒ Web RAG: for each question, a Google search is done and the top 3 snippets are included in the prompt for the LLM.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;Stack&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ—ï¸ Haystack LLM framework&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ¦™ Llama 3 8B Instruct&lt;&#x2F;li&gt;
&lt;li&gt;âš¡ Groq&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Original idea: Tuana Ã‡elik&lt;&#x2F;p&gt;
&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ¬ Project walkthrough video by Tuana Ã‡elik: &lt;div &gt;
    &lt;iframe src=&quot;https:&#x2F;&#x2F;www.youtube-nocookie.com&#x2F;embed&#x2F;C1oJ1ArYYZA&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;&#x2F;iframe&gt;
&lt;&#x2F;div&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;anakin87&#x2F;autoquizzer&quot;&gt;ğŸ‘¨â€ğŸ’» Code&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.theregister.com&#x2F;2024&#x2F;05&#x2F;29&#x2F;autoquizzer_llm_quiz_generation&#x2F;&quot;&gt;ğŸ“° LLMs can write and answer quizzes â€“ but arenâ€™t quite ready to disrupt trivia night&lt;&#x2F;a&gt; - The Register&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">Learn how I built this ğŸ”¥ application.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ” Sparse Embedding Retrieval in Haystack</title>
        <published>2024-04-29T00:00:00+00:00</published>
        <updated>2024-04-29T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/splade-haystack/" type="text/html"/>
        <id>https://anakin87.github.io/blog/splade-haystack/</id>
        
            <content type="html">&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;splade-haystack&#x2F;splade_haystack.jpeg&quot; alt=&quot;Splade&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Keyword-based retrieval methods like BM25 are efficient but lack semantic understanding.&lt;&#x2F;p&gt;
&lt;p&gt;On the other hand, dense vector retrieval requires considerable computational resources and may struggle in new domains.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ’¡ &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;naver&#x2F;splade&quot;&gt;SPLADE&lt;&#x2F;a&gt;, a sparse embedding retrieval technique, tries to combine the strengths of both methods.&lt;&#x2F;p&gt;
&lt;p&gt;Leveraging Language Models like BERT, SPLADE evaluates the relevance of query terms and performs automatic term expansion.&lt;&#x2F;p&gt;
&lt;p&gt;For a deep and visual overview of SPLADE, check out &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.pinecone.io&#x2F;learn&#x2F;splade&#x2F;&quot;&gt;this article by Pinecone and James Briggs&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;SPLADE is promising and we are happy to introduce this technique into the Haystack LLM framework! ğŸ‰
This integration features:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;FastEmbed Sparse Embedders&lt;&#x2F;li&gt;
&lt;li&gt;new Qdrant retrievers.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;This integration owes much to the dedication of our community member Corentin Meyer ğŸ‘ and to the help of Qdrant folks ğŸ™Œ.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ™ A special mention also goes to Prithivi Da, who created an industry-ready SPLADE model with a permissive license.&lt;&#x2F;p&gt;
&lt;p&gt;Curious to see SPLADE in action? Check out the notebook ğŸ‘‡
&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;sparse_embedding_retrieval&quot;&gt;ğŸ““ Sparse Embedding Retrieval with Qdrant and FastEmbed&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</content>
        <summary type="html">Learn how to use SPLADE for better retrieval with Haystack + Qdrant</summary>
        </entry><entry xml:lang="en">
        <title>Playing with ğŸ¦™ Llama 3 - RAG about Oscar night ğŸ¬</title>
        <published>2024-04-19T00:00:00+00:00</published>
        <updated>2024-04-19T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/rag-oscar-night/" type="text/html"/>
        <id>https://anakin87.github.io/blog/rag-oscar-night/</id>
        
            <content type="html">&lt;p&gt;What I find great about the new Llama 3 models is that
the small 8B instruct variant outperforms larger proprietary models such as GPT-3.5-Turbo-0613
in the &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;lmarena.ai&#x2F;?leaderboard&quot;&gt;ğŸ† LMSYS Chatbot Arena&lt;&#x2F;a&gt; (crowdsourced human evaluation)!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;rag-oscar-night&#x2F;llama3_arena.jpeg&quot; alt=&quot;Llama 3 8B in LMSYS Chatbot Arena&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Ofc, you can build with Llama 3 in the Haystack LLM framework from day one ğŸ˜&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;RAG about Oscar night ğŸ†ğŸ¬&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Stack: Haystack + Snowflake Arctic embeddings + Llama3&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;llama3_rag&quot;&gt;ğŸ““ Notebook&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</content>
        </entry><entry xml:lang="en">
        <title>ğŸ’ Playing with Gemma</title>
        <published>2024-02-21T00:00:00+00:00</published>
        <updated>2024-02-21T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/gemma-haystack/" type="text/html"/>
        <id>https://anakin87.github.io/blog/gemma-haystack/</id>
        
            <content type="html">&lt;p&gt;Everyone is excited about Gemma, the new family of open Language Models by Google DeepMind:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ”¹ different sizes (2B and 7B)&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ”¹ base models and instruction-tuned models&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ”¹ can be commercially used!&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;I tried it right away! ğŸ”¥&lt;&#x2F;p&gt;
&lt;p&gt;In Colab, using the Haystack LLM framework&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ”¸ Chat with Gemma (travel assistant) ğŸ›©&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ”¸ RAG with Gemma (about Rock music) ğŸ¸&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;ğŸ““ Here is the &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;colab.research.google.com&#x2F;github&#x2F;deepset-ai&#x2F;haystack-cookbook&#x2F;blob&#x2F;c4e70ea69f8f3a36133bb239a0ade70e35577e85&#x2F;notebooks&#x2F;gemma_chat_rag.ipynb&quot;&gt;notebook&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</content>
        </entry><entry xml:lang="en">
        <title>ğŸ‡®ğŸ‡¹ğŸ‡¬ğŸ‡§ Multilingual RAG from a ğŸ§ podcast</title>
        <published>2024-01-03T00:00:00+00:00</published>
        <updated>2024-01-03T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/multilingual-rag-podcast/" type="text/html"/>
        <id>https://anakin87.github.io/blog/multilingual-rag-podcast/</id>
        
            <content type="html">&lt;!-- toc --&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;multilingual-rag-podcast&#x2F;thumbnail.jpeg&quot; alt=&quot;Multilingual RAG from a podcast&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;idea&quot;&gt;Idea&lt;&#x2F;h2&gt;
&lt;p&gt;Happy new year, LLM aficionados!&lt;&#x2F;p&gt;
&lt;p&gt;A few weeks ago &lt;a href=&quot;..&#x2F;haystack-podcasts&quot;&gt;Sara Zanzottera and I were interviewed on the PointerPodcast&lt;&#x2F;a&gt;.
We talked about LLMs, open-source, RAGâ€¦ It was a blast!
Unfortunately, you can only enjoy it if you know Italianâ€¦&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ§ª So I came up with an experimental idea: create a multilingual RAG app based on that podcast.
This means you can pose questions in English and receive responses in English, even if the original content is in Italian.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;toolbox-the-open-source-stack&quot;&gt;ğŸ§° The open-source stack&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Haystack LLM orchestration framework, to build indexing and RAG pipelines&lt;&#x2F;li&gt;
&lt;li&gt;Whisper model for transcribing audio into text&lt;&#x2F;li&gt;
&lt;li&gt;Qdrant vector database to efficiently store and search embeddings corresponding to different chunks&lt;&#x2F;li&gt;
&lt;li&gt;intfloat&#x2F;multilingual-e5-large: a good multilingual embedding model&lt;&#x2F;li&gt;
&lt;li&gt;Mixtral 8x7B Instruct-v0.1: the powerful multilingual mixture of experts model&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“’ Explore the &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;multilingual_rag_podcast&quot;&gt;notebook&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;paperclip-findings&quot;&gt;ğŸ“ Findings&lt;&#x2F;h2&gt;
&lt;p&gt;Although the transcription does not have excellent quality (I used Whisper small), the application works quite well.&lt;&#x2F;p&gt;
&lt;p&gt;Mixtral can easily handle information in Italian and use it to formulate answers in English, without an intermediate translation step.&lt;&#x2F;p&gt;
</content>
        <summary type="html">Learn how to build a multilingual RAG pipeline based on a podcast episode transcript</summary>
        </entry>
</feed>
