<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet href="https://anakin87.github.io/feed_style.xsl" type="text/xsl"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <tabi:metadata xmlns:tabi="https://github.com/welpo/tabi">
        <tabi:base_url>https:&#x2F;&#x2F;anakin87.github.io&#x2F;</tabi:base_url>
        <tabi:separator>
            â€¢
        </tabi:separator>
        <tabi:about_feeds>This is a web feed, also known as an Atom feed. Subscribe by copying the URL from the address bar into your newsreader. Visit About Feeds to learn more and get started. It&#x27;s free.</tabi:about_feeds>
        <tabi:visit_the_site>Visit website</tabi:visit_the_site>
        <tabi:recent_posts>Recent posts</tabi:recent_posts>
        <tabi:last_updated_on>Updated on $DATE</tabi:last_updated_on>
        <tabi:default_theme></tabi:default_theme>
        <tabi:post_listing_date>date</tabi:post_listing_date>
        <tabi:current_section>Haystack</tabi:current_section>
    </tabi:metadata><link rel="extra-stylesheet" href="https://anakin87.github.io/skins/indigo_ingot.css?h=d429472afbb246441b1a" /><title>~/anakin87 - Haystack</title>
        <subtitle>Personal website of Stefano Fiorucci, AI&#x2F;NLP&#x2F;Software Engineer.</subtitle>
    <link href="https://anakin87.github.io/tags/haystack/atom.xml" rel="self" type="application/atom+xml"/>
    <link href="https://anakin87.github.io/tags/haystack/" rel="alternate" type="text/html"/>
    <generator uri="https://www.getzola.org/">Zola</generator><updated>2025-08-13T00:00:00+00:00</updated><id>https://anakin87.github.io/tags/haystack/atom.xml</id><entry xml:lang="en">
        <title>ğŸ•µï¸ğŸŒ Building Browser Agents</title>
        <published>2025-08-13T00:00:00+00:00</published>
        <updated>2025-08-13T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/browser-agent/" type="text/html"/>
        <id>https://anakin87.github.io/blog/browser-agent/</id>
        
            <content type="html">&lt;div class=&quot;admonition tip&quot;&gt;
    &lt;div class=&quot;admonition-icon admonition-icon-tip&quot;&gt;&lt;&#x2F;div&gt;
    &lt;div class=&quot;admonition-content&quot;&gt;
        &lt;strong class=&quot;admonition-title&quot;&gt;TIP&lt;&#x2F;strong&gt;
        &lt;p&gt;&lt;strong&gt;TL;DR&lt;&#x2F;strong&gt;: I built a Browser Agent from scratch using Haystack, Gemini, and Playwright MCP server ğŸ’«&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;browser_agents&quot;&gt;ğŸ““ Notebook&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;For a short intro, read on!&lt;&#x2F;p&gt;

    &lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;p&gt;&lt;video src=&quot;agent.mp4&quot; controls autoplay loop&gt;&lt;&#x2F;video&gt;&lt;&#x2F;p&gt;
&lt;p&gt;No API? No problem. Browser Agents can use websites like you do: click, type, wait, read.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ¥ In the video, Agent:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Goes to Hugging Face Spaces&lt;&#x2F;li&gt;
&lt;li&gt;Finds FLUX.1 [schnell] space (by Black Forest Labs)&lt;&#x2F;li&gt;
&lt;li&gt;Expands a short prompt (â€œmy holiday on Lake Comoâ€) into a detailed image generation prompt&lt;&#x2F;li&gt;
&lt;li&gt;Waits for the image&lt;&#x2F;li&gt;
&lt;li&gt;Returns the image URL&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;What else can it do?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Great for information gathering and summarization&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ—ï¸ğŸ—ï¸ Compare news websites and create a table of shared stories with links&lt;&#x2F;li&gt;
&lt;li&gt;â–¶ï¸ Find content creator social profiles from YouTube videos&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ›ï¸ Find a productâ€™s price range on Amazon&lt;&#x2F;li&gt;
&lt;li&gt;ğŸš‚ ğŸšŒ Gather public transportation travel optionsâ€¦&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;How is it built?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ—ï¸ deepset Hhaystack â†’ Agent execution logic&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ§  Google Gemini 2.5 Flash â†’ Good and fast LLM with a generous free tier&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ› ï¸ Microsoft Playwright MCP server â†’ Browser automation tools: navigate, click, type, waitâ€¦&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Even without vision capabilities, this setup can get quite far.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Next steps&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Move from notebook to real deployment&lt;&#x2F;li&gt;
&lt;li&gt;Try a local open model&lt;&#x2F;li&gt;
&lt;li&gt;Incorporate vision&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">Learn how to build an Agent that browses the web like a human</summary>
        </entry><entry xml:lang="en">
        <title>Haystack can now see ğŸ‘€</title>
        <published>2025-08-07T00:00:00+00:00</published>
        <updated>2025-08-07T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/haystack-image/" type="text/html"/>
        <id>https://anakin87.github.io/blog/haystack-image/</id>
        
            <content type="html">&lt;!-- toc --&gt;
&lt;p&gt;The 2.16.0 Haystack release adds a long-requested feature: &lt;strong&gt;image support&lt;&#x2F;strong&gt;!&lt;&#x2F;p&gt;
&lt;p&gt;This isnâ€™t just about passing images to an LLM. We built several features to enable practical multimodal use cases.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Whatâ€™s new?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ§  Support for multiple LLM providers: OpenAI, Amazon Bedrock, Google Gemini, Mistral AI, NVIDIA, OpenRouter, Ollama and more&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ›ï¸ Prompt template language to handle structured inputs, including images&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ“„ PDF and image converters&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ§¾ LLM-based extractor to pull text from images&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ” Image embedders using CLIP-like models&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ§© Components to build multimodal RAG pipelines and Agents&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;I had the chance of leading this effort with Sebastian Husch Lee (great collab).&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ““ Below you can find two notebooks to explore the new features:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;multimodal_intro&quot;&gt;Introduction to Multimodal Text Generation&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;tutorials&#x2F;46_multimodal_rag&quot;&gt;Creating Vision+Text RAG Pipelines&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;(ğŸ–¼ï¸ image by Bilge YÃ¼cel)&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;haystack-image&#x2F;image_agent.webp&quot; alt=&quot;Image Agent&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
</content>
        <summary type="html">Image support landed in Haystack! Tutorials inside.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ›¡ï¸ AI Guardrails with Open Language Models</title>
        <published>2025-07-03T00:00:00+00:00</published>
        <updated>2025-07-03T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/ai-guardrails/" type="text/html"/>
        <id>https://anakin87.github.io/blog/ai-guardrails/</id>
        
            <content type="html">&lt;div class=&quot;admonition tip&quot;&gt;
    &lt;div class=&quot;admonition-icon admonition-icon-tip&quot;&gt;&lt;&#x2F;div&gt;
    &lt;div class=&quot;admonition-content&quot;&gt;
        &lt;strong class=&quot;admonition-title&quot;&gt;TIP&lt;&#x2F;strong&gt;
        &lt;p&gt;Here is a tutorial on how to implement Content Moderation and Safety with Open Language Models.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;safety_moderation_open_lms&quot;&gt;ğŸ““ Notebook&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;For a short intro, read on!&lt;&#x2F;p&gt;

    &lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;ai-guardrails&#x2F;ai-guardrails.png&quot; alt=&quot;AI Guardrails with Open Language Models&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;How do you ensure your AI application is safe from harmful or inappropriate user inputs?&lt;&#x2F;p&gt;
&lt;p&gt;This is a core requirement for real-world AI deployments. Luckily, several open Language Models are built specifically for safety moderation.&lt;&#x2F;p&gt;
&lt;p&gt;Iâ€™ve been exploring them and put together a hands-on tutorial using the Haystack framework to build your own AI guardrails.&lt;&#x2F;p&gt;
&lt;p&gt;In the &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;safety_moderation_open_lms&quot;&gt;notebook&lt;&#x2F;a&gt;, youâ€™ll learn how to use and customize:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Meta Llama Guard (via Hugging Face API)&lt;&#x2F;li&gt;
&lt;li&gt;Google ShieldGemma (via Ollama)&lt;&#x2F;li&gt;
&lt;li&gt;IBM Granite Guardian (via Ollama), which can also evaluate RAG specific risk dimensions&lt;&#x2F;li&gt;
&lt;li&gt;NVIDIA NemoGuard models family, including a model for topic control&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Youâ€™ll also see how to integrate content moderation into a ğŸ” RAG pipeline.&lt;&#x2F;p&gt;
</content>
        <summary type="html">Learn how to implement Content Moderation and Safety with Open Language Models</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ„ Build an Agent to manage Santa&#x27;s Inventory ğŸ…</title>
        <published>2024-12-18T00:00:00+00:00</published>
        <updated>2024-12-18T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/santas-agent/" type="text/html"/>
        <id>https://anakin87.github.io/blog/santas-agent/</id>
        
            <content type="html">&lt;p&gt;Want to learn how to create Agents using Tool Calling? ğŸ› ï¸&lt;&#x2F;p&gt;
&lt;p&gt;Bilge YÃ¼cel and I have created a ğŸ„ Christmas Challenge for you!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;santas-agent&#x2F;elf.jpeg&quot; alt=&quot;Elf&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;In this assignment, youâ€™ll help Santaâ€™s elves build an Agent that can:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Check whatâ€™s in the inventory&lt;&#x2F;li&gt;
&lt;li&gt;Add or remove items from stock&lt;&#x2F;li&gt;
&lt;li&gt;Look up gift prices online and make purchases&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;advent-of-haystack&#x2F;day-8#challenge&quot;&gt;Challenge&lt;&#x2F;a&gt; - &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;colab.research.google.com&#x2F;drive&#x2F;10llkWo2vPnRYJWUp6lvqmZgwfvXJ0E07?usp=sharing&quot;&gt;Solution&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</content>
        <summary type="html">A Christmas challenge to build Agents using Tool Calling</summary>
        </entry><entry xml:lang="en">
        <title>ğŸğŸğŸ A Swarm of Agents with Llama 3.2, GPT-4o mini and Claude 3.5 Sonnet</title>
        <published>2024-11-26T00:00:00+00:00</published>
        <updated>2024-11-26T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/swarm/" type="text/html"/>
        <id>https://anakin87.github.io/blog/swarm/</id>
        
            <content type="html">&lt;div class=&quot;admonition tip&quot;&gt;
    &lt;div class=&quot;admonition-icon admonition-icon-tip&quot;&gt;&lt;&#x2F;div&gt;
    &lt;div class=&quot;admonition-content&quot;&gt;
        &lt;strong class=&quot;admonition-title&quot;&gt;TIP&lt;&#x2F;strong&gt;
        &lt;p&gt;&lt;strong&gt;TL;DR&lt;&#x2F;strong&gt;: I reimplemented the Swarm concept using Haystack, but made it work with both open and proprietary models ğŸ’«&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;blog&#x2F;swarm-of-agents&quot;&gt;âœï¸ Blog article&lt;&#x2F;a&gt; - &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;swarm&quot;&gt;ğŸ““ Notebook&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;For a short intro, read on!&lt;&#x2F;p&gt;

    &lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;swarm&#x2F;swarm_thumbnail.png&quot; alt=&quot;Swarm thumbnail&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Some time ago OpenAI published Swarm: an educational framework for building multi-agent systems.&lt;&#x2F;p&gt;
&lt;p&gt;Their approach focuses on two main concepts:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Routines&lt;&#x2F;strong&gt;: Each agent follows specific ğŸ“œ instructions and uses ğŸ› ï¸ tools to execute them.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Handoffs&lt;&#x2F;strong&gt; ğŸ¤: Agents can transfer control to one another using tool&#x2F;function calling.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;When I first read these ideas, I thought: &lt;em&gt;simple but powerful!&lt;&#x2F;em&gt; And they pair well with the recent unified tool support in Haystack.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ§‘â€ğŸ’» So, I decided to re-implement these concepts using Haystack, and in just a few lines of code, I had a working prototype.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ†’ Bonus feature: this implementation isnâ€™t tied to a single model provider - different agents can be powered by different models!&lt;&#x2F;p&gt;
&lt;p&gt;I replicated the ACME customer service example from the original article, with 3 Agents:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ Triage Agent - Llama 3.2 running on Ollama&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ Sales Agent - Anthropic Claude 3.5 Sonnet&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ Issues and Repairs Agent - OpenAI GPT-4o mini&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Want to see the full implementation and give it a try? ğŸ‘‡&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;blog&#x2F;swarm-of-agents&quot;&gt;âœï¸ Haystack blog article&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;swarm&quot;&gt;ğŸ““ Notebook&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;swarm&#x2F;swarm_terminal.gif&quot; alt=&quot;Swarm in action&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
</content>
        <summary type="html">Learn how to reimplement OpenAI Swarm and make it work with both open and proprietary models.</summary>
        </entry><entry xml:lang="en">
        <title>Create a ğŸ“° Newsletter Agent with Haystack Tools ğŸ› ï¸</title>
        <published>2024-10-17T00:00:00+00:00</published>
        <updated>2024-10-17T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/newsletter-agent/" type="text/html"/>
        <id>https://anakin87.github.io/blog/newsletter-agent/</id>
        
            <content type="html">&lt;p&gt;In the Haystack framework, weâ€™ve recently implemented unified Tool Calling support across different model providers.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;newsletter-agent&#x2F;newsletter_agent.jpeg&quot; alt=&quot;Newsletter Agent&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;In the following resources, weâ€™ll walk through building a Newsletter Agent using three tools:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;A tool to fetch top stories from Hacker News&lt;&#x2F;li&gt;
&lt;li&gt;A tool to create newsletters for a particular audience&lt;&#x2F;li&gt;
&lt;li&gt;A tool to send emails via Gmail.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;Resources&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;newsletter-agent&quot;&gt;ğŸ““ Notebook&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;ğŸ¬ Video: &lt;div &gt;
    &lt;iframe src=&quot;https:&#x2F;&#x2F;www.youtube-nocookie.com&#x2F;embed&#x2F;QWx3OzW2Pvo&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;&#x2F;iframe&gt;
&lt;&#x2F;div&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">Learn how to create an Agent that can fetch information, write a newsletter for a specific audience and send it.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ•µğŸ» Agentic RAG with ğŸ¦™ Llama 3.2 3B</title>
        <published>2024-09-26T00:00:00+00:00</published>
        <updated>2024-09-26T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/agentic-rag-llama32/" type="text/html"/>
        <id>https://anakin87.github.io/blog/agentic-rag-llama32/</id>
        
            <content type="html">&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;agentic-rag-llama32&#x2F;agentic_rag_llama.jpeg&quot; alt=&quot;Agentic RAG with Llama 3.2 3B&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I was excited to explore Llama 3.2, but as a simple ğŸ‡ªğŸ‡º EU guy, I donâ€™t have access to Metaâ€™s multimodal models. ğŸ˜¿&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ¤” So I thought: why not challenge the small 3B text model with Agentic RAG?&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ¯ The plan:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Build a system that tries to answer questions using a knowledge base.&lt;&#x2F;li&gt;
&lt;li&gt;If the documents donâ€™t contain the answer, use Web search for additional context.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;Check out my &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;llama32_agentic_rag&quot;&gt;experimental notebook&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;My stack:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ—ï¸ Haystack: open-source LLM orchestration framework&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ¦™ Llama-3.2-3B-Instruct&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ¦†ğŸŒ free DuckDuckGo API, integrated with Haystack - huge thanks to Giovanni Alzetta!&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;âœ¨ &lt;em&gt;The results? Encouraging - a few months ago, this level of performance from a small model would have been unthinkable.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This probably reflects the impressive IFEval score of the model (comparable to Llama 3.1 8B).&lt;&#x2F;p&gt;
</content>
        <summary type="html">Combine RAG on a knowledge base with Web Search to intelligently answer user questions.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ—‚ï¸â›ï¸ Structured data extraction with Small Language Models</title>
        <published>2024-08-02T00:00:00+00:00</published>
        <updated>2024-08-02T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/structured-data-extraction/" type="text/html"/>
        <id>https://anakin87.github.io/blog/structured-data-extraction/</id>
        
            <content type="html">&lt;p&gt;I like playing with small language models and applying them to practical problems.&lt;&#x2F;p&gt;
&lt;p&gt;Recently, I turned one of these experiments into a step-by-step recipe for the Open-Source AI cookbook (by ğŸ¤— Hugging Face)!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;learn&#x2F;cookbook&#x2F;en&#x2F;information_extraction_haystack_nuextract&quot;&gt;ğŸ‘¨â€ğŸ³ğŸ““ Check it out&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;video src=&quot;data_extraction.mp4&quot; controls autoplay loop&gt;&lt;&#x2F;video&gt;&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ¯ Goal: automatically extract structured information from startup funding announcements found on the web.&lt;&#x2F;p&gt;
&lt;p&gt;In this notebook, youâ€™ll discover how to:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ—ï¸ Build an Information Extraction pipeline orchestrated by Haystack&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ§  Use &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;numind&#x2F;NuExtract&quot;&gt;NuExtract&lt;&#x2F;a&gt;, a powerful Small Language Model (3.8B) fine-tuned for data extraction (by NuMind)&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ—’ï¸ Visualize results with Pandas&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ•µï¸ Create a simple graph to derive insights, such as the relationships between companies and investors&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;ğŸ™ Tuana Ã‡elik, Merve Noyan, Steven Liu for their help and support!&lt;&#x2F;p&gt;
</content>
        <summary type="html">Combine RAG on a knowledge base with Web Search to intelligently answer user questions.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸŒŒ Creating adventures with local LLMs</title>
        <published>2024-06-24T00:00:00+00:00</published>
        <updated>2024-06-24T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/adventures-local-llms/" type="text/html"/>
        <id>https://anakin87.github.io/blog/adventures-local-llms/</id>
        
            <content type="html">&lt;p&gt;What if ğŸ¤”â€¦ Homer Simpson met Spider-Man and they went on a quest for donuts? ğŸ©&lt;&#x2F;p&gt;
&lt;p&gt;Or if Fred Astaire and Corporal Hicks teamed up to fight xenomorphs? ğŸ‘¾&lt;&#x2F;p&gt;
&lt;p&gt;In the words of Karpathy, LLMs are dream machinesâ€¦
they seem specially made to simulate these wild scenarios!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Experimenting with this idea ğŸ‘‡&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Nous Research&#x2F;teknium recently released &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;NousResearch&#x2F;CharacterCodex&quot;&gt;Character Codex&lt;&#x2F;a&gt;:
a massive dataset with information on 16k characters, both fictional and real.
I couldnâ€™t wait to play itâ€¦&lt;&#x2F;p&gt;
&lt;p&gt;After a few attempts, I found that combining the information in this dataset with a good model (like Llama-3-8B)
opens the doors to a myriad of chat adventures.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ› ï¸ Stack:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Haystack for orchestration ğŸ—ï¸&lt;&#x2F;li&gt;
&lt;li&gt;llamafile ğŸ¦™ğŸ—‚ï¸ (by Mozilla) to run our model locally.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;Check out the &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;charactercodex_llamafile&quot;&gt;ğŸ““ notebook&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;
(includes a bonus ğŸ•µï¸ Mystery Character Quiz)&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;adventures-local-llms&#x2F;adventures.jpeg&quot; alt=&quot;Adventures&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
</content>
        <summary type="html">Make LLMs simulate adventures with llamafile + Character Codex.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ§ª RAG Evaluation with ğŸ”¥ Prometheus 2</title>
        <published>2024-06-17T00:00:00+00:00</published>
        <updated>2024-06-17T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/rag-eval-prometheus/" type="text/html"/>
        <id>https://anakin87.github.io/blog/rag-eval-prometheus/</id>
        
            <content type="html">&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;rag-eval-prometheus&#x2F;prometheus.png&quot; alt=&quot;Prometheus 2&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;When evaluating LLMsâ€™ responses, &lt;strong&gt;proprietary models&lt;&#x2F;strong&gt; like GPT-4 are commonly used due to their strong performance.&lt;&#x2F;p&gt;
&lt;p&gt;However, relying on closed models presents challenges related to data privacy ğŸ”’, transparency, controllability, and cost ğŸ’¸.&lt;&#x2F;p&gt;
&lt;p&gt;On the other hand, &lt;strong&gt;open models&lt;&#x2F;strong&gt; typically do not correlate well with human judgments and lack flexibility.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ”¥ &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2405.01535&quot;&gt;Prometheus 2&lt;&#x2F;a&gt; (by KAIST AI) is a new family of open-source models designed to address these gaps:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;two variants (&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;prometheus-eval&#x2F;prometheus-7b-v2.0&quot;&gt;7B&lt;&#x2F;a&gt; and &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;prometheus-eval&#x2F;prometheus-8x7b-v2.0&quot;&gt;8x7B&lt;&#x2F;a&gt;)&lt;&#x2F;li&gt;
&lt;li&gt;trained on open-source data&lt;&#x2F;li&gt;
&lt;li&gt;high correlation with human evaluations and proprietary models&lt;&#x2F;li&gt;
&lt;li&gt;highly flexible: capable of performing direct assessments and pairwise rankings, and allowing the definition of custom evaluation criteria.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;I experimented with Prometheus 2 + Haystack to evaluate RAG across different dimensions.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;blog&#x2F;rag-evaluation-with-prometheus-2&quot;&gt;ğŸ“ Blog post&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;prometheus2_evaluation&quot;&gt;ğŸ““ Notebook&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">Learn how to evaluate RAG pipelines with an open model.</summary>
        </entry><entry xml:lang="en">
        <title>âš™ï¸ Prompt Optimization with Haystack + DSPy</title>
        <published>2024-06-05T00:00:00+00:00</published>
        <updated>2024-06-05T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/haystack-dspy/" type="text/html"/>
        <id>https://anakin87.github.io/blog/haystack-dspy/</id>
        
            <content type="html">&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;haystack-dspy&#x2F;haystack_dspy.jpeg&quot; alt=&quot;Haystack + DSPy&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;When building applications with LLMs, writing effective prompts is a long process of trial and error. ğŸ”„&lt;&#x2F;p&gt;
&lt;p&gt;Often, if you switch models, you also have to change the prompt. ğŸ˜©&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What if you could automate this process?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ’¡ Thatâ€™s where DSPy comes in - a framework designed to algorithmically optimize prompts for Language Models.&lt;&#x2F;p&gt;
&lt;p&gt;By applying classical machine learning concepts (training and evaluation data, metrics, optimization), DSPy generates better prompts for a given model and task.&lt;&#x2F;p&gt;
&lt;p&gt;Recently, I explored combining DSPy with the robustness of Haystack Pipelines.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Check out the &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;prompt_optimization_with_dspy&quot;&gt;ğŸ§ªğŸ““ experimental notebook&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Hereâ€™s how it works:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;â–¶ï¸ Start from a Haystack RAG pipeline with a basic prompt&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ¯ Define a goal (in this case, get correct and concise answers)&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ“Š Create a DSPy program, define data and metrics&lt;&#x2F;li&gt;
&lt;li&gt;âœ¨ Optimize and evaluate -&amp;gt; improved prompt&lt;&#x2F;li&gt;
&lt;li&gt;ğŸš€ Build a refined Haystack RAG pipeline using the optimized prompt&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">Automate prompt engineering with DSPy and Haystack.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ§‘â€ğŸ« AutoQuizzer: create a quiz from a URL and play&#x2F;let the LLM play</title>
        <published>2024-05-16T00:00:00+00:00</published>
        <updated>2024-05-16T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/autoquizzer/" type="text/html"/>
        <id>https://anakin87.github.io/blog/autoquizzer/</id>
        
            <content type="html">&lt;!-- toc --&gt;
&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;&#x2F;h2&gt;
&lt;p&gt;Do you want to play a game against Llama 3? ğŸ¦™ğŸ¦™ğŸ¦™&lt;&#x2F;p&gt;
&lt;p&gt;Meet &lt;strong&gt;ğŸ§‘â€ğŸ« AutoQuizzer&lt;&#x2F;strong&gt;, a new LLM application that you can use for learning or just for fun.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Try it out on &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;deepset&#x2F;autoquizzer&quot;&gt;ğŸ¤— Hugging Face Spaces&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;how-it-works&quot;&gt;How it works&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;anakin87&#x2F;autoquizzer&#x2F;main&#x2F;autoquizzer.png&quot; alt=&quot;AutoQuizzer&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;You provide an URL -&amp;gt; A multiple-choice quiz is instantly generated.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;You can play the quiz yourself.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;You can let the LLM play in two different ways&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ“• Closed book: the LLM responds only by knowing the general topic and using its parametric knowledge and reasoning abilities.&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ”ğŸŒ Web RAG: for each question, a Google search is done and the top 3 snippets are included in the prompt for the LLM.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;Stack&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ—ï¸ Haystack LLM framework&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ¦™ Llama 3 8B Instruct&lt;&#x2F;li&gt;
&lt;li&gt;âš¡ Groq&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Original idea: Tuana Ã‡elik&lt;&#x2F;p&gt;
&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ¬ Project walkthrough video by Tuana Ã‡elik: &lt;div &gt;
    &lt;iframe src=&quot;https:&#x2F;&#x2F;www.youtube-nocookie.com&#x2F;embed&#x2F;C1oJ1ArYYZA&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;&#x2F;iframe&gt;
&lt;&#x2F;div&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;anakin87&#x2F;autoquizzer&quot;&gt;ğŸ‘¨â€ğŸ’» Code&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.theregister.com&#x2F;2024&#x2F;05&#x2F;29&#x2F;autoquizzer_llm_quiz_generation&#x2F;&quot;&gt;ğŸ“° LLMs can write and answer quizzes â€“ but arenâ€™t quite ready to disrupt trivia night&lt;&#x2F;a&gt; - The Register&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">Learn how I built this ğŸ”¥ application.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ” Sparse Embedding Retrieval in Haystack</title>
        <published>2024-04-29T00:00:00+00:00</published>
        <updated>2024-04-29T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/splade-haystack/" type="text/html"/>
        <id>https://anakin87.github.io/blog/splade-haystack/</id>
        
            <content type="html">&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;splade-haystack&#x2F;splade_haystack.jpeg&quot; alt=&quot;Splade&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Keyword-based retrieval methods like BM25 are efficient but lack semantic understanding.&lt;&#x2F;p&gt;
&lt;p&gt;On the other hand, dense vector retrieval requires considerable computational resources and may struggle in new domains.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ’¡ &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;naver&#x2F;splade&quot;&gt;SPLADE&lt;&#x2F;a&gt;, a sparse embedding retrieval technique, tries to combine the strengths of both methods.&lt;&#x2F;p&gt;
&lt;p&gt;Leveraging Language Models like BERT, SPLADE evaluates the relevance of query terms and performs automatic term expansion.&lt;&#x2F;p&gt;
&lt;p&gt;For a deep and visual overview of SPLADE, check out &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.pinecone.io&#x2F;learn&#x2F;splade&#x2F;&quot;&gt;this article by Pinecone and James Briggs&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;SPLADE is promising and we are happy to introduce this technique into the Haystack LLM framework! ğŸ‰
This integration features:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;FastEmbed Sparse Embedders&lt;&#x2F;li&gt;
&lt;li&gt;new Qdrant retrievers.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;This integration owes much to the dedication of our community member Corentin Meyer ğŸ‘ and to the help of Qdrant folks ğŸ™Œ.&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ™ A special mention also goes to Prithivi Da, who created an industry-ready SPLADE model with a permissive license.&lt;&#x2F;p&gt;
&lt;p&gt;Curious to see SPLADE in action? Check out the notebook ğŸ‘‡
&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;sparse_embedding_retrieval&quot;&gt;ğŸ““ Sparse Embedding Retrieval with Qdrant and FastEmbed&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</content>
        <summary type="html">Learn how to use SPLADE for better retrieval with Haystack + Qdrant</summary>
        </entry><entry xml:lang="en">
        <title>Playing with ğŸ¦™ Llama 3 - RAG about Oscar night ğŸ¬</title>
        <published>2024-04-19T00:00:00+00:00</published>
        <updated>2024-04-19T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/rag-oscar-night/" type="text/html"/>
        <id>https://anakin87.github.io/blog/rag-oscar-night/</id>
        
            <content type="html">&lt;p&gt;What I find great about the new Llama 3 models is that
the small 8B instruct variant outperforms larger proprietary models such as GPT-3.5-Turbo-0613
in the &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;lmarena.ai&#x2F;?leaderboard&quot;&gt;ğŸ† LMSYS Chatbot Arena&lt;&#x2F;a&gt; (crowdsourced human evaluation)!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;rag-oscar-night&#x2F;llama3_arena.jpeg&quot; alt=&quot;Llama 3 8B in LMSYS Chatbot Arena&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Ofc, you can build with Llama 3 in the Haystack LLM framework from day one ğŸ˜&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;RAG about Oscar night ğŸ†ğŸ¬&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Stack: Haystack + Snowflake Arctic embeddings + Llama3&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;llama3_rag&quot;&gt;ğŸ““ Notebook&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</content>
        </entry><entry xml:lang="en">
        <title>ğŸ’ gemma-2b-orpo: a Small Language Model trained with ORPO</title>
        <published>2024-03-26T00:00:00+00:00</published>
        <updated>2024-03-26T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/gemma-2b-orpo/" type="text/html"/>
        <id>https://anakin87.github.io/blog/gemma-2b-orpo/</id>
        
            <content type="html">&lt;div class=&quot;admonition tip&quot;&gt;
    &lt;div class=&quot;admonition-icon admonition-icon-tip&quot;&gt;&lt;&#x2F;div&gt;
    &lt;div class=&quot;admonition-content&quot;&gt;
        &lt;strong class=&quot;admonition-title&quot;&gt;TIP&lt;&#x2F;strong&gt;
        &lt;p&gt;ğŸ’» You can find the Training code on &lt;strong&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;anakin87&#x2F;gemma-2b-orpo&#x2F;blob&#x2F;main&#x2F;notebooks&#x2F;training.ipynb&quot;&gt;this notebook&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;.
For a short intro, read on!&lt;&#x2F;p&gt;

    &lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;gemma-2b-orpo&#x2F;gemma-2b-orpo.png&quot; alt=&quot;Gemma 2B ORPO&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;!-- toc --&gt;
&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;&#x2F;h2&gt;
&lt;p&gt;Meet my weekend experiment: gemma-2b-orpo&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ‘‰ &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;anakin87&#x2F;gemma-2b-orpo&quot;&gt;Model&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;A Small Language Model trained from google&#x2F;gemma-2b base model using ORPO.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-is-orpo&quot;&gt;What is ORPO?&lt;&#x2F;h2&gt;
&lt;p&gt;It stands for Odds Ratio Preference Optimization and is a new training paradigm for Language Models.&lt;&#x2F;p&gt;
&lt;p&gt;Typically, to obtain a helpful LM, you start with a pre-trained model, perform Supervised Fine-Tuning (SFT), and then Preference Alignment (with methods like RLHF or DPO). So far, these two steps have been necessary to achieve a model that follows instructions but is also aligned with human preferences.&lt;&#x2F;p&gt;
&lt;p&gt;ORPO collapses these two steps into one.&lt;&#x2F;p&gt;
&lt;p&gt;Working with preference data, this method introduces a penalty (based on log odds ratio) to the NLL loss function, to favor generations in the chosen response sets.&lt;&#x2F;p&gt;
&lt;p&gt;The first applications of ORPO show âš¡ï¸ faster training, lower memory usage and good results!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;my-small-weeekend-language-model&quot;&gt;â˜€ï¸ My Small (weeekend) Language Model&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Started with gemma-2b base model&lt;&#x2F;li&gt;
&lt;li&gt;Installed Hugging Face TRL from the main branch to use the new ORPOTrainer âœ¨&lt;&#x2F;li&gt;
&lt;li&gt;Chose a good dataset: &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;alvarobartt&#x2F;dpo-mix-7k-simplified&quot;&gt;dpo-mix-7k-simplified&lt;&#x2F;a&gt; by Ãlvaro BartolomÃ© del Canto and the Argilla friends&lt;&#x2F;li&gt;
&lt;li&gt;Trained the model for 4 hours on an NVIDIA A40 GPU (&amp;lt;3$ on RunPod)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;ğŸ“Š The model performs well for its size, with good results on the Nous Research benchmark suite ğŸŒ&lt;&#x2F;p&gt;
&lt;h2 id=&quot;books-resources&quot;&gt;ğŸ“š Resources&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2403.07691&quot;&gt;ORPO: Monolithic Preference Optimization without Reference Model&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;anakin87&#x2F;gemma-2b-orpo&#x2F;blob&#x2F;main&#x2F;notebooks&#x2F;training.ipynb&quot;&gt;gemma-2b-orpo Training notebook ğŸ““&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;anakin87&#x2F;gemma-2b-orpo&#x2F;blob&#x2F;main&#x2F;notebooks&#x2F;usage.ipynb&quot;&gt;gemma-2b-orpo Usage notebook (with the Haystack framework ğŸ’™)&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">Learn how fine-tuned a Small Language Model, collapsing SFT+DPO into a single step with ORPO.</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ§ªğŸ¦â€â¬›ğŸ“‘ From raw text to structured data with open LLMs and function calling</title>
        <published>2024-03-20T00:00:00+00:00</published>
        <updated>2024-03-20T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/raven-info-extraction/" type="text/html"/>
        <id>https://anakin87.github.io/blog/raven-info-extraction/</id>
        
            <content type="html">&lt;!-- toc --&gt;
&lt;h2 id=&quot;dart-the-challenge&quot;&gt;ğŸ¯ The challenge&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;you have a pile of unstructured texts from which you want to extract information in structured form&lt;&#x2F;li&gt;
&lt;li&gt;the desired information can vary dynamically&lt;&#x2F;li&gt;
&lt;li&gt;you want to combine tasks like text classification, NER, summarization, etc.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Language Models with function calling capabilities can be flexible tools ğŸ› ï¸ for this job!&lt;&#x2F;p&gt;
&lt;!-- Linking the exact notebook because it&#x27;s going to be deleted from the cookbook --&gt;
&lt;p&gt;&lt;strong&gt;ğŸ““ Take a look at the &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;colab.research.google.com&#x2F;github&#x2F;deepset-ai&#x2F;haystack-cookbook&#x2F;blob&#x2F;c4e70ea69f8f3a36133bb239a0ade70e35577e85&#x2F;notebooks&#x2F;information_extraction_raven.ipynb&quot;&gt;notebook&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;div &gt;
    &lt;iframe class=&quot;pdf&quot; src=&quot;.&amp;#x2F;raven.pdf&quot;  height=&quot;700&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;&#x2F;iframe&gt;
&lt;&#x2F;div&gt;&lt;h2 id=&quot;key-a-personal-journey&quot;&gt;ğŸ—ï¸ A (personal) journey&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;It all began with &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;gist.github.com&#x2F;kylemcdonald&#x2F;dbac21de2d7855633689f5526225154c&quot;&gt;Kyle McDonaldâ€™s gist&lt;&#x2F;a&gt;, where GPT-3.5-turbo was used to extract structured information from an article.&lt;&#x2F;li&gt;
&lt;li&gt;Fascinated by this idea, I explored the use of open models fine-tuned for function calling: I experimented with Gorilla OpenFunctions, to extract information about animals.&lt;&#x2F;li&gt;
&lt;li&gt;Now: armed with the powerful &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;huggingface.co&#x2F;Nexusflow&#x2F;NexusRaven-V2-13B&quot;&gt;ğŸ¦â€â¬› NexusRaven V2 model&lt;&#x2F;a&gt; (by Nexusflow) and Haystack 2.0, I revisited the experiment and made it more challenging.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;sparkles-results&quot;&gt;âœ¨ Results&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Haystackâ€™s LLM framework is model agnostic, so model switching went smoothly&lt;&#x2F;li&gt;
&lt;li&gt;Nexus Raven outperforms Gorilla OpenFunctions for this use case&lt;&#x2F;li&gt;
&lt;li&gt;Using a statistical model carries some caveats, which I have outlined in the notebook.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;â€œLetâ€™s unlock the potential of unstructured text, one function call at a time.â€&lt;&#x2F;p&gt;
&lt;p&gt;â˜ The last sentence is generated by ChatGPT, but I found it silly and funny. ğŸ˜&lt;&#x2F;p&gt;
</content>
        <summary type="html">Discover a hacky but effective way to extract structured using open LLMs with function calling capabilities (NexusRaven V2)</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ§‘â€ğŸ« LLMs 4 Devs: from 0 to your 1st LLM application</title>
        <published>2024-03-08T00:00:00+00:00</published>
        <updated>2024-03-08T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/llm4devs/" type="text/html"/>
        <id>https://anakin87.github.io/blog/llm4devs/</id>
        
            <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;&#x2F;h2&gt;
&lt;p&gt;The rise of ChatGPT and Large Language Models has revolutionized the tech landscape, leaving developers overwhelmed by the infinite opportunities and intrigued by the technical challenges posed by their complex nature.
This session provides a developer-centric introduction to LLMs, focused on practical applications. No pre-existing knowledge of LLMs and NLP is required.&lt;&#x2F;p&gt;
&lt;p&gt;You will gain insights into: using closed and open-source models, how to effectively prompt LLMs, vector databases, implementing Retrieval Augmented Generation applications (answer generation based on your data), building more complex applications.&lt;&#x2F;p&gt;
&lt;p&gt;Through a hands-on approach, I will show code examples using open-source tools: Haystack LLM framework, Hugging Face Transformers, Ollama, and more. I will also show how you can switch from proprietary to open models.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ¿ Talk - 1st edition - Open Source Day 2024: &lt;div &gt;
    &lt;iframe src=&quot;https:&#x2F;&#x2F;www.youtube-nocookie.com&#x2F;embed&#x2F;L6sUztYJXT8&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;&#x2F;iframe&gt;
&lt;&#x2F;div&gt;&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ¿ Talk - 2nd edition - PyCon Italy 2024: &lt;div &gt;
    &lt;iframe src=&quot;https:&#x2F;&#x2F;www.youtube-nocookie.com&#x2F;embed&#x2F;R_C0IJmAHrQ&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;&#x2F;iframe&gt;
&lt;&#x2F;div&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;anakin87&#x2F;llm4devs&quot;&gt;Repository with slides, code, and more&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">Introductory talk on LLMs for developers</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ™ï¸ Haystack Podcasts</title>
        <published>2024-03-01T00:00:00+00:00</published>
        <updated>2024-03-01T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/haystack-podcasts/" type="text/html"/>
        <id>https://anakin87.github.io/blog/haystack-podcasts/</id>
        
            <content type="html">&lt;p&gt;Two Italian podcasts where I was interviewed with my colleagues about Haystack, LLMs and open source:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ¤ &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;pointerpodcast.it&#x2F;p&#x2F;pointer183-haystack-creare-llm-applications-in-modo-facile-con-stefano-fiorucci-e-sara-zanzottera&#x2F;&quot;&gt;Pointer Podcast: Haystack, creare LLM Applications in modo facile - con Sara Zanzottera&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ¤ Intevista Pythonista: Haystack. Un framework open per app LLM. - con Massimiliano Pippi
&lt;div &gt;
    &lt;iframe src=&quot;https:&#x2F;&#x2F;www.youtube-nocookie.com&#x2F;embed&#x2F;HwhR1wb-0t4&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;&#x2F;iframe&gt;
&lt;&#x2F;div&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        <summary type="html">A collection of podcasts interviews about the Haystack LLM orchestration framework</summary>
        </entry><entry xml:lang="en">
        <title>ğŸ’ Playing with Gemma</title>
        <published>2024-02-21T00:00:00+00:00</published>
        <updated>2024-02-21T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/gemma-haystack/" type="text/html"/>
        <id>https://anakin87.github.io/blog/gemma-haystack/</id>
        
            <content type="html">&lt;p&gt;Everyone is excited about Gemma, the new family of open Language Models by Google DeepMind:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ”¹ different sizes (2B and 7B)&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ”¹ base models and instruction-tuned models&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ”¹ can be commercially used!&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;I tried it right away! ğŸ”¥&lt;&#x2F;p&gt;
&lt;p&gt;In Colab, using the Haystack LLM framework&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ”¸ Chat with Gemma (travel assistant) ğŸ›©&lt;&#x2F;li&gt;
&lt;li&gt;ğŸ”¸ RAG with Gemma (about Rock music) ğŸ¸&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;ğŸ““ Here is the &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;colab.research.google.com&#x2F;github&#x2F;deepset-ai&#x2F;haystack-cookbook&#x2F;blob&#x2F;c4e70ea69f8f3a36133bb239a0ade70e35577e85&#x2F;notebooks&#x2F;gemma_chat_rag.ipynb&quot;&gt;notebook&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</content>
        </entry><entry xml:lang="en">
        <title>ğŸ¦™ Ollama lands in the Haystack ecosystem</title>
        <published>2024-01-09T00:00:00+00:00</published>
        <updated>2024-01-09T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/ollama-haystack/" type="text/html"/>
        <id>https://anakin87.github.io/blog/ollama-haystack/</id>
        
            <content type="html">&lt;p&gt;ğŸ‰ Today Iâ€™m very happy to announce the integration between the Haystack LLM orchestration framework and the Ollama project.&lt;&#x2F;p&gt;
&lt;p&gt;Ollama is the equivalent of ğŸ³ Docker for LLMs:
a smart and easy way to pack and run quantized LLMs everywhere, even in cheap laptops (wo GPUs).&lt;&#x2F;p&gt;
&lt;p&gt;This integration, driven by community demand, was also implemented by the community:
thanks Alistair Rogers and Sachin Sachdeva! ğŸ™Œ&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ¿ğŸ¬ In the image, I am seeking movie suggestions from the great Notus 7B model (by Argilla ğŸ’•).&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;ollama-haystack&#x2F;ollama_haystack.jpeg&quot; alt=&quot;Ollama in action&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;books-resources&quot;&gt;ğŸ“š Resources&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;integrations&#x2F;ollama&quot;&gt;Haystack-Ollama integration page&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;docs.haystack.deepset.ai&#x2F;docs&#x2F;ollamachatgenerator&quot;&gt;Haystack-Ollama docs&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=8qqaqefugWQ&quot;&gt;Video tutorial by Mervin Praison&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        </entry><entry xml:lang="en">
        <title>ğŸ‡®ğŸ‡¹ğŸ‡¬ğŸ‡§ Multilingual RAG from a ğŸ§ podcast</title>
        <published>2024-01-03T00:00:00+00:00</published>
        <updated>2024-01-03T00:00:00+00:00</updated>
        <author>
            <name>Stefano Fiorucci</name>
        </author>
        <link rel="alternate" href="https://anakin87.github.io/blog/multilingual-rag-podcast/" type="text/html"/>
        <id>https://anakin87.github.io/blog/multilingual-rag-podcast/</id>
        
            <content type="html">&lt;!-- toc --&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;anakin87.github.io&#x2F;blog&#x2F;multilingual-rag-podcast&#x2F;thumbnail.jpeg&quot; alt=&quot;Multilingual RAG from a podcast&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;idea&quot;&gt;Idea&lt;&#x2F;h2&gt;
&lt;p&gt;Happy new year, LLM aficionados!&lt;&#x2F;p&gt;
&lt;p&gt;A few weeks ago &lt;a href=&quot;..&#x2F;haystack-podcasts&quot;&gt;Sara Zanzottera and I were interviewed on the PointerPodcast&lt;&#x2F;a&gt;.
We talked about LLMs, open-source, RAGâ€¦ It was a blast!
Unfortunately, you can only enjoy it if you know Italianâ€¦&lt;&#x2F;p&gt;
&lt;p&gt;ğŸ§ª So I came up with an experimental idea: create a multilingual RAG app based on that podcast.
This means you can pose questions in English and receive responses in English, even if the original content is in Italian.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;toolbox-the-open-source-stack&quot;&gt;ğŸ§° The open-source stack&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Haystack LLM orchestration framework, to build indexing and RAG pipelines&lt;&#x2F;li&gt;
&lt;li&gt;Whisper model for transcribing audio into text&lt;&#x2F;li&gt;
&lt;li&gt;Qdrant vector database to efficiently store and search embeddings corresponding to different chunks&lt;&#x2F;li&gt;
&lt;li&gt;intfloat&#x2F;multilingual-e5-large: a good multilingual embedding model&lt;&#x2F;li&gt;
&lt;li&gt;Mixtral 8x7B Instruct-v0.1: the powerful multilingual mixture of experts model&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“’ Explore the &lt;a class=&quot;external&quot; rel=&quot;external&quot; href=&quot;https:&#x2F;&#x2F;haystack.deepset.ai&#x2F;cookbook&#x2F;multilingual_rag_podcast&quot;&gt;notebook&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;paperclip-findings&quot;&gt;ğŸ“ Findings&lt;&#x2F;h2&gt;
&lt;p&gt;Although the transcription does not have excellent quality (I used Whisper small), the application works quite well.&lt;&#x2F;p&gt;
&lt;p&gt;Mixtral can easily handle information in Italian and use it to formulate answers in English, without an intermediate translation step.&lt;&#x2F;p&gt;
</content>
        <summary type="html">Learn how to build a multilingual RAG pipeline based on a podcast episode transcript</summary>
        </entry>
</feed>
